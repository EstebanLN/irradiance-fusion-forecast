{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8203d6aa",
   "metadata": {},
   "source": [
    "# Ground HPO with Optuna (MLP, LSTM, BiLSTM, CNN-LSTM, Transformer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a406c53",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5ed6cf39",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-24 22:06:47.184061: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-09-24 22:06:47.189332: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1758769607.195480  615932 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1758769607.197515  615932 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-09-24 22:06:47.204541: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 AVX512F AVX512_VNNI AVX512_BF16 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "/home/e.ladino/miniconda3/envs/e_ladino/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os, json, numpy as np, pandas as pd, matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, callbacks, regularizers, backend as K\n",
    "\n",
    "import optuna\n",
    "from optuna.samplers import TPESampler\n",
    "from optuna.pruners import MedianPruner\n",
    "from optuna.integration import TFKerasPruningCallback\n",
    "from optuna.storages import JournalStorage\n",
    "from optuna.storages import JournalFileStorage, JournalFileOpenLock"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8fc47f6",
   "metadata": {},
   "source": [
    "## Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1c7ce94f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Studies dir: /mnt/SOLARLAB/E_Ladino/Repo/irradiance-fusion-forecast/optuna_studies\n",
      "Artifacts dir: /mnt/SOLARLAB/E_Ladino/Repo/irradiance-fusion-forecast/models/optuna_artifacts\n"
     ]
    }
   ],
   "source": [
    "SEED = 42\n",
    "np.random.seed(SEED); tf.random.set_seed(SEED)\n",
    "\n",
    "DATA_DIR = Path(\"../data_processed\")\n",
    "OUT_DIR  = Path(\"../models\"); OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "STUDY_DIR= Path(\"../optuna_studies\"); STUDY_DIR.mkdir(parents=True, exist_ok=True)\n",
    "ART_DIR  = (OUT_DIR / \"optuna_artifacts\").resolve(); ART_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "TRAIN_PQ = DATA_DIR / \"ground_train_h6.parquet\"\n",
    "VAL_PQ   = DATA_DIR / \"ground_val_h6.parquet\"\n",
    "TEST_PQ  = DATA_DIR / \"ground_test_h6.parquet\"\n",
    "TARGET   = \"y_ghi_h6\"   # \"y_k_h6\" para el índice k\n",
    "\n",
    "print(\"Studies dir:\", STUDY_DIR.resolve())\n",
    "print(\"Artifacts dir:\", ART_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7e639da",
   "metadata": {},
   "source": [
    "### Data loading and preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "89b4b493",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_parquet(TRAIN_PQ).sort_index()\n",
    "val   = pd.read_parquet(VAL_PQ).sort_index()\n",
    "test  = pd.read_parquet(TEST_PQ).sort_index()\n",
    "assert TARGET in train and TARGET in val and TARGET in test, f\"{TARGET} missing!\"\n",
    "\n",
    "feat_cols = sorted(list(set(train.columns) & set(val.columns) & set(test.columns) - {TARGET}))\n",
    "feat_cols = [c for c in feat_cols if pd.api.types.is_numeric_dtype(train[c])]\n",
    "\n",
    "Xtr_df, ytr = train[feat_cols], train[TARGET]\n",
    "Xva_df, yva = val[feat_cols],   val[TARGET]\n",
    "Xte_df, yte = test[feat_cols],  test[TARGET]\n",
    "\n",
    "scaler = StandardScaler()\n",
    "Xtr = scaler.fit_transform(Xtr_df)\n",
    "Xva = scaler.transform(Xva_df)\n",
    "Xte = scaler.transform(Xte_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9305a371",
   "metadata": {},
   "source": [
    "## Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "05a460c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _rmse(a,b): \n",
    "    return float(np.sqrt(mean_squared_error(a,b)))\n",
    "\n",
    "def skill(y_true, y_pred, y_base):\n",
    "    return 1.0 - (_rmse(y_true, y_pred) / _rmse(y_true, y_base))\n",
    "\n",
    "def _build_seq(X_df, y_ser, L):\n",
    "    \"\"\"Secuencias sin índice (rápido para objetivos Optuna).\"\"\"\n",
    "    Xv, yv = X_df.values, y_ser.values\n",
    "    xs, ys = [], []\n",
    "    for i in range(L-1, len(X_df)):\n",
    "        block = Xv[i-L+1:i+1]\n",
    "        if np.isnan(block).any():\n",
    "            continue\n",
    "        xs.append(block); ys.append(yv[i])\n",
    "    return np.asarray(xs, dtype=\"float32\"), np.asarray(ys, dtype=\"float32\")\n",
    "\n",
    "def build_seq_with_idx(X_df, y_ser, L):\n",
    "    \"\"\"Secuencias con índice (para evaluación y plots).\"\"\"\n",
    "    Xv, yv = X_df.values, y_ser.values\n",
    "    xs, ys, idx = [], [], []\n",
    "    for i in range(L-1, len(X_df)):\n",
    "        block = Xv[i-L+1:i+1]\n",
    "        if np.isnan(block).any():\n",
    "            continue\n",
    "        xs.append(block); ys.append(yv[i]); idx.append(X_df.index[i])\n",
    "    return (np.asarray(xs, dtype=\"float32\"),\n",
    "            np.asarray(ys, dtype=\"float32\"),\n",
    "            pd.DatetimeIndex(idx))\n",
    "\n",
    "def prepare_journal_storage(study_name: str) -> JournalStorage:\n",
    "    log_path   = STUDY_DIR / f\"{study_name}.log\"\n",
    "    lock_path  = STUDY_DIR / f\"{study_name}.lock\"\n",
    "    # limpiar lock si quedó colgado\n",
    "    try: lock_path.unlink()\n",
    "    except FileNotFoundError: pass\n",
    "    file_storage = JournalFileStorage(str(log_path), lock_obj=JournalFileOpenLock(str(lock_path)))\n",
    "    return JournalStorage(file_storage)\n",
    "\n",
    "def _safe_load_best(study, rebuild_fn=None):\n",
    "    \"\"\"Carga robusta del mejor modelo guardado por el estudio.\"\"\"\n",
    "    p = Path(study.best_trial.user_attrs[\"model_path\"])\n",
    "    if not p.exists():\n",
    "        # fallback: buscar por nombre\n",
    "        hits = list(ART_DIR.rglob(p.name))\n",
    "        if hits:\n",
    "            p = hits[0]\n",
    "        elif rebuild_fn is not None:\n",
    "            model = rebuild_fn(study.best_trial.params)\n",
    "            p = ART_DIR / \"recover.keras\"\n",
    "            model.save(p)\n",
    "        else:\n",
    "            raise FileNotFoundError(f\"Checkpoint not found: {p}\")\n",
    "    return tf.keras.models.load_model(p), p"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd38d785",
   "metadata": {},
   "source": [
    "## Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1d7b3333",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline → RMSE: 196.2835 | MAE: 102.1871\n"
     ]
    }
   ],
   "source": [
    "base_src = None\n",
    "\n",
    "# for c in [\"k_ghi\",\"k_raw\",\"k_ghi_lag1\",\"k_raw_lag1\"]:\n",
    "#     if c in test.columns: base_src = test[c]; break\n",
    "# if base_src is None:\n",
    "#     base_src = pd.Series(np.nanmedian(ytr), index=test.index)\n",
    "\n",
    "\n",
    "for c in [\"ghi_qc\",\"ghi_sg_definitive\",\"ghi_qc_lag1\"]:\n",
    "    if c in test.columns: base_src = test[c]; break\n",
    "if base_src is None:\n",
    "    base_src = pd.Series(np.nanmedian(ytr), index=test.index)\n",
    "\n",
    "y_base = base_src.to_numpy()\n",
    "print(f\"Baseline → RMSE: {_rmse(yte, y_base):.4f} | MAE: {mean_absolute_error(yte, y_base):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b684d0e0",
   "metadata": {},
   "source": [
    "## Track A - MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a2285184",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_mlp(trial: optuna.Trial) -> float:\n",
    "    K.clear_session()\n",
    "    n1  = trial.suggest_int(\"n1\", 64, 512, step=64)\n",
    "    n2  = trial.suggest_int(\"n2\", 32, max(64, n1//2), step=32)\n",
    "    do1 = trial.suggest_float(\"do1\", 0.0, 0.5)\n",
    "    do2 = trial.suggest_float(\"do2\", 0.0, 0.5)\n",
    "    lr  = trial.suggest_float(\"lr\", 1e-4, 5e-3, log=True)\n",
    "    l2w = trial.suggest_float(\"l2\", 1e-8, 1e-3, log=True)\n",
    "    act = trial.suggest_categorical(\"act\", [\"relu\",\"selu\",\"gelu\"])\n",
    "    bs  = trial.suggest_categorical(\"batch\", [64, 128, 256, 512])\n",
    "    eps = trial.suggest_int(\"epochs\", 40, 150)\n",
    "\n",
    "    model = models.Sequential([\n",
    "        layers.Input(shape=(Xtr.shape[1],)),\n",
    "        layers.Dense(n1, activation=act, kernel_regularizer=regularizers.l2(l2w)),\n",
    "        layers.Dropout(do1),\n",
    "        layers.Dense(n2, activation=act, kernel_regularizer=regularizers.l2(l2w)),\n",
    "        layers.Dropout(do2),\n",
    "        layers.Dense(1)\n",
    "    ])\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=lr),\n",
    "                  loss=\"mse\", metrics=[\"mae\"])\n",
    "\n",
    "    tmp_dir  = ART_DIR / f\"A_mlp_t{trial.number:04d}\"; tmp_dir.mkdir(parents=True, exist_ok=True)\n",
    "    tmp_path = (tmp_dir / \"best.keras\").resolve()\n",
    "\n",
    "    cbs = [\n",
    "        callbacks.EarlyStopping(monitor=\"val_loss\", patience=12, restore_best_weights=True, verbose=0),\n",
    "        callbacks.ReduceLROnPlateau(monitor=\"val_loss\", factor=0.5, patience=6, min_lr=1e-5, verbose=0),\n",
    "        callbacks.ModelCheckpoint(filepath=str(tmp_path), monitor=\"val_loss\",\n",
    "                                  save_best_only=True, save_weights_only=False),\n",
    "        TFKerasPruningCallback(trial, \"val_loss\"),\n",
    "    ]\n",
    "\n",
    "    model.fit(Xtr, ytr, validation_data=(Xva, yva),\n",
    "              epochs=eps, batch_size=bs, verbose=0, callbacks=cbs)\n",
    "\n",
    "    yhat = model.predict(Xva, verbose=0).squeeze()\n",
    "    val_rmse = _rmse(yva, yhat)\n",
    "\n",
    "    # if not tmp_path.exists():\n",
    "    #     model.save(tmp_path)\n",
    "\n",
    "    trial.set_user_attr(\"model_path\", str(tmp_path))\n",
    "    return val_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fb7a4566",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_615932/3401579257.py:37: FutureWarning: The import path :class:`~optuna.storages.JournalFileOpenLock` has been deprecated in v4.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v4.0.0. Use :class:`~optuna.storages.journal.JournalFileOpenLock` instead.\n",
      "  file_storage = JournalFileStorage(str(log_path), lock_obj=JournalFileOpenLock(str(lock_path)))\n",
      "/tmp/ipykernel_615932/3401579257.py:37: FutureWarning: JournalFileStorage has been deprecated in v4.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v4.0.0. Use :class:`~optuna.storages.journal.JournalFileBackend` instead.\n",
      "  file_storage = JournalFileStorage(str(log_path), lock_obj=JournalFileOpenLock(str(lock_path)))\n",
      "[I 2025-09-24 22:06:49,911] Using an existing study with name 'ground_trackA_mlp' instead of creating a new one.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Study A (MLP)…\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/40 [00:00<?, ?it/s]2025-09-24 22:06:50.273826: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:152] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: CUDA_ERROR_COMPAT_NOT_SUPPORTED_ON_DEVICE: forward compatibility was attempted on non supported HW\n",
      "2025-09-24 22:06:50.273845: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:137] retrieving CUDA diagnostic information for host: solarlivinglabx\n",
      "2025-09-24 22:06:50.273848: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:144] hostname: solarlivinglabx\n",
      "2025-09-24 22:06:50.273904: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:168] libcuda reported version is: 580.65.6\n",
      "2025-09-24 22:06:50.273915: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:172] kernel reported version is: 575.64.3\n",
      "2025-09-24 22:06:50.273918: E external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:262] kernel version 575.64.3 does not match DSO version 580.65.6 -- cannot find working devices in this configuration\n",
      "Best trial: 41. Best value: 129.76:   2%|▎         | 1/40 [00:03<01:58,  3.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-09-24 22:06:52,950] Trial 80 pruned. Trial was pruned at epoch 6.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 41. Best value: 129.76:   5%|▌         | 2/40 [00:09<03:08,  4.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-09-24 22:06:59,260] Trial 81 pruned. Trial was pruned at epoch 14.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 41. Best value: 129.76:   8%|▊         | 3/40 [00:12<02:40,  4.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-09-24 22:07:02,835] Trial 82 pruned. Trial was pruned at epoch 6.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 41. Best value: 129.76:  10%|█         | 4/40 [00:16<02:31,  4.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-09-24 22:07:06,828] Trial 83 pruned. Trial was pruned at epoch 5.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 41. Best value: 129.76:  12%|█▎        | 5/40 [00:23<02:53,  4.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-09-24 22:07:13,173] Trial 84 pruned. Trial was pruned at epoch 12.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 41. Best value: 129.76:  15%|█▌        | 6/40 [00:30<03:16,  5.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-09-24 22:07:20,485] Trial 85 pruned. Trial was pruned at epoch 6.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 41. Best value: 129.76:  18%|█▊        | 7/40 [00:33<02:34,  4.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-09-24 22:07:22,952] Trial 86 pruned. Trial was pruned at epoch 5.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 41. Best value: 129.76:  20%|██        | 8/40 [00:36<02:15,  4.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-09-24 22:07:26,260] Trial 87 pruned. Trial was pruned at epoch 5.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 41. Best value: 129.76:  22%|██▎       | 9/40 [00:39<02:01,  3.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-09-24 22:07:29,433] Trial 88 pruned. Trial was pruned at epoch 5.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 41. Best value: 129.76:  25%|██▌       | 10/40 [00:41<01:38,  3.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-09-24 22:07:31,285] Trial 89 pruned. Trial was pruned at epoch 5.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 41. Best value: 129.76:  28%|██▊       | 11/40 [00:45<01:38,  3.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-09-24 22:07:34,977] Trial 90 pruned. Trial was pruned at epoch 5.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 41. Best value: 129.76:  30%|███       | 12/40 [00:50<01:50,  3.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-09-24 22:07:40,162] Trial 91 pruned. Trial was pruned at epoch 9.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 41. Best value: 129.76:  32%|███▎      | 13/40 [01:06<03:25,  7.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-09-24 22:07:56,239] Trial 92 finished with value: 129.99191681600823 and parameters: {'n1': 384, 'n2': 128, 'do1': 0.49485924818835864, 'do2': 0.2710207099882341, 'lr': 0.004468206532501238, 'l2': 2.5530403194971064e-05, 'act': 'gelu', 'batch': 512, 'epochs': 80}. Best is trial 41 with value: 129.75974644270465.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 41. Best value: 129.76:  35%|███▌      | 14/40 [01:09<02:43,  6.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-09-24 22:07:59,392] Trial 93 pruned. Trial was pruned at epoch 5.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 41. Best value: 129.76:  38%|███▊      | 15/40 [01:24<03:39,  8.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-09-24 22:08:13,991] Trial 94 finished with value: 129.8618180870536 and parameters: {'n1': 384, 'n2': 128, 'do1': 0.43281634565926735, 'do2': 0.2837264217076082, 'lr': 0.0029270987956317176, 'l2': 4.8406849801289635e-06, 'act': 'gelu', 'batch': 512, 'epochs': 84}. Best is trial 41 with value: 129.75974644270465.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 41. Best value: 129.76:  40%|████      | 16/40 [01:39<04:16, 10.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-09-24 22:08:29,054] Trial 95 finished with value: 129.87588726838405 and parameters: {'n1': 320, 'n2': 128, 'do1': 0.4323279177833842, 'do2': 0.2345478603891788, 'lr': 0.002642855496873881, 'l2': 4.70364908340342e-06, 'act': 'gelu', 'batch': 512, 'epochs': 93}. Best is trial 41 with value: 129.75974644270465.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 41. Best value: 129.76:  42%|████▎     | 17/40 [01:42<03:15,  8.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-09-24 22:08:32,472] Trial 96 pruned. Trial was pruned at epoch 5.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 41. Best value: 129.76:  45%|████▌     | 18/40 [01:45<02:30,  6.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-09-24 22:08:35,405] Trial 97 pruned. Trial was pruned at epoch 5.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 41. Best value: 129.76:  48%|████▊     | 19/40 [01:48<02:00,  5.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-09-24 22:08:38,680] Trial 98 pruned. Trial was pruned at epoch 5.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 41. Best value: 129.76:  50%|█████     | 20/40 [01:52<01:40,  5.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-09-24 22:08:42,028] Trial 99 pruned. Trial was pruned at epoch 5.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 41. Best value: 129.76:  52%|█████▎    | 21/40 [01:57<01:35,  5.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-09-24 22:08:47,026] Trial 100 pruned. Trial was pruned at epoch 5.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 41. Best value: 129.76:  55%|█████▌    | 22/40 [02:12<02:25,  8.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-09-24 22:09:02,268] Trial 101 finished with value: 130.02281951161495 and parameters: {'n1': 384, 'n2': 128, 'do1': 0.451313413822716, 'do2': 0.30374489593048015, 'lr': 0.003743889885010605, 'l2': 2.155258390927312e-05, 'act': 'gelu', 'batch': 512, 'epochs': 84}. Best is trial 41 with value: 129.75974644270465.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 41. Best value: 129.76:  57%|█████▊    | 23/40 [02:15<01:52,  6.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-09-24 22:09:05,465] Trial 102 pruned. Trial was pruned at epoch 5.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 41. Best value: 129.76:  60%|██████    | 24/40 [02:20<01:36,  6.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-09-24 22:09:10,118] Trial 103 pruned. Trial was pruned at epoch 9.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 41. Best value: 129.76:  62%|██████▎   | 25/40 [02:25<01:25,  5.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-09-24 22:09:14,975] Trial 104 pruned. Trial was pruned at epoch 9.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 41. Best value: 129.76:  65%|██████▌   | 26/40 [02:28<01:08,  4.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-09-24 22:09:18,005] Trial 105 pruned. Trial was pruned at epoch 5.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 41. Best value: 129.76:  68%|██████▊   | 27/40 [02:30<00:54,  4.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-09-24 22:09:20,585] Trial 106 pruned. Trial was pruned at epoch 5.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 41. Best value: 129.76:  70%|███████   | 28/40 [02:35<00:50,  4.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-09-24 22:09:24,952] Trial 107 pruned. Trial was pruned at epoch 5.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 41. Best value: 129.76:  72%|███████▎  | 29/40 [02:37<00:41,  3.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-09-24 22:09:27,749] Trial 108 pruned. Trial was pruned at epoch 5.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 41. Best value: 129.76:  75%|███████▌  | 30/40 [02:40<00:35,  3.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-09-24 22:09:30,568] Trial 109 pruned. Trial was pruned at epoch 5.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 41. Best value: 129.76:  78%|███████▊  | 31/40 [02:43<00:29,  3.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-09-24 22:09:33,263] Trial 110 pruned. Trial was pruned at epoch 5.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 41. Best value: 129.76:  80%|████████  | 32/40 [02:53<00:42,  5.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-09-24 22:09:43,256] Trial 111 finished with value: 130.14744493025978 and parameters: {'n1': 320, 'n2': 128, 'do1': 0.45895240554716277, 'do2': 0.28481067574131724, 'lr': 0.00425509670966469, 'l2': 0.00032026130078507335, 'act': 'gelu', 'batch': 256, 'epochs': 97}. Best is trial 41 with value: 129.75974644270465.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 41. Best value: 129.76:  82%|████████▎ | 33/40 [03:07<00:54,  7.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-09-24 22:09:57,061] Trial 112 finished with value: 129.83415653488493 and parameters: {'n1': 320, 'n2': 128, 'do1': 0.4446431307454366, 'do2': 0.33273067289457, 'lr': 0.003825957465921398, 'l2': 0.0007202115617983749, 'act': 'gelu', 'batch': 256, 'epochs': 93}. Best is trial 41 with value: 129.75974644270465.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 41. Best value: 129.76:  85%|████████▌ | 34/40 [03:16<00:50,  8.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-09-24 22:10:06,877] Trial 113 finished with value: 130.09749949557062 and parameters: {'n1': 320, 'n2': 128, 'do1': 0.4429640961936036, 'do2': 0.3079227105526868, 'lr': 0.003771399713847665, 'l2': 0.0006533352791682612, 'act': 'gelu', 'batch': 256, 'epochs': 87}. Best is trial 41 with value: 129.75974644270465.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 41. Best value: 129.76:  88%|████████▊ | 35/40 [03:29<00:48,  9.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-09-24 22:10:19,725] Trial 114 finished with value: 129.9740508957461 and parameters: {'n1': 320, 'n2': 128, 'do1': 0.4331324795643336, 'do2': 0.055719787663361116, 'lr': 0.003179612255951713, 'l2': 0.00022194539400150837, 'act': 'gelu', 'batch': 256, 'epochs': 101}. Best is trial 41 with value: 129.75974644270465.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 41. Best value: 129.76:  90%|█████████ | 36/40 [03:37<00:36,  9.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-09-24 22:10:27,036] Trial 115 pruned. Trial was pruned at epoch 14.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 41. Best value: 129.76:  92%|█████████▎| 37/40 [03:40<00:21,  7.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-09-24 22:10:29,938] Trial 116 pruned. Trial was pruned at epoch 5.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 41. Best value: 129.76:  95%|█████████▌| 38/40 [03:42<00:11,  5.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-09-24 22:10:32,790] Trial 117 pruned. Trial was pruned at epoch 5.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 41. Best value: 129.76:  98%|█████████▊| 39/40 [03:46<00:05,  5.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-09-24 22:10:36,744] Trial 118 pruned. Trial was pruned at epoch 6.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 41. Best value: 129.76: 100%|██████████| 40/40 [03:49<00:00,  5.75s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-09-24 22:10:39,824] Trial 119 pruned. Trial was pruned at epoch 5.\n",
      "Best MLP params: {'n1': 320, 'n2': 128, 'do1': 0.4136533265515615, 'do2': 0.32902271732486804, 'lr': 0.002993580716382224, 'l2': 6.43129160846118e-05, 'act': 'gelu', 'batch': 512, 'epochs': 114}\n",
      "MLP test → RMSE: 135.6021 | MAE: 66.9260 | R2: 0.7227 | Skill: 0.309\n"
     ]
    }
   ],
   "source": [
    "storageA = prepare_journal_storage(\"ground_trackA_mlp\")\n",
    "studyA = optuna.create_study(direction=\"minimize\",\n",
    "                             sampler=TPESampler(seed=SEED),\n",
    "                             pruner=MedianPruner(n_startup_trials=8, n_warmup_steps=5),\n",
    "                             study_name=\"ground_trackA_mlp\",\n",
    "                             storage=storageA, load_if_exists=True)\n",
    "print(\"Running Study A (MLP)…\")\n",
    "studyA.optimize(objective_mlp, n_trials=40, show_progress_bar=True)\n",
    "\n",
    "best_mlp, bestA_path = _safe_load_best(studyA)\n",
    "yhatA = best_mlp.predict(Xte, verbose=0).squeeze()\n",
    "print(\"Best MLP params:\", studyA.best_trial.params)\n",
    "print(f\"MLP test → RMSE: {_rmse(yte, yhatA):.4f} | MAE: {mean_absolute_error(yte, yhatA):.4f} | R2: {r2_score(yte, yhatA):.4f} | Skill: {skill(yte, yhatA, y_base):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccd9c63c",
   "metadata": {},
   "source": [
    "## Track B - Sequentials"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "185cbc5c",
   "metadata": {},
   "source": [
    "### Mods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b89bcd3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtr_s = pd.DataFrame(Xtr, index=Xtr_df.index, columns=feat_cols)\n",
    "Xva_s = pd.DataFrame(Xva, index=Xva_df.index, columns=feat_cols)\n",
    "Xte_s = pd.DataFrame(Xte, index=Xte_df.index, columns=feat_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ebeef5d",
   "metadata": {},
   "source": [
    "### LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "392c9a2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_lstm(trial: optuna.Trial) -> float:\n",
    "    K.clear_session()\n",
    "    L   = trial.suggest_categorical(\"seq_len\", [6, 12, 18, 24])\n",
    "    u   = trial.suggest_int(\"units\", 32, 128, step=32)\n",
    "    do  = trial.suggest_float(\"dropout\", 0.0, 0.4)\n",
    "    lr  = trial.suggest_float(\"lr\", 5e-5, 5e-3, log=True)\n",
    "    bs  = trial.suggest_categorical(\"batch\", [64, 128, 256])\n",
    "    eps = trial.suggest_int(\"epochs\", 40, 120)\n",
    "\n",
    "    Xtr_seq, ytr_seq = _build_seq(Xtr_s, ytr, L)\n",
    "    Xva_seq, yva_seq = _build_seq(Xva_s, yva, L)\n",
    "    if min(map(len,[Xtr_seq, Xva_seq])) == 0: \n",
    "        raise optuna.TrialPruned()\n",
    "\n",
    "    model = models.Sequential([\n",
    "        layers.Input(shape=(L, Xtr_seq.shape[2])),\n",
    "        layers.LSTM(u, dropout=do),\n",
    "        layers.Dense(1)\n",
    "    ])\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=lr), loss=\"mse\", metrics=[\"mae\"])\n",
    "\n",
    "    tmp_dir  = ART_DIR / f\"B_lstm_t{trial.number:04d}\"; tmp_dir.mkdir(parents=True, exist_ok=True)\n",
    "    tmp_path = (tmp_dir / \"best.keras\").resolve()\n",
    "\n",
    "    cbs = [\n",
    "        callbacks.EarlyStopping(monitor=\"val_loss\", patience=10, restore_best_weights=True, verbose=0),\n",
    "        callbacks.ModelCheckpoint(filepath=str(tmp_path), monitor=\"val_loss\",\n",
    "                                  save_best_only=True, save_weights_only=False),\n",
    "        TFKerasPruningCallback(trial, \"val_loss\"),\n",
    "    ]\n",
    "    model.fit(Xtr_seq, ytr_seq, validation_data=(Xva_seq, yva_seq),\n",
    "              epochs=eps, batch_size=bs, verbose=0, callbacks=cbs)\n",
    "\n",
    "    yhat = model.predict(Xva_seq, verbose=0).squeeze()\n",
    "    val_rmse = _rmse(yva_seq, yhat)\n",
    "\n",
    "    if not tmp_path.exists():\n",
    "        model.save(tmp_path)\n",
    "\n",
    "    trial.set_user_attr(\"model_path\", str(tmp_path))\n",
    "    trial.set_user_attr(\"seq_len_used\", L)\n",
    "    return val_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6777b424",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_615932/3401579257.py:37: FutureWarning: The import path :class:`~optuna.storages.JournalFileOpenLock` has been deprecated in v4.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v4.0.0. Use :class:`~optuna.storages.journal.JournalFileOpenLock` instead.\n",
      "  file_storage = JournalFileStorage(str(log_path), lock_obj=JournalFileOpenLock(str(lock_path)))\n",
      "/tmp/ipykernel_615932/3401579257.py:37: FutureWarning: JournalFileStorage has been deprecated in v4.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v4.0.0. Use :class:`~optuna.storages.journal.JournalFileBackend` instead.\n",
      "  file_storage = JournalFileStorage(str(log_path), lock_obj=JournalFileOpenLock(str(lock_path)))\n",
      "[I 2025-09-24 22:10:40,258] Using an existing study with name 'ground_trackB_lstm' instead of creating a new one.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Study B1 (LSTM)…\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 22. Best value: 130.254:   2%|▎         | 1/40 [00:31<20:20, 31.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-09-24 22:11:11,554] Trial 40 pruned. Trial was pruned at epoch 17.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 41. Best value: 130.022:   5%|▌         | 2/40 [01:40<33:58, 53.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-09-24 22:12:20,851] Trial 41 finished with value: 130.02156521852442 and parameters: {'seq_len': 18, 'units': 96, 'dropout': 0.2931592840752003, 'lr': 0.0024592686936317975, 'batch': 64, 'epochs': 69}. Best is trial 41 with value: 130.02156521852442.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 41. Best value: 130.022:   8%|▊         | 3/40 [02:56<39:20, 63.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-09-24 22:13:36,702] Trial 42 finished with value: 130.5086428531651 and parameters: {'seq_len': 18, 'units': 96, 'dropout': 0.34422690278769474, 'lr': 0.002329809802803772, 'batch': 64, 'epochs': 78}. Best is trial 41 with value: 130.02156521852442.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 41. Best value: 130.022:  10%|█         | 4/40 [03:17<28:13, 47.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-09-24 22:13:58,097] Trial 43 pruned. Trial was pruned at epoch 6.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 44. Best value: 129.939:  12%|█▎        | 5/40 [04:47<36:23, 62.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-09-24 22:15:27,706] Trial 44 finished with value: 129.939266161638 and parameters: {'seq_len': 18, 'units': 96, 'dropout': 0.33451698668631263, 'lr': 0.002312846347785296, 'batch': 64, 'epochs': 61}. Best is trial 44 with value: 129.939266161638.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 44. Best value: 129.939:  15%|█▌        | 6/40 [06:17<40:38, 71.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-09-24 22:16:57,546] Trial 45 finished with value: 130.20014640928787 and parameters: {'seq_len': 18, 'units': 96, 'dropout': 0.3455174628601367, 'lr': 0.0023043316062673637, 'batch': 64, 'epochs': 61}. Best is trial 44 with value: 129.939266161638.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 44. Best value: 129.939:  18%|█▊        | 7/40 [06:36<29:58, 54.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-09-24 22:17:16,614] Trial 46 pruned. Trial was pruned at epoch 5.\n"
     ]
    }
   ],
   "source": [
    "storageB1 = prepare_journal_storage(\"ground_trackB_lstm\")\n",
    "studyB1 = optuna.create_study(direction=\"minimize\",\n",
    "                              sampler=TPESampler(seed=SEED),\n",
    "                              pruner=MedianPruner(n_startup_trials=8, n_warmup_steps=5),\n",
    "                              study_name=\"ground_trackB_lstm\",\n",
    "                              storage=storageB1, load_if_exists=True)\n",
    "print(\"Running Study B1 (LSTM)…\")\n",
    "studyB1.optimize(objective_lstm, n_trials=40, show_progress_bar=True)\n",
    "\n",
    "best_lstm, _ = _safe_load_best(studyB1)\n",
    "bestL1 = studyB1.best_trial.user_attrs[\"seq_len_used\"]\n",
    "Xte_seq, yte_seq, idx_LSTM = build_seq_with_idx(Xte_s, yte, bestL1)\n",
    "yhatB1 = best_lstm.predict(Xte_seq, verbose=0).squeeze()\n",
    "y_base_LSTM = pd.Series(y_base, index=Xte_df.index).reindex(idx_LSTM).to_numpy()\n",
    "print(\"Best LSTM params:\", studyB1.best_trial.params | {\"seq_len\": bestL1})\n",
    "print(f\"LSTM test → RMSE: {_rmse(yte_seq, yhatB1):.4f} | MAE: {mean_absolute_error(yte_seq, yhatB1):.4f} | R2: {r2_score(yte_seq, yhatB1):.4f} | Skill: {skill(yte_seq, yhatB1, y_base_LSTM):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "218b9bf3",
   "metadata": {},
   "source": [
    "### BiLSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1b34537",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_bilstm(trial: optuna.Trial) -> float:\n",
    "    K.clear_session()\n",
    "    L   = trial.suggest_categorical(\"seq_len\", [6, 12, 18, 24])\n",
    "    u   = trial.suggest_int(\"units\", 32, 128, step=32)\n",
    "    do  = trial.suggest_float(\"dropout\", 0.0, 0.4)\n",
    "    lr  = trial.suggest_float(\"lr\", 5e-5, 5e-3, log=True)\n",
    "    bs  = trial.suggest_categorical(\"batch\", [64, 128, 256])\n",
    "    eps = trial.suggest_int(\"epochs\", 40, 120)\n",
    "\n",
    "    Xtr_seq, ytr_seq = _build_seq(Xtr_s, ytr, L)\n",
    "    Xva_seq, yva_seq = _build_seq(Xva_s, yva, L)\n",
    "    if min(map(len,[Xtr_seq, Xva_seq])) == 0: \n",
    "        raise optuna.TrialPruned()\n",
    "\n",
    "    model = models.Sequential([\n",
    "        layers.Input(shape=(L, Xtr_seq.shape[2])),\n",
    "        layers.Bidirectional(layers.LSTM(u, dropout=do)),\n",
    "        layers.Dense(1)\n",
    "    ])\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=lr), loss=\"mse\", metrics=[\"mae\"])\n",
    "\n",
    "    tmp_dir  = ART_DIR / f\"B_bilstm_t{trial.number:04d}\"; tmp_dir.mkdir(parents=True, exist_ok=True)\n",
    "    tmp_path = (tmp_dir / \"best.keras\").resolve()\n",
    "\n",
    "    cbs = [\n",
    "        callbacks.EarlyStopping(monitor=\"val_loss\", patience=10, restore_best_weights=True, verbose=0),\n",
    "        callbacks.ModelCheckpoint(filepath=str(tmp_path), monitor=\"val_loss\",\n",
    "                                  save_best_only=True, save_weights_only=False),\n",
    "        TFKerasPruningCallback(trial, \"val_loss\"),\n",
    "    ]\n",
    "    model.fit(Xtr_seq, ytr_seq, validation_data=(Xva_seq, yva_seq),\n",
    "              epochs=eps, batch_size=bs, verbose=0, callbacks=cbs)\n",
    "\n",
    "    yhat = model.predict(Xva_seq, verbose=0).squeeze()\n",
    "    val_rmse = _rmse(yva_seq, yhat)\n",
    "\n",
    "    if not tmp_path.exists():\n",
    "        model.save(tmp_path)\n",
    "\n",
    "    trial.set_user_attr(\"model_path\", str(tmp_path))\n",
    "    trial.set_user_attr(\"seq_len_used\", L)\n",
    "    return val_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3b5bd62",
   "metadata": {},
   "outputs": [],
   "source": [
    "storageB2 = prepare_journal_storage(\"ground_trackB_bilstm\")\n",
    "studyB2 = optuna.create_study(direction=\"minimize\",\n",
    "                              sampler=TPESampler(seed=SEED),\n",
    "                              pruner=MedianPruner(n_startup_trials=8, n_warmup_steps=5),\n",
    "                              study_name=\"ground_trackB_bilstm\",\n",
    "                              storage=storageB2, load_if_exists=True)\n",
    "print(\"Running Study B2 (BiLSTM)…\")\n",
    "studyB2.optimize(objective_bilstm, n_trials=35, show_progress_bar=True)\n",
    "\n",
    "best_bi, _ = _safe_load_best(studyB2)\n",
    "bestL2 = studyB2.best_trial.user_attrs[\"seq_len_used\"]\n",
    "Xte_seq, yte_seq, idx_BI = build_seq_with_idx(Xte_s, yte, bestL2)\n",
    "yhatB2 = best_bi.predict(Xte_seq, verbose=0).squeeze()\n",
    "y_base_BI = pd.Series(y_base, index=Xte_df.index).reindex(idx_BI).to_numpy()\n",
    "print(\"Best BiLSTM params:\", studyB2.best_trial.params | {\"seq_len\": bestL2})\n",
    "print(f\"BiLSTM test → RMSE: {_rmse(yte_seq, yhatB2):.4f} | MAE: {mean_absolute_error(yte_seq, yhatB2):.4f} | R2: {r2_score(yte_seq, yhatB2):.4f} | Skill: {skill(yte_seq, yhatB2, y_base_BI):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d213bc8d",
   "metadata": {},
   "source": [
    "### CNN-LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f1c2392",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_cnnlstm(trial: optuna.Trial) -> float:\n",
    "    K.clear_session()\n",
    "    L     = trial.suggest_categorical(\"seq_len\", [6, 12, 18, 24])\n",
    "    filt  = trial.suggest_int(\"filters\", 16, 64, step=16)\n",
    "    ksz   = trial.suggest_categorical(\"kernel_size\", [2,3,5])\n",
    "    pool  = trial.suggest_categorical(\"pool\", [1,2])\n",
    "    u     = trial.suggest_int(\"lstm_units\", 32, 128, step=32)\n",
    "    do    = trial.suggest_float(\"dropout\", 0.0, 0.4)\n",
    "    lr    = trial.suggest_float(\"lr\", 5e-5, 5e-3, log=True)\n",
    "    bs    = trial.suggest_categorical(\"batch\", [64, 128, 256])\n",
    "    eps   = trial.suggest_int(\"epochs\", 40, 120)\n",
    "\n",
    "    Xtr_seq, ytr_seq = _build_seq(Xtr_s, ytr, L)\n",
    "    Xva_seq, yva_seq = _build_seq(Xva_s, yva, L)\n",
    "    if min(map(len,[Xtr_seq, Xva_seq])) == 0: \n",
    "        raise optuna.TrialPruned()\n",
    "\n",
    "    model = models.Sequential([\n",
    "        layers.Input(shape=(L, Xtr_seq.shape[2])),\n",
    "        layers.Conv1D(filt, kernel_size=ksz, padding=\"causal\", activation=\"relu\"),\n",
    "        layers.MaxPooling1D(pool_size=pool) if pool>1 else layers.Lambda(lambda z: z),\n",
    "        layers.LSTM(u, dropout=do),\n",
    "        layers.Dense(1)\n",
    "    ])\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=lr), loss=\"mse\", metrics=[\"mae\"])\n",
    "\n",
    "    tmp_dir  = ART_DIR / f\"B_cnnlstm_t{trial.number:04d}\"; tmp_dir.mkdir(parents=True, exist_ok=True)\n",
    "    tmp_path = (tmp_dir / \"best.keras\").resolve()\n",
    "\n",
    "    cbs = [\n",
    "        callbacks.EarlyStopping(monitor=\"val_loss\", patience=10, restore_best_weights=True, verbose=0),\n",
    "        callbacks.ModelCheckpoint(filepath=str(tmp_path), monitor=\"val_loss\",\n",
    "                                  save_best_only=True, save_weights_only=False),\n",
    "        TFKerasPruningCallback(trial, \"val_loss\"),\n",
    "    ]\n",
    "    model.fit(Xtr_seq, ytr_seq, validation_data=(Xva_seq, yva_seq),\n",
    "              epochs=eps, batch_size=bs, verbose=0, callbacks=cbs)\n",
    "\n",
    "    yhat = model.predict(Xva_seq, verbose=0).squeeze()\n",
    "    val_rmse = _rmse(yva_seq, yhat)\n",
    "\n",
    "    if not tmp_path.exists():\n",
    "        model.save(tmp_path)\n",
    "\n",
    "    trial.set_user_attr(\"model_path\", str(tmp_path))\n",
    "    trial.set_user_attr(\"seq_len_used\", L)\n",
    "    return val_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee61c1f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "storageB3 = prepare_journal_storage(\"ground_trackB_cnnlstm\")\n",
    "studyB3 = optuna.create_study(direction=\"minimize\",\n",
    "                              sampler=TPESampler(seed=SEED),\n",
    "                              pruner=MedianPruner(n_startup_trials=8, n_warmup_steps=5),\n",
    "                              study_name=\"ground_trackB_cnnlstm\",\n",
    "                              storage=storageB3, load_if_exists=True)\n",
    "print(\"Running Study B3 (CNN-LSTM)…\")\n",
    "studyB3.optimize(objective_cnnlstm, n_trials=35, show_progress_bar=True)\n",
    "\n",
    "best_cnn, _ = _safe_load_best(studyB3)\n",
    "bestL3 = studyB3.best_trial.user_attrs[\"seq_len_used\"]\n",
    "Xte_seq, yte_seq, idx_CNN = build_seq_with_idx(Xte_s, yte, bestL3)\n",
    "yhatB3 = best_cnn.predict(Xte_seq, verbose=0).squeeze()\n",
    "y_base_CNN = pd.Series(y_base, index=Xte_df.index).reindex(idx_CNN).to_numpy()\n",
    "print(\"Best CNN-LSTM params:\", studyB3.best_trial.params | {\"seq_len\": bestL3})\n",
    "print(f\"CNN-LSTM test → RMSE: {_rmse(yte_seq, yhatB3):.4f} | MAE: {mean_absolute_error(yte_seq, yhatB3):.4f} | R2: {r2_score(yte_seq, yhatB3):.4f} | Skill: {skill(yte_seq, yhatB3, y_base_CNN):.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c53a6c7",
   "metadata": {},
   "source": [
    "### Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f244d1ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_transformer(trial: optuna.Trial) -> float:\n",
    "    K.clear_session()\n",
    "    L       = trial.suggest_categorical(\"seq_len\", [6, 12, 18, 24])\n",
    "    d_model = trial.suggest_categorical(\"d_model\", [32, 64, 96, 128])\n",
    "    heads   = trial.suggest_categorical(\"heads\", [2, 4, 8])\n",
    "    if d_model % heads != 0:\n",
    "        raise optuna.TrialPruned()\n",
    "    ff_dim  = trial.suggest_categorical(\"ff_dim\", [64, 96, 128, 192])\n",
    "    att_do  = trial.suggest_float(\"att_dropout\", 0.0, 0.3)\n",
    "    do      = trial.suggest_float(\"dropout\", 0.0, 0.4)\n",
    "    lr      = trial.suggest_float(\"lr\", 5e-5, 5e-3, log=True)\n",
    "    bs      = trial.suggest_categorical(\"batch\", [64, 128, 256])\n",
    "    eps     = trial.suggest_int(\"epochs\", 40, 120)\n",
    "\n",
    "    Xtr_seq, ytr_seq = _build_seq(Xtr_s, ytr, L)\n",
    "    Xva_seq, yva_seq = _build_seq(Xva_s, yva, L)\n",
    "    if min(map(len,[Xtr_seq, Xva_seq])) == 0: \n",
    "        raise optuna.TrialPruned()\n",
    "\n",
    "    inp = layers.Input(shape=(L, Xtr_seq.shape[2]))\n",
    "    x   = layers.Dense(d_model)(inp)\n",
    "    x2  = layers.MultiHeadAttention(num_heads=heads, key_dim=d_model//heads, dropout=att_do)(x, x)\n",
    "    x   = layers.Add()([x, x2]); x = layers.LayerNormalization()(x)\n",
    "    ff  = layers.Dense(ff_dim, activation=\"relu\")(x)\n",
    "    ff  = layers.Dense(d_model)(ff)\n",
    "    x   = layers.Add()([x, ff]); x = layers.LayerNormalization()(x)\n",
    "    x   = layers.GlobalAveragePooling1D()(x)\n",
    "    x   = layers.Dropout(do)(x)\n",
    "    out = layers.Dense(1)(x)\n",
    "    model = models.Model(inp, out)\n",
    "\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=lr), loss=\"mse\", metrics=[\"mae\"])\n",
    "\n",
    "    tmp_dir  = ART_DIR / f\"B_transformer_t{trial.number:04d}\"; tmp_dir.mkdir(parents=True, exist_ok=True)\n",
    "    tmp_path = (tmp_dir / \"best.keras\").resolve()\n",
    "\n",
    "    cbs = [\n",
    "        callbacks.EarlyStopping(monitor=\"val_loss\", patience=10, restore_best_weights=True, verbose=0),\n",
    "        callbacks.ModelCheckpoint(filepath=str(tmp_path), monitor=\"val_loss\",\n",
    "                                  save_best_only=True, save_weights_only=False),\n",
    "        TFKerasPruningCallback(trial, \"val_loss\"),\n",
    "    ]\n",
    "    model.fit(Xtr_seq, ytr_seq, validation_data=(Xva_seq, yva_seq),\n",
    "              epochs=eps, batch_size=bs, verbose=0, callbacks=cbs)\n",
    "\n",
    "    yhat = model.predict(Xva_seq, verbose=0).squeeze()\n",
    "    val_rmse = _rmse(yva_seq, yhat)\n",
    "\n",
    "    if not tmp_path.exists():\n",
    "        model.save(tmp_path)\n",
    "\n",
    "    trial.set_user_attr(\"model_path\", str(tmp_path))\n",
    "    trial.set_user_attr(\"seq_len_used\", L)\n",
    "    return val_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab6eee50",
   "metadata": {},
   "outputs": [],
   "source": [
    "storageB4 = prepare_journal_storage(\"ground_trackB_transformer\")\n",
    "studyB4 = optuna.create_study(direction=\"minimize\",\n",
    "                              sampler=TPESampler(seed=SEED),\n",
    "                              pruner=MedianPruner(n_startup_trials=8, n_warmup_steps=5),\n",
    "                              study_name=\"ground_trackB_transformer\",\n",
    "                              storage=storageB4, load_if_exists=True)\n",
    "print(\"Running Study B4 (Transformer)…\")\n",
    "studyB4.optimize(objective_transformer, n_trials=40, show_progress_bar=True)\n",
    "\n",
    "best_tr, _ = _safe_load_best(studyB4)\n",
    "bestL4 = studyB4.best_trial.user_attrs[\"seq_len_used\"]\n",
    "Xte_seq, yte_seq, idx_TR = build_seq_with_idx(Xte_s, yte, bestL4)\n",
    "yhatB4 = best_tr.predict(Xte_seq, verbose=0).squeeze()\n",
    "y_base_TR = pd.Series(y_base, index=Xte_df.index).reindex(idx_TR).to_numpy()\n",
    "print(\"Best Transformer params:\", studyB4.best_trial.params | {\"seq_len\": bestL4})\n",
    "print(f\"Transformer test → RMSE: {_rmse(yte_seq, yhatB4):.4f} | MAE: {mean_absolute_error(yte_seq, yhatB4):.4f} | R2: {r2_score(yte_seq, yhatB4):.4f} | Skill: {skill(yte_seq, yhatB4, y_base_TR):.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01676ed5",
   "metadata": {},
   "source": [
    "## Best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5bf2a76",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = {\n",
    "    \"MLP\":        studyA.best_trial.params,\n",
    "    \"LSTM\":       studyB1.best_trial.params | {\"seq_len\": studyB1.best_trial.user_attrs[\"seq_len_used\"]},\n",
    "    \"BiLSTM\":     studyB2.best_trial.params | {\"seq_len\": studyB2.best_trial.user_attrs[\"seq_len_used\"]},\n",
    "    \"CNN_LSTM\":   studyB3.best_trial.params | {\"seq_len\": studyB3.best_trial.user_attrs[\"seq_len_used\"]},\n",
    "    \"Transformer\":studyB4.best_trial.params | {\"seq_len\": studyB4.best_trial.user_attrs[\"seq_len_used\"]},\n",
    "}\n",
    "(out := OUT_DIR / \"best_hpo_params_all.json\")\n",
    "with open(out, \"w\") as f:\n",
    "    json.dump(best_params, f, indent=2)\n",
    "print(\"Saved params →\", out)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f728f0a",
   "metadata": {},
   "source": [
    "## Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65cbfe37",
   "metadata": {},
   "outputs": [],
   "source": [
    "models_info = {\n",
    "    \"MLP\": {\n",
    "        \"type\": \"tabular\",\n",
    "        \"model\": best_mlp,\n",
    "        \"idx\": Xte_df.index,\n",
    "        \"y_base\": y_base\n",
    "    },\n",
    "    \"LSTM\": {\n",
    "        \"type\": \"seq\",\n",
    "        \"model\": best_lstm,\n",
    "        \"L\": bestL1,\n",
    "        \"idx\": idx_LSTM,\n",
    "        \"y_base\": y_base_LSTM\n",
    "    },\n",
    "    \"BiLSTM\": {\n",
    "        \"type\": \"seq\",\n",
    "        \"model\": best_bi,\n",
    "        \"L\": bestL2,\n",
    "        \"idx\": idx_BI,\n",
    "        \"y_base\": y_base_BI\n",
    "    },\n",
    "    \"CNN-LSTM\": {\n",
    "        \"type\": \"seq\",\n",
    "        \"model\": best_cnn,\n",
    "        \"L\": bestL3,\n",
    "        \"idx\": idx_CNN,\n",
    "        \"y_base\": y_base_CNN\n",
    "    },\n",
    "    \"Transformer\": {\n",
    "        \"type\": \"seq\",\n",
    "        \"model\": best_tr,\n",
    "        \"L\": bestL4,\n",
    "        \"idx\": idx_TR,\n",
    "        \"y_base\": y_base_TR\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6de2026",
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = []\n",
    "OUT_FIG = OUT_DIR\n",
    "for name, cfg in models_info.items():\n",
    "    print(f\"\\n=== {name} ===\")\n",
    "    if cfg[\"type\"] == \"tabular\":\n",
    "        y_true = yte\n",
    "        y_pred = cfg[\"model\"].predict(Xte, verbose=0).squeeze()\n",
    "        idx    = cfg[\"idx\"]\n",
    "        yb     = cfg[\"y_base\"]\n",
    "    else:\n",
    "        L = int(cfg[\"L\"])\n",
    "        X_seq, y_seq, idx = build_seq_with_idx(Xte_s, yte, L)\n",
    "        if len(X_seq) == 0:\n",
    "            print(\"No hay secuencias válidas (NaNs). Se omite.\")\n",
    "            continue\n",
    "        y_true = y_seq\n",
    "        y_pred = cfg[\"model\"].predict(X_seq, verbose=0).squeeze()\n",
    "        yb     = pd.Series(y_base, index=Xte_df.index).reindex(idx).to_numpy()\n",
    "\n",
    "    rmse = _rmse(y_true, y_pred)\n",
    "    mae  = mean_absolute_error(y_true, y_pred)\n",
    "    r2   = r2_score(y_true, y_pred)\n",
    "    skl  = skill(y_true, y_pred, yb)\n",
    "    print(f\"RMSE={rmse:.4f} | MAE={mae:.4f} | R2={r2:.4f} | Skill={skl:.3f}\")\n",
    "\n",
    "    rows.append({\"model\": name, \"RMSE\": rmse, \"MAE\": mae, \"R2\": r2, \"Skill\": skl})\n",
    "\n",
    "    # 1) Serie temporal (recorte)\n",
    "    N = min(400, len(y_true))\n",
    "    plt.figure(figsize=(12, 3.6))\n",
    "    plt.plot(idx[:N], y_true[:N], label=\"truth\", lw=1.4)\n",
    "    plt.plot(idx[:N], y_pred[:N], label=name, lw=1.1)\n",
    "    plt.plot(idx[:N], yb[:N], label=\"baseline\", lw=1.0, alpha=0.7)\n",
    "    plt.title(f\"Test — Truth vs {name} vs Baseline ({TARGET})\")\n",
    "    plt.ylabel(\"GHI (W/m²)\" if TARGET.startswith(\"y_ghi\") else \"k-index\")\n",
    "    plt.xlabel(\"Time\"); plt.grid(True, ls=\"--\", alpha=0.3); plt.legend()\n",
    "    plt.xticks(rotation=45); plt.tight_layout()\n",
    "    plt.savefig(OUT_FIG / f\"{name}_ts_test.png\", dpi=140)\n",
    "    plt.show()\n",
    "\n",
    "    # 2) Scatter\n",
    "    lim_min = float(min(np.min(y_true), np.min(y_pred)))\n",
    "    lim_max = float(max(np.max(y_true), np.max(y_pred)))\n",
    "    plt.figure(figsize=(4.8, 4.8))\n",
    "    plt.scatter(y_true, y_pred, s=10, alpha=0.5)\n",
    "    plt.plot([lim_min, lim_max], [lim_min, lim_max], 'r--', lw=1.0)\n",
    "    plt.xlabel(\"Actual\"); plt.ylabel(\"Predicted\")\n",
    "    plt.title(f\"{name} — Actual vs Predicted\\nRMSE={rmse:.3f} MAE={mae:.3f} R2={r2:.3f}\")\n",
    "    plt.grid(True, ls=\"--\", alpha=0.3); plt.tight_layout()\n",
    "    plt.savefig(OUT_FIG / f\"{name}_scatter.png\", dpi=140)\n",
    "    plt.show()\n",
    "\n",
    "    # 3) Histograma de residuales\n",
    "    resid = y_pred - y_true\n",
    "    plt.figure(figsize=(6, 3.2))\n",
    "    plt.hist(resid, bins=50, alpha=0.85)\n",
    "    plt.axvline(0, color='r', ls='--', lw=1)\n",
    "    plt.title(f\"{name} — Residuals (mean={np.mean(resid):.3f})\")\n",
    "    plt.xlabel(\"Residual\"); plt.ylabel(\"Frequency\")\n",
    "    plt.grid(True, ls=\"--\", alpha=0.3); plt.tight_layout()\n",
    "    plt.savefig(OUT_FIG / f\"{name}_residuals.png\", dpi=140)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "688e6743",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame(rows).sort_values(\"RMSE\")\n",
    "print(\"\\n=== Test Summary ===\")\n",
    "print(results_df.round(4))\n",
    "results_df.to_csv(OUT_DIR / \"hpo_models_test_summary.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "e_ladino",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
