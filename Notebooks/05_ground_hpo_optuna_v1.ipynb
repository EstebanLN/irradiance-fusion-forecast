{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8203d6aa",
   "metadata": {},
   "source": [
    "# Ground HPO with Optuna (MLP, LSTM, BiLSTM, CNN-LSTM, Transformer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a406c53",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6aa9132",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"       # 0=all,1=info,2=warning,3=error\n",
    "# # os.environ[\"TF_ENABLE_ONEDNN_OPTS\"] = \"0\"    # opcional: desactiva oneDNN por reproducibilidad exacta (puede bajar performance)\n",
    "\n",
    "# import tensorflow as tf\n",
    "# gpus = tf.config.list_physical_devices('GPU')\n",
    "# for g in gpus:\n",
    "#     tf.config.experimental.set_memory_growth(g, True)\n",
    "# print(\"GPUs visibles:\", gpus)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fe79efe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tensorflow as tf, time\n",
    "# with tf.device('/GPU:0'):\n",
    "#     a = tf.random.normal([4000, 4000])\n",
    "#     b = tf.random.normal([4000, 4000])\n",
    "#     tf.linalg.matmul(a, b)  # warmup\n",
    "# t0 = time.time()\n",
    "# for _ in range(5):\n",
    "#     with tf.device('/GPU:0'):\n",
    "#         c = tf.linalg.matmul(a, b)\n",
    "# _ = c.numpy()\n",
    "# print(\"Tiempo 5 matmul GPU:\", time.time() - t0, \"s\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ed6cf39",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, json, numpy as np, pandas as pd, matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, callbacks, regularizers, backend as K\n",
    "\n",
    "import optuna\n",
    "from optuna.samplers import TPESampler\n",
    "from optuna.pruners import MedianPruner\n",
    "from optuna.integration import TFKerasPruningCallback\n",
    "from optuna.storages import JournalStorage\n",
    "from optuna.storages import JournalFileStorage, JournalFileOpenLock"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8fc47f6",
   "metadata": {},
   "source": [
    "## Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c7ce94f",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "np.random.seed(SEED); tf.random.set_seed(SEED)\n",
    "\n",
    "DATA_DIR = Path(\"../data_processed\")\n",
    "OUT_DIR  = Path(\"../models\"); OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "STUDY_DIR= Path(\"../optuna_studies\"); STUDY_DIR.mkdir(parents=True, exist_ok=True)\n",
    "ART_DIR  = (OUT_DIR / \"optuna_artifacts\").resolve(); ART_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "TRAIN_PQ = DATA_DIR / \"ground_train_h6.parquet\"\n",
    "VAL_PQ   = DATA_DIR / \"ground_val_h6.parquet\"\n",
    "TEST_PQ  = DATA_DIR / \"ground_test_h6.parquet\"\n",
    "TARGET   = \"y_ghi_h6\" \n",
    "\n",
    "print(\"Studies dir:\", STUDY_DIR.resolve())\n",
    "print(\"Artifacts dir:\", ART_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7e639da",
   "metadata": {},
   "source": [
    "### Data loading and preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89b4b493",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_parquet(TRAIN_PQ).sort_index()\n",
    "val   = pd.read_parquet(VAL_PQ).sort_index()\n",
    "test  = pd.read_parquet(TEST_PQ).sort_index()\n",
    "assert TARGET in train and TARGET in val and TARGET in test, f\"{TARGET} missing!\"\n",
    "\n",
    "feat_cols = sorted(list(set(train.columns) & set(val.columns) & set(test.columns) - {TARGET}))\n",
    "feat_cols = [c for c in feat_cols if pd.api.types.is_numeric_dtype(train[c])]\n",
    "\n",
    "Xtr_df, ytr = train[feat_cols], train[TARGET]\n",
    "Xva_df, yva = val[feat_cols],   val[TARGET]\n",
    "Xte_df, yte = test[feat_cols],  test[TARGET]\n",
    "\n",
    "scaler = StandardScaler()\n",
    "Xtr = scaler.fit_transform(Xtr_df)\n",
    "Xva = scaler.transform(Xva_df)\n",
    "Xte = scaler.transform(Xte_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f85f1e32",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(feat_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9305a371",
   "metadata": {},
   "source": [
    "## Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05a460c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _rmse(a,b):\n",
    "    return float(np.sqrt(mean_squared_error(a,b)))\n",
    "\n",
    "def skill(y_true, y_pred, y_base):\n",
    "    return 1.0 - (_rmse(y_true, y_pred) / _rmse(y_true, y_base))\n",
    "\n",
    "def _build_seq(X_df, y_ser, L):\n",
    "    \"\"\"Secuencias sin índice (rápido para objetivos Optuna).\"\"\"\n",
    "    Xv, yv = X_df.values, y_ser.values\n",
    "    xs, ys = [], []\n",
    "    for i in range(L-1, len(X_df)):\n",
    "        block = Xv[i-L+1:i+1]\n",
    "        if np.isnan(block).any():\n",
    "            continue\n",
    "        xs.append(block); ys.append(yv[i])\n",
    "    return np.asarray(xs, dtype=\"float32\"), np.asarray(ys, dtype=\"float32\")\n",
    "\n",
    "def build_seq_with_idx(X_df, y_ser, L):\n",
    "    \"\"\"Secuencias con índice (para evaluación y plots).\"\"\"\n",
    "    Xv, yv = X_df.values, y_ser.values\n",
    "    xs, ys, idx = [], [], []\n",
    "    for i in range(L-1, len(X_df)):\n",
    "        block = Xv[i-L+1:i+1]\n",
    "        if np.isnan(block).any():\n",
    "            continue\n",
    "        xs.append(block); ys.append(yv[i]); idx.append(X_df.index[i])\n",
    "    return (np.asarray(xs, dtype=\"float32\"),\n",
    "            np.asarray(ys, dtype=\"float32\"),\n",
    "            pd.DatetimeIndex(idx))\n",
    "\n",
    "def prepare_journal_storage(study_name: str) -> JournalStorage:\n",
    "    log_path   = STUDY_DIR / f\"{study_name}.log\"\n",
    "    lock_path  = STUDY_DIR / f\"{study_name}.lock\"\n",
    "    try: lock_path.unlink()\n",
    "    except FileNotFoundError: pass\n",
    "    file_storage = JournalFileStorage(str(log_path), lock_obj=JournalFileOpenLock(str(lock_path)))\n",
    "    return JournalStorage(file_storage)\n",
    "\n",
    "# def _safe_load_best(study, rebuild_fn=None):\n",
    "#     \"\"\"Carga robusta del mejor modelo guardado por el estudio.\"\"\"\n",
    "#     p = Path(study.best_trial.user_attrs[\"model_path\"])\n",
    "#     if not p.exists():\n",
    "#         # fallback: buscar por nombre\n",
    "#         hits = list(ART_DIR.rglob(p.name))\n",
    "#         if hits:\n",
    "#             p = hits[0]\n",
    "#         elif rebuild_fn is not None:\n",
    "#             model = rebuild_fn(study.best_trial.params)\n",
    "#             p = ART_DIR / \"recover.keras\"\n",
    "#             model.save(p)\n",
    "#         else:\n",
    "#             raise FileNotFoundError(f\"Checkpoint not found: {p}\")\n",
    "#     return tf.keras.models.load_model(p), p"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e762b245",
   "metadata": {},
   "source": [
    "### Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69ab07d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_mlp(input_dim, n1=128, n2=64, do1=0.2, do2=0.1, act=\"relu\", l2w=0.0):\n",
    "    return tf.keras.Sequential([\n",
    "        layers.Input(shape=(input_dim,)),\n",
    "        layers.Dense(n1, activation=act, kernel_regularizer=regularizers.l2(l2w)),\n",
    "        layers.Dropout(do1),\n",
    "        layers.Dense(n2, activation=act, kernel_regularizer=regularizers.l2(l2w)),\n",
    "        layers.Dropout(do2),\n",
    "        layers.Dense(1, dtype=\"float32\"),\n",
    "    ])\n",
    "\n",
    "def build_lstm(L, n_feat, units=64, do=0.0):\n",
    "    inp = layers.Input(shape=(L, n_feat))\n",
    "    x   = layers.LSTM(units, dropout=do)(inp)\n",
    "    out = layers.Dense(1, dtype=\"float32\")(x)\n",
    "    return tf.keras.Model(inp, out)\n",
    "\n",
    "def build_bilstm(L, n_feat, units=64, do=0.0):\n",
    "    inp = layers.Input(shape=(L, n_feat))\n",
    "    x   = layers.Bidirectional(layers.LSTM(units, dropout=do))(inp)\n",
    "    out = layers.Dense(1, dtype=\"float32\")(x)\n",
    "    return tf.keras.Model(inp, out)\n",
    "\n",
    "def build_cnnlstm(L, n_feat, filt=32, ksz=3, pool=1, lstm_units=64, do=0.0):\n",
    "    inp = layers.Input(shape=(L, n_feat))\n",
    "    x   = layers.Conv1D(filt, kernel_size=ksz, padding=\"causal\", activation=\"relu\")(inp)\n",
    "    x   = (layers.MaxPooling1D(pool_size=pool)(x) if pool>1 else layers.Identity()(x))\n",
    "    x   = layers.LSTM(lstm_units, dropout=do)(x)\n",
    "    out = layers.Dense(1, dtype=\"float32\")(x)\n",
    "    return tf.keras.Model(inp, out)\n",
    "\n",
    "def build_transformer(L, n_feat, d_model=64, heads=4, ff_dim=128, att_do=0.1, do=0.0):\n",
    "    inp = layers.Input(shape=(L, n_feat))\n",
    "    x   = layers.Dense(d_model)(inp)\n",
    "    x2  = layers.MultiHeadAttention(num_heads=heads, key_dim=d_model//heads, dropout=att_do)(x, x)\n",
    "    x   = layers.Add()([x, x2]); x = layers.LayerNormalization()(x)\n",
    "    ff  = layers.Dense(ff_dim, activation=\"relu\")(x); ff = layers.Dense(d_model)(ff)\n",
    "    x   = layers.Add()([x, ff]); x = layers.LayerNormalization()(x)\n",
    "    x   = layers.GlobalAveragePooling1D()(x)\n",
    "    x   = layers.Dropout(do)(x)\n",
    "    out = layers.Dense(1, dtype=\"float32\")(x)\n",
    "    return tf.keras.Model(inp, out)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7fc2449",
   "metadata": {},
   "source": [
    "### Saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3518825a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _safe_load_best(study):\n",
    "    \"\"\"\n",
    "    Carga robusta: si el best_trial no tiene los nuevos user_attrs (arch, seq_len_used, n_feat),\n",
    "    los infiere desde study_name / ruta del checkpoint / params del trial.\n",
    "    Reconstruye la arquitectura y carga PESOS (.weights.h5 o .keras/.h5 legacy).\n",
    "    \"\"\"\n",
    "    ua = dict(study.best_trial.user_attrs) if study.best_trial.user_attrs else {}\n",
    "\n",
    "    # 1) Localiza el checkpoint\n",
    "    wpath = None\n",
    "    if \"model_path\" in ua:\n",
    "        p = Path(ua[\"model_path\"])\n",
    "        if p.exists():\n",
    "            wpath = p\n",
    "        else:\n",
    "            hits = list(ART_DIR.rglob(p.name))\n",
    "            if hits:\n",
    "                wpath = hits[0]\n",
    "    if wpath is None:\n",
    "        # Fallback: deduce por nombre de estudio\n",
    "        # Busca archivos 'best.weights.h5' o 'best.keras' en ART_DIR que coincidan con el estudio\n",
    "        patt = []\n",
    "        name = (study.study_name or \"\").lower()\n",
    "        if \"mlp\" in name: patt.append(\"A_mlp_*\")\n",
    "        if \"lstm\" in name and \"bilstm\" not in name: patt.append(\"B_lstm_*\")\n",
    "        if \"bilstm\" in name: patt.append(\"B_bilstm_*\")\n",
    "        if \"cnn\" in name: patt.append(\"B_cnnlstm_*\")\n",
    "        if \"transformer\" in name: patt.append(\"B_transformer_*\")\n",
    "        candidates = []\n",
    "        for pat in (patt or [\"*\"]):\n",
    "            candidates += list(ART_DIR.glob(f\"{pat}/best.weights.h5\"))\n",
    "            candidates += list(ART_DIR.glob(f\"{pat}/best.keras\"))\n",
    "            candidates += list(ART_DIR.glob(f\"{pat}/best.h5\"))\n",
    "        if not candidates:\n",
    "            raise FileNotFoundError(\"No checkpoint found for best trial and no user_attrs['model_path'].\")\n",
    "        # Toma el más reciente\n",
    "        wpath = max(candidates, key=lambda p: p.stat().st_mtime)\n",
    "\n",
    "    # 2) Deducir 'arch'\n",
    "    arch = ua.get(\"arch\")\n",
    "    base = wpath.parent.name.lower()\n",
    "    sname = (study.study_name or \"\").lower()\n",
    "    if arch is None:\n",
    "        if \"mlp\" in sname or base.startswith(\"a_mlp\"):\n",
    "            arch = \"mlp\"\n",
    "        elif \"bilstm\" in sname or \"b_bilstm\" in base:\n",
    "            arch = \"bilstm\"\n",
    "        elif (\"lstm\" in sname and \"bilstm\" not in sname) or \"b_lstm\" in base:\n",
    "            arch = \"lstm\"\n",
    "        elif \"cnn\" in sname or \"cnn\" in base:\n",
    "            arch = \"cnn-lstm\"\n",
    "        elif \"transformer\" in sname or \"transformer\" in base:\n",
    "            arch = \"transformer\"\n",
    "        else:\n",
    "            raise KeyError(\"Cannot infer 'arch' from study; please re-run trials or set user_attrs.\")\n",
    "\n",
    "    # 3) Deducir L y n_feat para secuenciales\n",
    "    params = study.best_trial.params\n",
    "    L = ua.get(\"seq_len_used\") or params.get(\"seq_len\")\n",
    "    n_feat = ua.get(\"n_feat\")\n",
    "    if arch != \"mlp\":\n",
    "        if L is None:\n",
    "            # default razonable si faltara\n",
    "            L = 12\n",
    "        if n_feat is None:\n",
    "            # usar el contexto global ya cargado\n",
    "            n_feat = int(Xtr_s.shape[1])\n",
    "\n",
    "    # 4) Reconstruye modelo y carga pesos / modelo\n",
    "    # (acepta tanto weights-only como modelo completo legacy)\n",
    "    if wpath.suffix in {\".keras\", \".h5\"} and \"weights\" not in wpath.name:\n",
    "        # Legacy: modelo completo; cargar con safe_mode desactivado SOLO si confías en el archivo\n",
    "        import keras\n",
    "        try:\n",
    "            keras.config.enable_unsafe_deserialization()\n",
    "        except Exception:\n",
    "            pass\n",
    "        model = tf.keras.models.load_model(wpath, compile=False, safe_mode=False)\n",
    "        model.compile(optimizer=\"adam\", loss=\"mse\", metrics=[\"mae\"])\n",
    "        return model, wpath\n",
    "\n",
    "    # Weights-only (recomendado)\n",
    "    if arch == \"mlp\":\n",
    "        model = build_mlp(\n",
    "            input_dim=Xtr.shape[1],\n",
    "            n1=params.get(\"n1\",128),\n",
    "            n2=params.get(\"n2\",64),\n",
    "            do1=params.get(\"do1\",0.0),\n",
    "            do2=params.get(\"do2\",0.0),\n",
    "            act=params.get(\"act\",\"relu\"),\n",
    "            l2w=params.get(\"l2\",0.0),\n",
    "        )\n",
    "    elif arch == \"lstm\":\n",
    "        model = build_lstm(int(L), int(n_feat),\n",
    "                           units=params.get(\"units\",64),\n",
    "                           do=params.get(\"dropout\",0.0))\n",
    "    elif arch == \"bilstm\":\n",
    "        model = build_bilstm(int(L), int(n_feat),\n",
    "                             units=params.get(\"units\",64),\n",
    "                             do=params.get(\"dropout\",0.0))\n",
    "    elif arch == \"cnn-lstm\":\n",
    "        model = build_cnnlstm(int(L), int(n_feat),\n",
    "                              filt=params.get(\"filters\",32),\n",
    "                              ksz=params.get(\"kernel_size\",3),\n",
    "                              pool=params.get(\"pool\",1),\n",
    "                              lstm_units=params.get(\"lstm_units\",64),\n",
    "                              do=params.get(\"dropout\",0.0))\n",
    "    elif arch == \"transformer\":\n",
    "        model = build_transformer(int(L), int(n_feat),\n",
    "                                  d_model=params.get(\"d_model\",64),\n",
    "                                  heads=params.get(\"heads\",4),\n",
    "                                  ff_dim=params.get(\"ff_dim\",128),\n",
    "                                  att_do=params.get(\"att_dropout\",0.1),\n",
    "                                  do=params.get(\"dropout\",0.0))\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown arch: {arch}\")\n",
    "\n",
    "    model.compile(optimizer=\"adam\", loss=\"mse\", metrics=[\"mae\"])\n",
    "    model.load_weights(str(wpath))\n",
    "    return model, wpath\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd38d785",
   "metadata": {},
   "source": [
    "## Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d7b3333",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_src = None\n",
    "\n",
    "# for c in [\"k_ghi\",\"k_raw\",\"k_ghi_lag1\",\"k_raw_lag1\"]:\n",
    "#     if c in test.columns: base_src = test[c]; break\n",
    "# if base_src is None:\n",
    "#     base_src = pd.Series(np.nanmedian(ytr), index=test.index)\n",
    "\n",
    "for c in [\"ghi_qc\",\"ghi_sg_definitive\",\"ghi_qc_lag1\"]:\n",
    "    if c in test.columns: base_src = test[c]; break\n",
    "if base_src is None:\n",
    "    base_src = pd.Series(np.nanmedian(ytr), index=test.index)\n",
    "\n",
    "y_base = base_src.to_numpy()\n",
    "print(f\"Baseline → RMSE: {_rmse(yte, y_base):.4f} | MAE: {mean_absolute_error(yte, y_base):.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b684d0e0",
   "metadata": {},
   "source": [
    "## Track A - MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2285184",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_mlp(trial: optuna.Trial) -> float:\n",
    "    K.clear_session()\n",
    "    n1  = trial.suggest_int(\"n1\", 64, 512, step=64)\n",
    "    n2  = trial.suggest_int(\"n2\", 32, max(64, n1//2), step=32)\n",
    "    do1 = trial.suggest_float(\"do1\", 0.0, 0.5)\n",
    "    do2 = trial.suggest_float(\"do2\", 0.0, 0.5)\n",
    "    lr  = trial.suggest_float(\"lr\", 1e-4, 5e-3, log=True)\n",
    "    l2w = trial.suggest_float(\"l2\", 1e-8, 1e-3, log=True)\n",
    "    act = trial.suggest_categorical(\"act\", [\"relu\",\"selu\",\"gelu\"])\n",
    "    bs  = trial.suggest_categorical(\"batch\", [64, 128, 256, 512])\n",
    "    eps = trial.suggest_int(\"epochs\", 40, 150)\n",
    "\n",
    "    model = build_mlp(Xtr.shape[1], n1=n1, n2=n2, do1=do1, do2=do2, act=act, l2w=l2w)\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=lr),\n",
    "                  loss=\"mse\", metrics=[\"mae\"])\n",
    "\n",
    "    tmp_dir  = ART_DIR / f\"A_mlp_t{trial.number:04d}\"; tmp_dir.mkdir(parents=True, exist_ok=True)\n",
    "    tmp_path = (tmp_dir / \"best.weights.h5\").resolve()\n",
    "\n",
    "    cbs = [\n",
    "        callbacks.EarlyStopping(monitor=\"val_loss\", patience=12, restore_best_weights=True, verbose=0),\n",
    "        callbacks.ReduceLROnPlateau(monitor=\"val_loss\", factor=0.5, patience=6, min_lr=1e-5, verbose=0),\n",
    "        callbacks.ModelCheckpoint(filepath=str(tmp_path), monitor=\"val_loss\",\n",
    "                                  save_best_only=True, save_weights_only=True),\n",
    "        TFKerasPruningCallback(trial, \"val_loss\"),\n",
    "    ]\n",
    "\n",
    "    model.fit(Xtr, ytr, validation_data=(Xva, yva),\n",
    "              epochs=eps, batch_size=bs, verbose=0, callbacks=cbs)\n",
    "\n",
    "    yhat = model.predict(Xva, verbose=0).squeeze()\n",
    "    val_rmse = _rmse(yva, yhat)\n",
    "\n",
    "    trial.set_user_attr(\"model_path\", str(tmp_path))\n",
    "    trial.set_user_attr(\"arch\", \"mlp\")\n",
    "    trial.set_user_attr(\"input_dim\", Xtr.shape[1])\n",
    "    return val_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb7a4566",
   "metadata": {},
   "outputs": [],
   "source": [
    "storageA = prepare_journal_storage(\"ground_trackA_mlp\")\n",
    "studyA = optuna.create_study(direction=\"minimize\",\n",
    "                             sampler=TPESampler(seed=SEED),\n",
    "                             pruner=MedianPruner(n_startup_trials=8, n_warmup_steps=5),\n",
    "                             study_name=\"ground_trackA_mlp\",\n",
    "                             storage=storageA, load_if_exists=True)\n",
    "print(\"Running Study A (MLP)…\")\n",
    "studyA.optimize(objective_mlp, n_trials=40, show_progress_bar=True)\n",
    "\n",
    "best_mlp, bestA_path = _safe_load_best(studyA)\n",
    "yhatA = best_mlp.predict(Xte, verbose=0).squeeze()\n",
    "print(\"Best MLP params:\", studyA.best_trial.params)\n",
    "print(f\"MLP test → RMSE: {_rmse(yte, yhatA):.4f} | MAE: {mean_absolute_error(yte, yhatA):.4f} | R2: {r2_score(yte, yhatA):.4f} | Skill: {skill(yte, yhatA, y_base):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccd9c63c",
   "metadata": {},
   "source": [
    "## Track B - Sequentials"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "185cbc5c",
   "metadata": {},
   "source": [
    "### Mods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b89bcd3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtr_s = pd.DataFrame(Xtr, index=Xtr_df.index, columns=feat_cols)\n",
    "Xva_s = pd.DataFrame(Xva, index=Xva_df.index, columns=feat_cols)\n",
    "Xte_s = pd.DataFrame(Xte, index=Xte_df.index, columns=feat_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ebeef5d",
   "metadata": {},
   "source": [
    "### LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "392c9a2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_lstm(trial: optuna.Trial) -> float:\n",
    "    K.clear_session()\n",
    "    L   = trial.suggest_categorical(\"seq_len\", [6, 12, 18, 24])\n",
    "    u   = trial.suggest_int(\"units\", 32, 128, step=32)\n",
    "    do  = trial.suggest_float(\"dropout\", 0.0, 0.4)\n",
    "    lr  = trial.suggest_float(\"lr\", 5e-5, 5e-3, log=True)\n",
    "    bs  = trial.suggest_categorical(\"batch\", [64, 128, 256])\n",
    "    eps = trial.suggest_int(\"epochs\", 40, 120)\n",
    "\n",
    "    Xtr_seq, ytr_seq = _build_seq(Xtr_s, ytr, L)\n",
    "    Xva_seq, yva_seq = _build_seq(Xva_s, yva, L)\n",
    "    if min(map(len,[Xtr_seq, Xva_seq])) == 0:\n",
    "        raise optuna.TrialPruned()\n",
    "\n",
    "    model = build_lstm(L, Xtr_seq.shape[2], units=u, do=do)\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=lr), loss=\"mse\", metrics=[\"mae\"])\n",
    "\n",
    "    tmp_dir  = ART_DIR / f\"B_lstm_t{trial.number:04d}\"; tmp_dir.mkdir(parents=True, exist_ok=True)\n",
    "    tmp_path = (tmp_dir / \"best.weights.h5\").resolve()\n",
    "\n",
    "    cbs = [\n",
    "        callbacks.EarlyStopping(monitor=\"val_loss\", patience=10, restore_best_weights=True, verbose=0),\n",
    "        callbacks.ModelCheckpoint(filepath=str(tmp_path), monitor=\"val_loss\",\n",
    "                                  save_best_only=True, save_weights_only=True),\n",
    "        TFKerasPruningCallback(trial, \"val_loss\"),\n",
    "    ]\n",
    "    model.fit(Xtr_seq, ytr_seq, validation_data=(Xva_seq, yva_seq),\n",
    "              epochs=eps, batch_size=bs, verbose=0, callbacks=cbs)\n",
    "\n",
    "    yhat = model.predict(Xva_seq, verbose=0).squeeze()\n",
    "    val_rmse = _rmse(yva_seq, yhat)\n",
    "\n",
    "    trial.set_user_attr(\"model_path\", str(tmp_path))\n",
    "    trial.set_user_attr(\"arch\", \"lstm\")\n",
    "    trial.set_user_attr(\"seq_len_used\", L)\n",
    "    trial.set_user_attr(\"n_feat\", Xtr_s.shape[1])\n",
    "    return val_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6777b424",
   "metadata": {},
   "outputs": [],
   "source": [
    "storageB1 = prepare_journal_storage(\"ground_trackB_lstm\")\n",
    "studyB1 = optuna.create_study(direction=\"minimize\",\n",
    "                              sampler=TPESampler(seed=SEED),\n",
    "                              pruner=MedianPruner(n_startup_trials=8, n_warmup_steps=5),\n",
    "                              study_name=\"ground_trackB_lstm\",\n",
    "                              storage=storageB1, load_if_exists=True)\n",
    "print(\"Running Study B1 (LSTM)…\")\n",
    "studyB1.optimize(objective_lstm, n_trials=40, show_progress_bar=True)\n",
    "\n",
    "best_lstm, _ = _safe_load_best(studyB1)\n",
    "bestL1 = studyB1.best_trial.user_attrs[\"seq_len_used\"]\n",
    "Xte_seq, yte_seq, idx_LSTM = build_seq_with_idx(Xte_s, yte, bestL1)\n",
    "yhatB1 = best_lstm.predict(Xte_seq, verbose=0).squeeze()\n",
    "y_base_LSTM = pd.Series(y_base, index=Xte_df.index).reindex(idx_LSTM).to_numpy()\n",
    "print(\"Best LSTM params:\", studyB1.best_trial.params | {\"seq_len\": bestL1})\n",
    "print(f\"LSTM test → RMSE: {_rmse(yte_seq, yhatB1):.4f} | MAE: {mean_absolute_error(yte_seq, yhatB1):.4f} | R2: {r2_score(yte_seq, yhatB1):.4f} | Skill: {skill(yte_seq, yhatB1, y_base_LSTM):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "218b9bf3",
   "metadata": {},
   "source": [
    "### BiLSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1b34537",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_bilstm(trial: optuna.Trial) -> float:\n",
    "    K.clear_session()\n",
    "    L   = trial.suggest_categorical(\"seq_len\", [6, 12, 18, 24])\n",
    "    u   = trial.suggest_int(\"units\", 32, 128, step=32)\n",
    "    do  = trial.suggest_float(\"dropout\", 0.0, 0.4)\n",
    "    lr  = trial.suggest_float(\"lr\", 5e-5, 5e-3, log=True)\n",
    "    bs  = trial.suggest_categorical(\"batch\", [64, 128, 256])\n",
    "    eps = trial.suggest_int(\"epochs\", 40, 120)\n",
    "\n",
    "    Xtr_seq, ytr_seq = _build_seq(Xtr_s, ytr, L)\n",
    "    Xva_seq, yva_seq = _build_seq(Xva_s, yva, L)\n",
    "    if min(map(len,[Xtr_seq, Xva_seq])) == 0:\n",
    "        raise optuna.TrialPruned()\n",
    "\n",
    "    model = build_bilstm(L, Xtr_seq.shape[2], units=u, do=do)\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=lr), loss=\"mse\", metrics=[\"mae\"])\n",
    "\n",
    "    tmp_dir  = ART_DIR / f\"B_bilstm_t{trial.number:04d}\"; tmp_dir.mkdir(parents=True, exist_ok=True)\n",
    "    tmp_path = (tmp_dir / \"best.weights.h5\").resolve()\n",
    "\n",
    "    cbs = [\n",
    "        callbacks.EarlyStopping(monitor=\"val_loss\", patience=10, restore_best_weights=True, verbose=0),\n",
    "        callbacks.ModelCheckpoint(filepath=str(tmp_path), monitor=\"val_loss\",\n",
    "                                  save_best_only=True, save_weights_only=True),\n",
    "        TFKerasPruningCallback(trial, \"val_loss\"),\n",
    "    ]\n",
    "    model.fit(Xtr_seq, ytr_seq, validation_data=(Xva_seq, yva_seq),\n",
    "              epochs=eps, batch_size=bs, verbose=0, callbacks=cbs)\n",
    "\n",
    "    yhat = model.predict(Xva_seq, verbose=0).squeeze()\n",
    "    val_rmse = _rmse(yva_seq, yhat)\n",
    "\n",
    "    trial.set_user_attr(\"model_path\", str(tmp_path))\n",
    "    trial.set_user_attr(\"arch\", \"bilstm\")\n",
    "    trial.set_user_attr(\"seq_len_used\", L)\n",
    "    trial.set_user_attr(\"n_feat\", Xtr_s.shape[1])\n",
    "    return val_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3b5bd62",
   "metadata": {},
   "outputs": [],
   "source": [
    "storageB2 = prepare_journal_storage(\"ground_trackB_bilstm\")\n",
    "studyB2 = optuna.create_study(direction=\"minimize\",\n",
    "                              sampler=TPESampler(seed=SEED),\n",
    "                              pruner=MedianPruner(n_startup_trials=8, n_warmup_steps=5),\n",
    "                              study_name=\"ground_trackB_bilstm\",\n",
    "                              storage=storageB2, load_if_exists=True)\n",
    "print(\"Running Study B2 (BiLSTM)…\")\n",
    "studyB2.optimize(objective_bilstm, n_trials=35, show_progress_bar=True)\n",
    "\n",
    "best_bi, _ = _safe_load_best(studyB2)\n",
    "bestL2 = studyB2.best_trial.user_attrs[\"seq_len_used\"]\n",
    "Xte_seq, yte_seq, idx_BI = build_seq_with_idx(Xte_s, yte, bestL2)\n",
    "yhatB2 = best_bi.predict(Xte_seq, verbose=0).squeeze()\n",
    "y_base_BI = pd.Series(y_base, index=Xte_df.index).reindex(idx_BI).to_numpy()\n",
    "print(\"Best BiLSTM params:\", studyB2.best_trial.params | {\"seq_len\": bestL2})\n",
    "print(f\"BiLSTM test → RMSE: {_rmse(yte_seq, yhatB2):.4f} | MAE: {mean_absolute_error(yte_seq, yhatB2):.4f} | R2: {r2_score(yte_seq, yhatB2):.4f} | Skill: {skill(yte_seq, yhatB2, y_base_BI):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d213bc8d",
   "metadata": {},
   "source": [
    "### CNN-LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f1c2392",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_cnnlstm(trial: optuna.Trial) -> float:\n",
    "    K.clear_session()\n",
    "    L     = trial.suggest_categorical(\"seq_len\", [6, 12, 18, 24])\n",
    "    filt  = trial.suggest_int(\"filters\", 16, 64, step=16)\n",
    "    ksz   = trial.suggest_categorical(\"kernel_size\", [2,3,5])\n",
    "    pool  = trial.suggest_categorical(\"pool\", [1,2])\n",
    "    u     = trial.suggest_int(\"lstm_units\", 32, 128, step=32)\n",
    "    do    = trial.suggest_float(\"dropout\", 0.0, 0.4)\n",
    "    lr    = trial.suggest_float(\"lr\", 5e-5, 5e-3, log=True)\n",
    "    bs    = trial.suggest_categorical(\"batch\", [64, 128, 256])\n",
    "    eps   = trial.suggest_int(\"epochs\", 40, 120)\n",
    "\n",
    "    Xtr_seq, ytr_seq = _build_seq(Xtr_s, ytr, L)\n",
    "    Xva_seq, yva_seq = _build_seq(Xva_s, yva, L)\n",
    "    if min(map(len,[Xtr_seq, Xva_seq])) == 0:\n",
    "        raise optuna.TrialPruned()\n",
    "\n",
    "    model = build_cnnlstm(L, Xtr_seq.shape[2], filt=filt, ksz=ksz, pool=pool, lstm_units=u, do=do)\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=lr), loss=\"mse\", metrics=[\"mae\"])\n",
    "\n",
    "    tmp_dir  = ART_DIR / f\"B_cnnlstm_t{trial.number:04d}\"; tmp_dir.mkdir(parents=True, exist_ok=True)\n",
    "    tmp_path = (tmp_dir / \"best.weights.h5\").resolve()\n",
    "\n",
    "    cbs = [\n",
    "        callbacks.EarlyStopping(monitor=\"val_loss\", patience=10, restore_best_weights=True, verbose=0),\n",
    "        callbacks.ModelCheckpoint(filepath=str(tmp_path), monitor=\"val_loss\",\n",
    "                                  save_best_only=True, save_weights_only=True),\n",
    "        TFKerasPruningCallback(trial, \"val_loss\"),\n",
    "    ]\n",
    "    model.fit(Xtr_seq, ytr_seq, validation_data=(Xva_seq, yva_seq),\n",
    "              epochs=eps, batch_size=bs, verbose=0, callbacks=cbs)\n",
    "\n",
    "    yhat = model.predict(Xva_seq, verbose=0).squeeze()\n",
    "    val_rmse = _rmse(yva_seq, yhat)\n",
    "\n",
    "    trial.set_user_attr(\"model_path\", str(tmp_path))\n",
    "    trial.set_user_attr(\"arch\", \"cnn-lstm\")\n",
    "    trial.set_user_attr(\"seq_len_used\", L)\n",
    "    trial.set_user_attr(\"n_feat\", Xtr_s.shape[1])\n",
    "    return val_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee61c1f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "storageB3 = prepare_journal_storage(\"ground_trackB_cnnlstm\")\n",
    "studyB3 = optuna.create_study(direction=\"minimize\",\n",
    "                              sampler=TPESampler(seed=SEED),\n",
    "                              pruner=MedianPruner(n_startup_trials=8, n_warmup_steps=5),\n",
    "                              study_name=\"ground_trackB_cnnlstm\",\n",
    "                              storage=storageB3, load_if_exists=True)\n",
    "print(\"Running Study B3 (CNN-LSTM)…\")\n",
    "studyB3.optimize(objective_cnnlstm, n_trials=35, show_progress_bar=True)\n",
    "\n",
    "best_cnn, _ = _safe_load_best(studyB3)\n",
    "bestL3 = studyB3.best_trial.user_attrs[\"seq_len_used\"]\n",
    "Xte_seq, yte_seq, idx_CNN = build_seq_with_idx(Xte_s, yte, bestL3)\n",
    "yhatB3 = best_cnn.predict(Xte_seq, verbose=0).squeeze()\n",
    "y_base_CNN = pd.Series(y_base, index=Xte_df.index).reindex(idx_CNN).to_numpy()\n",
    "print(\"Best CNN-LSTM params:\", studyB3.best_trial.params | {\"seq_len\": bestL3})\n",
    "print(f\"CNN-LSTM test → RMSE: {_rmse(yte_seq, yhatB3):.4f} | MAE: {mean_absolute_error(yte_seq, yhatB3):.4f} | R2: {r2_score(yte_seq, yhatB3):.4f} | Skill: {skill(yte_seq, yhatB3, y_base_CNN):.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c53a6c7",
   "metadata": {},
   "source": [
    "### Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f244d1ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_transformer(trial: optuna.Trial) -> float:\n",
    "    K.clear_session()\n",
    "    L       = trial.suggest_categorical(\"seq_len\", [6, 12, 18, 24])\n",
    "    d_model = trial.suggest_categorical(\"d_model\", [32, 64, 96, 128])\n",
    "    heads   = trial.suggest_categorical(\"heads\", [2, 4, 8])\n",
    "    if d_model % heads != 0:\n",
    "        raise optuna.TrialPruned()\n",
    "    ff_dim  = trial.suggest_categorical(\"ff_dim\", [64, 96, 128, 192])\n",
    "    att_do  = trial.suggest_float(\"att_dropout\", 0.0, 0.3)\n",
    "    do      = trial.suggest_float(\"dropout\", 0.0, 0.4)\n",
    "    lr      = trial.suggest_float(\"lr\", 5e-5, 5e-3, log=True)\n",
    "    bs      = trial.suggest_categorical(\"batch\", [64, 128, 256])\n",
    "    eps     = trial.suggest_int(\"epochs\", 40, 120)\n",
    "\n",
    "    Xtr_seq, ytr_seq = _build_seq(Xtr_s, ytr, L)\n",
    "    Xva_seq, yva_seq = _build_seq(Xva_s, yva, L)\n",
    "    if min(map(len,[Xtr_seq, Xva_seq])) == 0:\n",
    "        raise optuna.TrialPruned()\n",
    "\n",
    "    model = build_transformer(L, Xtr_seq.shape[2], d_model=d_model, heads=heads,\n",
    "                              ff_dim=ff_dim, att_do=att_do, do=do)\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=lr), loss=\"mse\", metrics=[\"mae\"])\n",
    "\n",
    "    tmp_dir  = ART_DIR / f\"B_transformer_t{trial.number:04d}\"; tmp_dir.mkdir(parents=True, exist_ok=True)\n",
    "    tmp_path = (tmp_dir / \"best.weights.h5\").resolve()\n",
    "\n",
    "    cbs = [\n",
    "        callbacks.EarlyStopping(monitor=\"val_loss\", patience=10, restore_best_weights=True, verbose=0),\n",
    "        callbacks.ModelCheckpoint(filepath=str(tmp_path), monitor=\"val_loss\",\n",
    "                                  save_best_only=True, save_weights_only=True),\n",
    "        TFKerasPruningCallback(trial, \"val_loss\"),\n",
    "    ]\n",
    "    model.fit(Xtr_seq, ytr_seq, validation_data=(Xva_seq, yva_seq),\n",
    "              epochs=eps, batch_size=bs, verbose=0, callbacks=cbs)\n",
    "\n",
    "    yhat = model.predict(Xva_seq, verbose=0).squeeze()\n",
    "    val_rmse = _rmse(yva_seq, yhat)\n",
    "\n",
    "    trial.set_user_attr(\"model_path\", str(tmp_path))\n",
    "    trial.set_user_attr(\"arch\", \"transformer\")\n",
    "    trial.set_user_attr(\"seq_len_used\", L)\n",
    "    trial.set_user_attr(\"n_feat\", Xtr_s.shape[1])\n",
    "    return val_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab6eee50",
   "metadata": {},
   "outputs": [],
   "source": [
    "storageB4 = prepare_journal_storage(\"ground_trackB_transformer\")\n",
    "studyB4 = optuna.create_study(direction=\"minimize\",\n",
    "                              sampler=TPESampler(seed=SEED),\n",
    "                              pruner=MedianPruner(n_startup_trials=8, n_warmup_steps=5),\n",
    "                              study_name=\"ground_trackB_transformer\",\n",
    "                              storage=storageB4, load_if_exists=True)\n",
    "print(\"Running Study B4 (Transformer)…\")\n",
    "studyB4.optimize(objective_transformer, n_trials=40, show_progress_bar=True)\n",
    "\n",
    "best_tr, _ = _safe_load_best(studyB4)\n",
    "bestL4 = studyB4.best_trial.user_attrs[\"seq_len_used\"]\n",
    "Xte_seq, yte_seq, idx_TR = build_seq_with_idx(Xte_s, yte, bestL4)\n",
    "yhatB4 = best_tr.predict(Xte_seq, verbose=0).squeeze()\n",
    "y_base_TR = pd.Series(y_base, index=Xte_df.index).reindex(idx_TR).to_numpy()\n",
    "print(\"Best Transformer params:\", studyB4.best_trial.params | {\"seq_len\": bestL4})\n",
    "print(f\"Transformer test → RMSE: {_rmse(yte_seq, yhatB4):.4f} | MAE: {mean_absolute_error(yte_seq, yhatB4):.4f} | R2: {r2_score(yte_seq, yhatB4):.4f} | Skill: {skill(yte_seq, yhatB4, y_base_TR):.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01676ed5",
   "metadata": {},
   "source": [
    "## Best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5bf2a76",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = {\n",
    "    \"MLP\":        studyA.best_trial.params,\n",
    "    \"LSTM\":       studyB1.best_trial.params | {\"seq_len\": studyB1.best_trial.user_attrs[\"seq_len_used\"]},\n",
    "    \"BiLSTM\":     studyB2.best_trial.params | {\"seq_len\": studyB2.best_trial.user_attrs[\"seq_len_used\"]},\n",
    "    \"CNN_LSTM\":   studyB3.best_trial.params | {\"seq_len\": studyB3.best_trial.user_attrs[\"seq_len_used\"]},\n",
    "    \"Transformer\":studyB4.best_trial.params | {\"seq_len\": studyB4.best_trial.user_attrs[\"seq_len_used\"]},\n",
    "}\n",
    "(out := OUT_DIR / \"best_hpo_params_all.json\")\n",
    "with open(out, \"w\") as f:\n",
    "    json.dump(best_params, f, indent=2)\n",
    "print(\"Saved params →\", out)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f728f0a",
   "metadata": {},
   "source": [
    "## Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65cbfe37",
   "metadata": {},
   "outputs": [],
   "source": [
    "models_info = {\n",
    "    \"MLP\": {\n",
    "        \"type\": \"tabular\",\n",
    "        \"model\": best_mlp,\n",
    "        \"idx\": Xte_df.index,\n",
    "        \"y_base\": y_base\n",
    "    },\n",
    "    \"LSTM\": {\n",
    "        \"type\": \"seq\",\n",
    "        \"model\": best_lstm,\n",
    "        \"L\": bestL1,\n",
    "        \"idx\": idx_LSTM,\n",
    "        \"y_base\": y_base_LSTM\n",
    "    },\n",
    "    \"BiLSTM\": {\n",
    "        \"type\": \"seq\",\n",
    "        \"model\": best_bi,\n",
    "        \"L\": bestL2,\n",
    "        \"idx\": idx_BI,\n",
    "        \"y_base\": y_base_BI\n",
    "    },\n",
    "    \"CNN-LSTM\": {\n",
    "        \"type\": \"seq\",\n",
    "        \"model\": best_cnn,\n",
    "        \"L\": bestL3,\n",
    "        \"idx\": idx_CNN,\n",
    "        \"y_base\": y_base_CNN\n",
    "    },\n",
    "    \"Transformer\": {\n",
    "        \"type\": \"seq\",\n",
    "        \"model\": best_tr,\n",
    "        \"L\": bestL4,\n",
    "        \"idx\": idx_TR,\n",
    "        \"y_base\": y_base_TR\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6de2026",
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = []\n",
    "OUT_FIG = Path(\"../reports/figures\")\n",
    "for name, cfg in models_info.items():\n",
    "    print(f\"\\n=== {name} ===\")\n",
    "    if cfg[\"type\"] == \"tabular\":\n",
    "        y_true = yte\n",
    "        y_pred = cfg[\"model\"].predict(Xte, verbose=0).squeeze()\n",
    "        idx    = cfg[\"idx\"]\n",
    "        yb     = cfg[\"y_base\"]\n",
    "    else:\n",
    "        L = int(cfg[\"L\"])\n",
    "        X_seq, y_seq, idx = build_seq_with_idx(Xte_s, yte, L)\n",
    "        if len(X_seq) == 0:\n",
    "            print(\"No hay secuencias válidas (NaNs). Se omite.\")\n",
    "            continue\n",
    "        y_true = y_seq\n",
    "        y_pred = cfg[\"model\"].predict(X_seq, verbose=0).squeeze()\n",
    "        yb     = pd.Series(y_base, index=Xte_df.index).reindex(idx).to_numpy()\n",
    "\n",
    "    rmse = _rmse(y_true, y_pred)\n",
    "    mae  = mean_absolute_error(y_true, y_pred)\n",
    "    r2   = r2_score(y_true, y_pred)\n",
    "    skl  = skill(y_true, y_pred, yb)\n",
    "    print(f\"RMSE={rmse:.4f} | MAE={mae:.4f} | R2={r2:.4f} | Skill={skl:.3f}\")\n",
    "\n",
    "    rows.append({\"model\": name, \"RMSE\": rmse, \"MAE\": mae, \"R2\": r2, \"Skill\": skl})\n",
    "\n",
    "    # 1) Time series (clip)\n",
    "    N = min(400, len(y_true))\n",
    "    plt.figure(figsize=(12, 3.6))\n",
    "    plt.plot(idx[:N], y_true[:N], label=\"truth\", lw=1.4)\n",
    "    plt.plot(idx[:N], y_pred[:N], label=name, lw=1.1)\n",
    "    plt.plot(idx[:N], yb[:N], label=\"baseline\", lw=1.0, alpha=0.7)\n",
    "    plt.title(f\"Test — Truth vs {name} vs Baseline ({TARGET})\")\n",
    "    plt.ylabel(\"GHI (W/m²)\" if TARGET.startswith(\"y_ghi\") else \"k-index\")\n",
    "    plt.xlabel(\"Time\"); plt.grid(True, ls=\"--\", alpha=0.3); plt.legend()\n",
    "    plt.xticks(rotation=45); plt.tight_layout()\n",
    "    plt.savefig(OUT_FIG / f\"{name}_ts_test.png\", dpi=140)\n",
    "    plt.show()\n",
    "\n",
    "    # 2) Scatter\n",
    "    lim_min = float(min(np.min(y_true), np.min(y_pred)))\n",
    "    lim_max = float(max(np.max(y_true), np.max(y_pred)))\n",
    "    plt.figure(figsize=(4.8, 4.8))\n",
    "    plt.scatter(y_true, y_pred, s=10, alpha=0.5)\n",
    "    plt.plot([lim_min, lim_max], [lim_min, lim_max], 'r--', lw=1.0)\n",
    "    plt.xlabel(\"Actual\"); plt.ylabel(\"Predicted\")\n",
    "    plt.title(f\"{name} — Actual vs Predicted\\nRMSE={rmse:.3f} MAE={mae:.3f} R2={r2:.3f}\")\n",
    "    plt.grid(True, ls=\"--\", alpha=0.3); plt.tight_layout()\n",
    "    plt.savefig(OUT_FIG / f\"{name}_scatter.png\", dpi=140)\n",
    "    plt.show()\n",
    "\n",
    "    # 3) Residuals histogram\n",
    "    resid = y_pred - y_true\n",
    "    plt.figure(figsize=(6, 3.2))\n",
    "    plt.hist(resid, bins=50, alpha=0.85)\n",
    "    plt.axvline(0, color='r', ls='--', lw=1)\n",
    "    plt.title(f\"{name} — Residuals (mean={np.mean(resid):.3f})\")\n",
    "    plt.xlabel(\"Residual\"); plt.ylabel(\"Frequency\")\n",
    "    plt.grid(True, ls=\"--\", alpha=0.3); plt.tight_layout()\n",
    "    plt.savefig(OUT_FIG / f\"{name}_residuals.png\", dpi=140)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "688e6743",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame(rows).sort_values(\"RMSE\")\n",
    "print(\"\\n=== Test Summary ===\")\n",
    "print(results_df.round(4))\n",
    "results_df.to_csv(OUT_DIR / \"hpo_models_test_summary.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "e_ladino",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
