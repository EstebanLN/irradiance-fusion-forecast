{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8203d6aa",
   "metadata": {},
   "source": [
    "# Ground HPO with Optuna (MLP, LSTM, BiLSTM, CNN-LSTM, Transformer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a406c53",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d6aa9132",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tensorflow as tf\n",
    "# print(\"TensorFlow version:\", tf.__version__)\n",
    "# print(\"GPU disponible:\", tf.config.list_physical_devices('GPU'))\n",
    "\n",
    "# # Test simple\n",
    "# hello = tf.constant('Hello, TensorFlow!')\n",
    "# print(hello.numpy().decode())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5ed6cf39",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, json, numpy as np, pandas as pd, matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, callbacks, regularizers, backend as K\n",
    "\n",
    "import optuna\n",
    "from optuna.samplers import TPESampler\n",
    "from optuna.pruners import MedianPruner\n",
    "from optuna.integration import TFKerasPruningCallback\n",
    "from optuna.storages import JournalStorage\n",
    "from optuna.storages import JournalFileStorage, JournalFileOpenLock"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8fc47f6",
   "metadata": {},
   "source": [
    "## Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1c7ce94f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Studies dir: /mnt/SOLARLAB/E_Ladino/Repo/irradiance-fusion-forecast/optuna_studies\n",
      "Artifacts dir: /mnt/SOLARLAB/E_Ladino/Repo/irradiance-fusion-forecast/models/optuna_artifacts\n"
     ]
    }
   ],
   "source": [
    "SEED = 42\n",
    "np.random.seed(SEED); tf.random.set_seed(SEED)\n",
    "\n",
    "DATA_DIR = Path(\"../data_processed\")\n",
    "OUT_DIR  = Path(\"../models\"); OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "STUDY_DIR= Path(\"../optuna_studies\"); STUDY_DIR.mkdir(parents=True, exist_ok=True)\n",
    "ART_DIR  = (OUT_DIR / \"optuna_artifacts\").resolve(); ART_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "TRAIN_PQ = DATA_DIR / \"ground_train_h6.parquet\"\n",
    "VAL_PQ   = DATA_DIR / \"ground_val_h6.parquet\"\n",
    "TEST_PQ  = DATA_DIR / \"ground_test_h6.parquet\"\n",
    "TARGET   = \"y_ghi_h6\" \n",
    "\n",
    "print(\"Studies dir:\", STUDY_DIR.resolve())\n",
    "print(\"Artifacts dir:\", ART_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7e639da",
   "metadata": {},
   "source": [
    "### Data loading and preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "89b4b493",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_parquet(TRAIN_PQ).sort_index()\n",
    "val   = pd.read_parquet(VAL_PQ).sort_index()\n",
    "test  = pd.read_parquet(TEST_PQ).sort_index()\n",
    "assert TARGET in train and TARGET in val and TARGET in test, f\"{TARGET} missing!\"\n",
    "\n",
    "feat_cols = sorted(list(set(train.columns) & set(val.columns) & set(test.columns) - {TARGET}))\n",
    "feat_cols = [c for c in feat_cols if pd.api.types.is_numeric_dtype(train[c])]\n",
    "\n",
    "Xtr_df, ytr = train[feat_cols], train[TARGET]\n",
    "Xva_df, yva = val[feat_cols],   val[TARGET]\n",
    "Xte_df, yte = test[feat_cols],  test[TARGET]\n",
    "\n",
    "scaler = StandardScaler()\n",
    "Xtr = scaler.fit_transform(Xtr_df)\n",
    "Xva = scaler.transform(Xva_df)\n",
    "Xte = scaler.transform(Xte_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9305a371",
   "metadata": {},
   "source": [
    "## Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "05a460c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _rmse(a,b):\n",
    "    return float(np.sqrt(mean_squared_error(a,b)))\n",
    "\n",
    "def skill(y_true, y_pred, y_base):\n",
    "    return 1.0 - (_rmse(y_true, y_pred) / _rmse(y_true, y_base))\n",
    "\n",
    "def _build_seq(X_df, y_ser, L):\n",
    "    \"\"\"Secuencias sin índice (rápido para objetivos Optuna).\"\"\"\n",
    "    Xv, yv = X_df.values, y_ser.values\n",
    "    xs, ys = [], []\n",
    "    for i in range(L-1, len(X_df)):\n",
    "        block = Xv[i-L+1:i+1]\n",
    "        if np.isnan(block).any():\n",
    "            continue\n",
    "        xs.append(block); ys.append(yv[i])\n",
    "    return np.asarray(xs, dtype=\"float32\"), np.asarray(ys, dtype=\"float32\")\n",
    "\n",
    "def build_seq_with_idx(X_df, y_ser, L):\n",
    "    \"\"\"Secuencias con índice (para evaluación y plots).\"\"\"\n",
    "    Xv, yv = X_df.values, y_ser.values\n",
    "    xs, ys, idx = [], [], []\n",
    "    for i in range(L-1, len(X_df)):\n",
    "        block = Xv[i-L+1:i+1]\n",
    "        if np.isnan(block).any():\n",
    "            continue\n",
    "        xs.append(block); ys.append(yv[i]); idx.append(X_df.index[i])\n",
    "    return (np.asarray(xs, dtype=\"float32\"),\n",
    "            np.asarray(ys, dtype=\"float32\"),\n",
    "            pd.DatetimeIndex(idx))\n",
    "\n",
    "def prepare_journal_storage(study_name: str) -> JournalStorage:\n",
    "    log_path   = STUDY_DIR / f\"{study_name}.log\"\n",
    "    lock_path  = STUDY_DIR / f\"{study_name}.lock\"\n",
    "    try: lock_path.unlink()\n",
    "    except FileNotFoundError: pass\n",
    "    file_storage = JournalFileStorage(str(log_path), lock_obj=JournalFileOpenLock(str(lock_path)))\n",
    "    return JournalStorage(file_storage)\n",
    "\n",
    "# def _safe_load_best(study, rebuild_fn=None):\n",
    "#     \"\"\"Carga robusta del mejor modelo guardado por el estudio.\"\"\"\n",
    "#     p = Path(study.best_trial.user_attrs[\"model_path\"])\n",
    "#     if not p.exists():\n",
    "#         # fallback: buscar por nombre\n",
    "#         hits = list(ART_DIR.rglob(p.name))\n",
    "#         if hits:\n",
    "#             p = hits[0]\n",
    "#         elif rebuild_fn is not None:\n",
    "#             model = rebuild_fn(study.best_trial.params)\n",
    "#             p = ART_DIR / \"recover.keras\"\n",
    "#             model.save(p)\n",
    "#         else:\n",
    "#             raise FileNotFoundError(f\"Checkpoint not found: {p}\")\n",
    "#     return tf.keras.models.load_model(p), p"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e762b245",
   "metadata": {},
   "source": [
    "### Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "69ab07d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_mlp(input_dim, n1=128, n2=64, do1=0.2, do2=0.1, act=\"relu\", l2w=0.0):\n",
    "    return tf.keras.Sequential([\n",
    "        layers.Input(shape=(input_dim,)),\n",
    "        layers.Dense(n1, activation=act, kernel_regularizer=regularizers.l2(l2w)),\n",
    "        layers.Dropout(do1),\n",
    "        layers.Dense(n2, activation=act, kernel_regularizer=regularizers.l2(l2w)),\n",
    "        layers.Dropout(do2),\n",
    "        layers.Dense(1, dtype=\"float32\"),\n",
    "    ])\n",
    "\n",
    "def build_lstm(L, n_feat, units=64, do=0.0):\n",
    "    inp = layers.Input(shape=(L, n_feat))\n",
    "    x   = layers.LSTM(units, dropout=do)(inp)\n",
    "    out = layers.Dense(1, dtype=\"float32\")(x)\n",
    "    return tf.keras.Model(inp, out)\n",
    "\n",
    "def build_bilstm(L, n_feat, units=64, do=0.0):\n",
    "    inp = layers.Input(shape=(L, n_feat))\n",
    "    x   = layers.Bidirectional(layers.LSTM(units, dropout=do))(inp)\n",
    "    out = layers.Dense(1, dtype=\"float32\")(x)\n",
    "    return tf.keras.Model(inp, out)\n",
    "\n",
    "def build_cnnlstm(L, n_feat, filt=32, ksz=3, pool=1, lstm_units=64, do=0.0):\n",
    "    inp = layers.Input(shape=(L, n_feat))\n",
    "    x   = layers.Conv1D(filt, kernel_size=ksz, padding=\"causal\", activation=\"relu\")(inp)\n",
    "    x   = (layers.MaxPooling1D(pool_size=pool)(x) if pool>1 else layers.Identity()(x))\n",
    "    x   = layers.LSTM(lstm_units, dropout=do)(x)\n",
    "    out = layers.Dense(1, dtype=\"float32\")(x)\n",
    "    return tf.keras.Model(inp, out)\n",
    "\n",
    "def build_transformer(L, n_feat, d_model=64, heads=4, ff_dim=128, att_do=0.1, do=0.0):\n",
    "    inp = layers.Input(shape=(L, n_feat))\n",
    "    x   = layers.Dense(d_model)(inp)\n",
    "    x2  = layers.MultiHeadAttention(num_heads=heads, key_dim=d_model//heads, dropout=att_do)(x, x)\n",
    "    x   = layers.Add()([x, x2]); x = layers.LayerNormalization()(x)\n",
    "    ff  = layers.Dense(ff_dim, activation=\"relu\")(x); ff = layers.Dense(d_model)(ff)\n",
    "    x   = layers.Add()([x, ff]); x = layers.LayerNormalization()(x)\n",
    "    x   = layers.GlobalAveragePooling1D()(x)\n",
    "    x   = layers.Dropout(do)(x)\n",
    "    out = layers.Dense(1, dtype=\"float32\")(x)\n",
    "    return tf.keras.Model(inp, out)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7fc2449",
   "metadata": {},
   "source": [
    "### Saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3518825a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _safe_load_best(study):\n",
    "    \"\"\"\n",
    "    Carga robusta: si el best_trial no tiene los nuevos user_attrs (arch, seq_len_used, n_feat),\n",
    "    los infiere desde study_name / ruta del checkpoint / params del trial.\n",
    "    Reconstruye la arquitectura y carga PESOS (.weights.h5 o .keras/.h5 legacy).\n",
    "    \"\"\"\n",
    "    ua = dict(study.best_trial.user_attrs) if study.best_trial.user_attrs else {}\n",
    "\n",
    "    # 1) Localiza el checkpoint\n",
    "    wpath = None\n",
    "    if \"model_path\" in ua:\n",
    "        p = Path(ua[\"model_path\"])\n",
    "        if p.exists():\n",
    "            wpath = p\n",
    "        else:\n",
    "            hits = list(ART_DIR.rglob(p.name))\n",
    "            if hits:\n",
    "                wpath = hits[0]\n",
    "    if wpath is None:\n",
    "        # Fallback: deduce por nombre de estudio\n",
    "        # Busca archivos 'best.weights.h5' o 'best.keras' en ART_DIR que coincidan con el estudio\n",
    "        patt = []\n",
    "        name = (study.study_name or \"\").lower()\n",
    "        if \"mlp\" in name: patt.append(\"A_mlp_*\")\n",
    "        if \"lstm\" in name and \"bilstm\" not in name: patt.append(\"B_lstm_*\")\n",
    "        if \"bilstm\" in name: patt.append(\"B_bilstm_*\")\n",
    "        if \"cnn\" in name: patt.append(\"B_cnnlstm_*\")\n",
    "        if \"transformer\" in name: patt.append(\"B_transformer_*\")\n",
    "        candidates = []\n",
    "        for pat in (patt or [\"*\"]):\n",
    "            candidates += list(ART_DIR.glob(f\"{pat}/best.weights.h5\"))\n",
    "            candidates += list(ART_DIR.glob(f\"{pat}/best.keras\"))\n",
    "            candidates += list(ART_DIR.glob(f\"{pat}/best.h5\"))\n",
    "        if not candidates:\n",
    "            raise FileNotFoundError(\"No checkpoint found for best trial and no user_attrs['model_path'].\")\n",
    "        # Toma el más reciente\n",
    "        wpath = max(candidates, key=lambda p: p.stat().st_mtime)\n",
    "\n",
    "    # 2) Deducir 'arch'\n",
    "    arch = ua.get(\"arch\")\n",
    "    base = wpath.parent.name.lower()\n",
    "    sname = (study.study_name or \"\").lower()\n",
    "    if arch is None:\n",
    "        if \"mlp\" in sname or base.startswith(\"a_mlp\"):\n",
    "            arch = \"mlp\"\n",
    "        elif \"bilstm\" in sname or \"b_bilstm\" in base:\n",
    "            arch = \"bilstm\"\n",
    "        elif (\"lstm\" in sname and \"bilstm\" not in sname) or \"b_lstm\" in base:\n",
    "            arch = \"lstm\"\n",
    "        elif \"cnn\" in sname or \"cnn\" in base:\n",
    "            arch = \"cnn-lstm\"\n",
    "        elif \"transformer\" in sname or \"transformer\" in base:\n",
    "            arch = \"transformer\"\n",
    "        else:\n",
    "            raise KeyError(\"Cannot infer 'arch' from study; please re-run trials or set user_attrs.\")\n",
    "\n",
    "    # 3) Deducir L y n_feat para secuenciales\n",
    "    params = study.best_trial.params\n",
    "    L = ua.get(\"seq_len_used\") or params.get(\"seq_len\")\n",
    "    n_feat = ua.get(\"n_feat\")\n",
    "    if arch != \"mlp\":\n",
    "        if L is None:\n",
    "            # default razonable si faltara\n",
    "            L = 12\n",
    "        if n_feat is None:\n",
    "            # usar el contexto global ya cargado\n",
    "            n_feat = int(Xtr_s.shape[1])\n",
    "\n",
    "    # 4) Reconstruye modelo y carga pesos / modelo\n",
    "    # (acepta tanto weights-only como modelo completo legacy)\n",
    "    if wpath.suffix in {\".keras\", \".h5\"} and \"weights\" not in wpath.name:\n",
    "        # Legacy: modelo completo; cargar con safe_mode desactivado SOLO si confías en el archivo\n",
    "        import keras\n",
    "        try:\n",
    "            keras.config.enable_unsafe_deserialization()\n",
    "        except Exception:\n",
    "            pass\n",
    "        model = tf.keras.models.load_model(wpath, compile=False, safe_mode=False)\n",
    "        model.compile(optimizer=\"adam\", loss=\"mse\", metrics=[\"mae\"])\n",
    "        return model, wpath\n",
    "\n",
    "    # Weights-only (recomendado)\n",
    "    if arch == \"mlp\":\n",
    "        model = build_mlp(\n",
    "            input_dim=Xtr.shape[1],\n",
    "            n1=params.get(\"n1\",128),\n",
    "            n2=params.get(\"n2\",64),\n",
    "            do1=params.get(\"do1\",0.0),\n",
    "            do2=params.get(\"do2\",0.0),\n",
    "            act=params.get(\"act\",\"relu\"),\n",
    "            l2w=params.get(\"l2\",0.0),\n",
    "        )\n",
    "    elif arch == \"lstm\":\n",
    "        model = build_lstm(int(L), int(n_feat),\n",
    "                           units=params.get(\"units\",64),\n",
    "                           do=params.get(\"dropout\",0.0))\n",
    "    elif arch == \"bilstm\":\n",
    "        model = build_bilstm(int(L), int(n_feat),\n",
    "                             units=params.get(\"units\",64),\n",
    "                             do=params.get(\"dropout\",0.0))\n",
    "    elif arch == \"cnn-lstm\":\n",
    "        model = build_cnnlstm(int(L), int(n_feat),\n",
    "                              filt=params.get(\"filters\",32),\n",
    "                              ksz=params.get(\"kernel_size\",3),\n",
    "                              pool=params.get(\"pool\",1),\n",
    "                              lstm_units=params.get(\"lstm_units\",64),\n",
    "                              do=params.get(\"dropout\",0.0))\n",
    "    elif arch == \"transformer\":\n",
    "        model = build_transformer(int(L), int(n_feat),\n",
    "                                  d_model=params.get(\"d_model\",64),\n",
    "                                  heads=params.get(\"heads\",4),\n",
    "                                  ff_dim=params.get(\"ff_dim\",128),\n",
    "                                  att_do=params.get(\"att_dropout\",0.1),\n",
    "                                  do=params.get(\"dropout\",0.0))\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown arch: {arch}\")\n",
    "\n",
    "    model.compile(optimizer=\"adam\", loss=\"mse\", metrics=[\"mae\"])\n",
    "    model.load_weights(str(wpath))\n",
    "    return model, wpath\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd38d785",
   "metadata": {},
   "source": [
    "## Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1d7b3333",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline → RMSE: 196.2835 | MAE: 102.1871\n"
     ]
    }
   ],
   "source": [
    "base_src = None\n",
    "\n",
    "# for c in [\"k_ghi\",\"k_raw\",\"k_ghi_lag1\",\"k_raw_lag1\"]:\n",
    "#     if c in test.columns: base_src = test[c]; break\n",
    "# if base_src is None:\n",
    "#     base_src = pd.Series(np.nanmedian(ytr), index=test.index)\n",
    "\n",
    "for c in [\"ghi_qc\",\"ghi_sg_definitive\",\"ghi_qc_lag1\"]:\n",
    "    if c in test.columns: base_src = test[c]; break\n",
    "if base_src is None:\n",
    "    base_src = pd.Series(np.nanmedian(ytr), index=test.index)\n",
    "\n",
    "y_base = base_src.to_numpy()\n",
    "print(f\"Baseline → RMSE: {_rmse(yte, y_base):.4f} | MAE: {mean_absolute_error(yte, y_base):.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b684d0e0",
   "metadata": {},
   "source": [
    "## Track A - MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a2285184",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_mlp(trial: optuna.Trial) -> float:\n",
    "    K.clear_session()\n",
    "    n1  = trial.suggest_int(\"n1\", 64, 512, step=64)\n",
    "    n2  = trial.suggest_int(\"n2\", 32, max(64, n1//2), step=32)\n",
    "    do1 = trial.suggest_float(\"do1\", 0.0, 0.5)\n",
    "    do2 = trial.suggest_float(\"do2\", 0.0, 0.5)\n",
    "    lr  = trial.suggest_float(\"lr\", 1e-4, 5e-3, log=True)\n",
    "    l2w = trial.suggest_float(\"l2\", 1e-8, 1e-3, log=True)\n",
    "    act = trial.suggest_categorical(\"act\", [\"relu\",\"selu\",\"gelu\"])\n",
    "    bs  = trial.suggest_categorical(\"batch\", [64, 128, 256, 512])\n",
    "    eps = trial.suggest_int(\"epochs\", 40, 150)\n",
    "\n",
    "    model = build_mlp(Xtr.shape[1], n1=n1, n2=n2, do1=do1, do2=do2, act=act, l2w=l2w)\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=lr),\n",
    "                  loss=\"mse\", metrics=[\"mae\"])\n",
    "\n",
    "    tmp_dir  = ART_DIR / f\"A_mlp_t{trial.number:04d}\"; tmp_dir.mkdir(parents=True, exist_ok=True)\n",
    "    tmp_path = (tmp_dir / \"best.weights.h5\").resolve()\n",
    "\n",
    "    cbs = [\n",
    "        callbacks.EarlyStopping(monitor=\"val_loss\", patience=12, restore_best_weights=True, verbose=0),\n",
    "        callbacks.ReduceLROnPlateau(monitor=\"val_loss\", factor=0.5, patience=6, min_lr=1e-5, verbose=0),\n",
    "        callbacks.ModelCheckpoint(filepath=str(tmp_path), monitor=\"val_loss\",\n",
    "                                  save_best_only=True, save_weights_only=True),\n",
    "        TFKerasPruningCallback(trial, \"val_loss\"),\n",
    "    ]\n",
    "\n",
    "    model.fit(Xtr, ytr, validation_data=(Xva, yva),\n",
    "              epochs=eps, batch_size=bs, verbose=0, callbacks=cbs)\n",
    "\n",
    "    yhat = model.predict(Xva, verbose=0).squeeze()\n",
    "    val_rmse = _rmse(yva, yhat)\n",
    "\n",
    "    trial.set_user_attr(\"model_path\", str(tmp_path))\n",
    "    trial.set_user_attr(\"arch\", \"mlp\")\n",
    "    trial.set_user_attr(\"input_dim\", Xtr.shape[1])\n",
    "    return val_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fb7a4566",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_235179/3240221310.py:36: FutureWarning: The import path :class:`~optuna.storages.JournalFileOpenLock` has been deprecated in v4.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v4.0.0. Use :class:`~optuna.storages.journal.JournalFileOpenLock` instead.\n",
      "  file_storage = JournalFileStorage(str(log_path), lock_obj=JournalFileOpenLock(str(lock_path)))\n",
      "/tmp/ipykernel_235179/3240221310.py:36: FutureWarning: JournalFileStorage has been deprecated in v4.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v4.0.0. Use :class:`~optuna.storages.journal.JournalFileBackend` instead.\n",
      "  file_storage = JournalFileStorage(str(log_path), lock_obj=JournalFileOpenLock(str(lock_path)))\n",
      "[I 2025-10-01 16:09:09,343] Using an existing study with name 'ground_trackA_mlp' instead of creating a new one.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Study A (MLP)…\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe0203fe548240ffae7ba950ada797bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1759352950.458305  235344 service.cc:148] XLA service 0x709390006d70 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1759352950.458334  235344 service.cc:156]   StreamExecutor device (0): NVIDIA GeForce RTX 4090, Compute Capability 8.9\n",
      "2025-10-01 16:09:10.469895: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "I0000 00:00:1759352950.512878  235344 cuda_dnn.cc:529] Loaded cuDNN version 90101\n",
      "I0000 00:00:1759352950.965818  235344 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-01 16:09:13,723] Trial 280 pruned. Trial was pruned at epoch 6.\n",
      "[I 2025-10-01 16:09:17,003] Trial 281 pruned. Trial was pruned at epoch 7.\n",
      "[I 2025-10-01 16:09:20,609] Trial 282 pruned. Trial was pruned at epoch 5.\n",
      "[I 2025-10-01 16:09:24,219] Trial 283 pruned. Trial was pruned at epoch 5.\n",
      "[I 2025-10-01 16:09:27,293] Trial 284 pruned. Trial was pruned at epoch 5.\n",
      "[I 2025-10-01 16:09:35,426] Trial 285 finished with value: 129.86142704581295 and parameters: {'n1': 320, 'n2': 128, 'do1': 0.47684926882088585, 'do2': 0.06391216214132003, 'lr': 0.0025884469649539122, 'l2': 5.684619701688143e-05, 'act': 'gelu', 'batch': 512, 'epochs': 120}. Best is trial 178 with value: 129.60320302513747.\n",
      "[I 2025-10-01 16:09:38,467] Trial 286 pruned. Trial was pruned at epoch 5.\n",
      "[I 2025-10-01 16:09:41,848] Trial 287 pruned. Trial was pruned at epoch 6.\n",
      "[I 2025-10-01 16:09:45,352] Trial 288 pruned. Trial was pruned at epoch 6.\n",
      "[I 2025-10-01 16:09:48,721] Trial 289 pruned. Trial was pruned at epoch 5.\n",
      "[I 2025-10-01 16:09:55,711] Trial 290 pruned. Trial was pruned at epoch 7.\n",
      "[I 2025-10-01 16:09:58,910] Trial 291 pruned. Trial was pruned at epoch 5.\n",
      "[I 2025-10-01 16:10:02,511] Trial 292 pruned. Trial was pruned at epoch 6.\n",
      "[I 2025-10-01 16:10:06,320] Trial 293 pruned. Trial was pruned at epoch 5.\n",
      "[I 2025-10-01 16:10:09,990] Trial 294 pruned. Trial was pruned at epoch 5.\n",
      "[I 2025-10-01 16:10:19,326] Trial 295 finished with value: 129.83381054014782 and parameters: {'n1': 512, 'n2': 160, 'do1': 0.4768764550858372, 'do2': 0.15308914549221084, 'lr': 0.0025295043753648223, 'l2': 0.0009972560702974662, 'act': 'gelu', 'batch': 512, 'epochs': 116}. Best is trial 178 with value: 129.60320302513747.\n",
      "[I 2025-10-01 16:10:27,948] Trial 296 finished with value: 129.7919383691645 and parameters: {'n1': 512, 'n2': 160, 'do1': 0.4768575369599301, 'do2': 0.16012991651531777, 'lr': 0.0025123319640042927, 'l2': 0.0008253861077749432, 'act': 'gelu', 'batch': 512, 'epochs': 116}. Best is trial 178 with value: 129.60320302513747.\n",
      "[I 2025-10-01 16:10:39,168] Trial 297 finished with value: 129.88633101437193 and parameters: {'n1': 512, 'n2': 160, 'do1': 0.48264239025023314, 'do2': 0.1601391044930645, 'lr': 0.002604005168071231, 'l2': 0.0008697032679375169, 'act': 'gelu', 'batch': 512, 'epochs': 117}. Best is trial 178 with value: 129.60320302513747.\n",
      "[I 2025-10-01 16:10:49,851] Trial 298 finished with value: 129.74863017099642 and parameters: {'n1': 512, 'n2': 160, 'do1': 0.4740111696609452, 'do2': 0.16039782565088984, 'lr': 0.0021493571091697793, 'l2': 0.0008503899443318286, 'act': 'gelu', 'batch': 512, 'epochs': 115}. Best is trial 178 with value: 129.60320302513747.\n",
      "[I 2025-10-01 16:10:59,237] Trial 299 finished with value: 129.96042817190548 and parameters: {'n1': 512, 'n2': 160, 'do1': 0.4771820766445218, 'do2': 0.15410090254607225, 'lr': 0.002116918149904112, 'l2': 0.0009761595689975393, 'act': 'gelu', 'batch': 512, 'epochs': 115}. Best is trial 178 with value: 129.60320302513747.\n",
      "[I 2025-10-01 16:11:03,154] Trial 300 pruned. Trial was pruned at epoch 7.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-01 16:11:05.363505: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_48_0', 768 bytes spill stores, 720 bytes spill loads\n",
      "\n",
      "2025-10-01 16:11:05.982140: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_48_0', 756 bytes spill stores, 444 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-01 16:11:07,829] Trial 301 pruned. Trial was pruned at epoch 5.\n",
      "[I 2025-10-01 16:11:18,792] Trial 302 finished with value: 129.8895564508556 and parameters: {'n1': 512, 'n2': 160, 'do1': 0.4824553672347597, 'do2': 0.16078367445403463, 'lr': 0.0023362957235692474, 'l2': 0.0007503624944386232, 'act': 'gelu', 'batch': 512, 'epochs': 115}. Best is trial 178 with value: 129.60320302513747.\n",
      "[I 2025-10-01 16:11:23,388] Trial 303 pruned. Trial was pruned at epoch 9.\n",
      "[I 2025-10-01 16:11:32,465] Trial 304 finished with value: 129.85316978466486 and parameters: {'n1': 512, 'n2': 160, 'do1': 0.46406590166368256, 'do2': 0.17227965638112092, 'lr': 0.0024886303889480195, 'l2': 0.0007386831172570987, 'act': 'gelu', 'batch': 512, 'epochs': 118}. Best is trial 178 with value: 129.60320302513747.\n",
      "[I 2025-10-01 16:11:41,479] Trial 305 finished with value: 129.8731352127914 and parameters: {'n1': 512, 'n2': 160, 'do1': 0.48587962568621357, 'do2': 0.14629677922275236, 'lr': 0.0022411093810283216, 'l2': 0.0009970977267408944, 'act': 'gelu', 'batch': 512, 'epochs': 113}. Best is trial 178 with value: 129.60320302513747.\n",
      "[I 2025-10-01 16:11:51,517] Trial 306 finished with value: 129.94179135530263 and parameters: {'n1': 512, 'n2': 256, 'do1': 0.47156932800540197, 'do2': 0.13761389405675928, 'lr': 0.002490202960202108, 'l2': 0.0005916227071850799, 'act': 'gelu', 'batch': 512, 'epochs': 116}. Best is trial 178 with value: 129.60320302513747.\n",
      "[I 2025-10-01 16:11:58,728] Trial 307 pruned. Trial was pruned at epoch 12.\n",
      "[I 2025-10-01 16:12:10,651] Trial 308 finished with value: 129.72711744273053 and parameters: {'n1': 512, 'n2': 160, 'do1': 0.4985787942216098, 'do2': 0.15439597796165738, 'lr': 0.002690477225828144, 'l2': 0.0006677296266638917, 'act': 'gelu', 'batch': 512, 'epochs': 119}. Best is trial 178 with value: 129.60320302513747.\n",
      "[I 2025-10-01 16:12:18,989] Trial 309 finished with value: 129.88491751113753 and parameters: {'n1': 512, 'n2': 160, 'do1': 0.4888955140442428, 'do2': 0.1566856654641613, 'lr': 0.002650486668890463, 'l2': 0.0005512118303022749, 'act': 'gelu', 'batch': 512, 'epochs': 118}. Best is trial 178 with value: 129.60320302513747.\n",
      "[I 2025-10-01 16:12:22,415] Trial 310 pruned. Trial was pruned at epoch 5.\n",
      "[I 2025-10-01 16:12:27,504] Trial 311 pruned. Trial was pruned at epoch 11.\n",
      "[I 2025-10-01 16:12:31,291] Trial 312 pruned. Trial was pruned at epoch 5.\n",
      "[I 2025-10-01 16:12:35,161] Trial 313 pruned. Trial was pruned at epoch 5.\n",
      "[I 2025-10-01 16:12:45,285] Trial 314 finished with value: 129.724241783292 and parameters: {'n1': 512, 'n2': 160, 'do1': 0.47583660939477523, 'do2': 0.14108728784055444, 'lr': 0.0022663228166482753, 'l2': 0.0005110831044186833, 'act': 'gelu', 'batch': 512, 'epochs': 111}. Best is trial 178 with value: 129.60320302513747.\n",
      "[I 2025-10-01 16:12:55,088] Trial 315 finished with value: 129.9035850400211 and parameters: {'n1': 512, 'n2': 160, 'do1': 0.47863724193618523, 'do2': 0.13388156660458297, 'lr': 0.0022855227462072517, 'l2': 0.00029131761602260947, 'act': 'gelu', 'batch': 512, 'epochs': 112}. Best is trial 178 with value: 129.60320302513747.\n",
      "[I 2025-10-01 16:13:03,537] Trial 316 finished with value: 130.0008112955454 and parameters: {'n1': 512, 'n2': 160, 'do1': 0.4911275358037213, 'do2': 0.13709052733648905, 'lr': 0.002294523267583769, 'l2': 0.00044503279767824945, 'act': 'gelu', 'batch': 512, 'epochs': 110}. Best is trial 178 with value: 129.60320302513747.\n",
      "[I 2025-10-01 16:13:12,679] Trial 317 finished with value: 129.86148720608045 and parameters: {'n1': 512, 'n2': 160, 'do1': 0.4756348498890727, 'do2': 0.1461909616088914, 'lr': 0.0019264465917601837, 'l2': 0.0005391042541309345, 'act': 'gelu', 'batch': 512, 'epochs': 114}. Best is trial 178 with value: 129.60320302513747.\n",
      "[I 2025-10-01 16:13:22,438] Trial 318 finished with value: 129.940325847098 and parameters: {'n1': 512, 'n2': 160, 'do1': 0.4769981677363205, 'do2': 0.1479765173718674, 'lr': 0.002100859823342814, 'l2': 3.5722169993270363e-05, 'act': 'gelu', 'batch': 512, 'epochs': 116}. Best is trial 178 with value: 129.60320302513747.\n",
      "[I 2025-10-01 16:13:33,206] Trial 319 finished with value: 129.85122947771808 and parameters: {'n1': 512, 'n2': 160, 'do1': 0.49217291810782143, 'do2': 0.16210509950249588, 'lr': 0.0023897545707521903, 'l2': 1.9592632767700218e-05, 'act': 'gelu', 'batch': 512, 'epochs': 120}. Best is trial 178 with value: 129.60320302513747.\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'arch'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 10\u001b[39m\n\u001b[32m      7\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mRunning Study A (MLP)…\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      8\u001b[39m studyA.optimize(objective_mlp, n_trials=\u001b[32m40\u001b[39m, show_progress_bar=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m best_mlp, bestA_path = \u001b[43m_safe_load_best\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudyA\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     11\u001b[39m yhatA = best_mlp.predict(Xte, verbose=\u001b[32m0\u001b[39m).squeeze()\n\u001b[32m     12\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mBest MLP params:\u001b[39m\u001b[33m\"\u001b[39m, studyA.best_trial.params)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 10\u001b[39m, in \u001b[36m_safe_load_best\u001b[39m\u001b[34m(study)\u001b[39m\n\u001b[32m      7\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m hits: wpath = hits[\u001b[32m0\u001b[39m]\n\u001b[32m      8\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m: \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mCheckpoint not found: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mwpath\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m arch = \u001b[43mua\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43march\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[32m     11\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m arch == \u001b[33m\"\u001b[39m\u001b[33mmlp\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m     12\u001b[39m     model = build_mlp(ua[\u001b[33m\"\u001b[39m\u001b[33minput_dim\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m     13\u001b[39m                       n1=study.best_trial.params.get(\u001b[33m\"\u001b[39m\u001b[33mn1\u001b[39m\u001b[33m\"\u001b[39m,\u001b[32m128\u001b[39m),\n\u001b[32m     14\u001b[39m                       n2=study.best_trial.params.get(\u001b[33m\"\u001b[39m\u001b[33mn2\u001b[39m\u001b[33m\"\u001b[39m,\u001b[32m64\u001b[39m),\n\u001b[32m   (...)\u001b[39m\u001b[32m     17\u001b[39m                       act=study.best_trial.params.get(\u001b[33m\"\u001b[39m\u001b[33mact\u001b[39m\u001b[33m\"\u001b[39m,\u001b[33m\"\u001b[39m\u001b[33mrelu\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m     18\u001b[39m                       l2w=study.best_trial.params.get(\u001b[33m\"\u001b[39m\u001b[33ml2\u001b[39m\u001b[33m\"\u001b[39m,\u001b[32m0.0\u001b[39m))\n",
      "\u001b[31mKeyError\u001b[39m: 'arch'"
     ]
    }
   ],
   "source": [
    "storageA = prepare_journal_storage(\"ground_trackA_mlp\")\n",
    "studyA = optuna.create_study(direction=\"minimize\",\n",
    "                             sampler=TPESampler(seed=SEED),\n",
    "                             pruner=MedianPruner(n_startup_trials=8, n_warmup_steps=5),\n",
    "                             study_name=\"ground_trackA_mlp\",\n",
    "                             storage=storageA, load_if_exists=True)\n",
    "print(\"Running Study A (MLP)…\")\n",
    "studyA.optimize(objective_mlp, n_trials=40, show_progress_bar=True)\n",
    "\n",
    "best_mlp, bestA_path = _safe_load_best(studyA)\n",
    "yhatA = best_mlp.predict(Xte, verbose=0).squeeze()\n",
    "print(\"Best MLP params:\", studyA.best_trial.params)\n",
    "print(f\"MLP test → RMSE: {_rmse(yte, yhatA):.4f} | MAE: {mean_absolute_error(yte, yhatA):.4f} | R2: {r2_score(yte, yhatA):.4f} | Skill: {skill(yte, yhatA, y_base):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccd9c63c",
   "metadata": {},
   "source": [
    "## Track B - Sequentials"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "185cbc5c",
   "metadata": {},
   "source": [
    "### Mods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b89bcd3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtr_s = pd.DataFrame(Xtr, index=Xtr_df.index, columns=feat_cols)\n",
    "Xva_s = pd.DataFrame(Xva, index=Xva_df.index, columns=feat_cols)\n",
    "Xte_s = pd.DataFrame(Xte, index=Xte_df.index, columns=feat_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ebeef5d",
   "metadata": {},
   "source": [
    "### LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "392c9a2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_lstm(trial: optuna.Trial) -> float:\n",
    "    K.clear_session()\n",
    "    L   = trial.suggest_categorical(\"seq_len\", [6, 12, 18, 24])\n",
    "    u   = trial.suggest_int(\"units\", 32, 128, step=32)\n",
    "    do  = trial.suggest_float(\"dropout\", 0.0, 0.4)\n",
    "    lr  = trial.suggest_float(\"lr\", 5e-5, 5e-3, log=True)\n",
    "    bs  = trial.suggest_categorical(\"batch\", [64, 128, 256])\n",
    "    eps = trial.suggest_int(\"epochs\", 40, 120)\n",
    "\n",
    "    Xtr_seq, ytr_seq = _build_seq(Xtr_s, ytr, L)\n",
    "    Xva_seq, yva_seq = _build_seq(Xva_s, yva, L)\n",
    "    if min(map(len,[Xtr_seq, Xva_seq])) == 0:\n",
    "        raise optuna.TrialPruned()\n",
    "\n",
    "    model = build_lstm(L, Xtr_seq.shape[2], units=u, do=do)\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=lr), loss=\"mse\", metrics=[\"mae\"])\n",
    "\n",
    "    tmp_dir  = ART_DIR / f\"B_lstm_t{trial.number:04d}\"; tmp_dir.mkdir(parents=True, exist_ok=True)\n",
    "    tmp_path = (tmp_dir / \"best.weights.h5\").resolve()\n",
    "\n",
    "    cbs = [\n",
    "        callbacks.EarlyStopping(monitor=\"val_loss\", patience=10, restore_best_weights=True, verbose=0),\n",
    "        callbacks.ModelCheckpoint(filepath=str(tmp_path), monitor=\"val_loss\",\n",
    "                                  save_best_only=True, save_weights_only=True),\n",
    "        TFKerasPruningCallback(trial, \"val_loss\"),\n",
    "    ]\n",
    "    model.fit(Xtr_seq, ytr_seq, validation_data=(Xva_seq, yva_seq),\n",
    "              epochs=eps, batch_size=bs, verbose=0, callbacks=cbs)\n",
    "\n",
    "    yhat = model.predict(Xva_seq, verbose=0).squeeze()\n",
    "    val_rmse = _rmse(yva_seq, yhat)\n",
    "\n",
    "    trial.set_user_attr(\"model_path\", str(tmp_path))\n",
    "    trial.set_user_attr(\"arch\", \"lstm\")\n",
    "    trial.set_user_attr(\"seq_len_used\", L)\n",
    "    trial.set_user_attr(\"n_feat\", Xtr_s.shape[1])\n",
    "    return val_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6777b424",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_23508/3401579257.py:37: FutureWarning: The import path :class:`~optuna.storages.JournalFileOpenLock` has been deprecated in v4.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v4.0.0. Use :class:`~optuna.storages.journal.JournalFileOpenLock` instead.\n",
      "  file_storage = JournalFileStorage(str(log_path), lock_obj=JournalFileOpenLock(str(lock_path)))\n",
      "/tmp/ipykernel_23508/3401579257.py:37: FutureWarning: JournalFileStorage has been deprecated in v4.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v4.0.0. Use :class:`~optuna.storages.journal.JournalFileBackend` instead.\n",
      "  file_storage = JournalFileStorage(str(log_path), lock_obj=JournalFileOpenLock(str(lock_path)))\n",
      "[I 2025-10-01 11:47:45,330] Using an existing study with name 'ground_trackB_lstm' instead of creating a new one.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Study B1 (LSTM)…\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1fe90d59fca34335a87b505fb524aad2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-01 11:48:12,438] Trial 200 finished with value: 130.18653984283475 and parameters: {'seq_len': 18, 'units': 128, 'dropout': 0.1172490103060074, 'lr': 0.003043678318589167, 'batch': 64, 'epochs': 109}. Best is trial 76 with value: 129.32426541449985.\n",
      "[I 2025-10-01 11:48:36,942] Trial 201 finished with value: 130.56615002078448 and parameters: {'seq_len': 18, 'units': 128, 'dropout': 0.07232375907229845, 'lr': 0.004969705820928518, 'batch': 64, 'epochs': 49}. Best is trial 76 with value: 129.32426541449985.\n",
      "[I 2025-10-01 11:49:01,846] Trial 202 finished with value: 130.27167376054933 and parameters: {'seq_len': 18, 'units': 128, 'dropout': 0.07003913433717746, 'lr': 0.004524343692476639, 'batch': 64, 'epochs': 51}. Best is trial 76 with value: 129.32426541449985.\n",
      "[I 2025-10-01 11:49:26,999] Trial 203 finished with value: 130.69040677063867 and parameters: {'seq_len': 18, 'units': 128, 'dropout': 0.08289988847687813, 'lr': 0.0049973777287680024, 'batch': 64, 'epochs': 49}. Best is trial 76 with value: 129.32426541449985.\n",
      "[I 2025-10-01 11:49:54,837] Trial 204 finished with value: 130.24230723443898 and parameters: {'seq_len': 18, 'units': 128, 'dropout': 0.09087525550641128, 'lr': 0.004547835975844108, 'batch': 64, 'epochs': 40}. Best is trial 76 with value: 129.32426541449985.\n",
      "[I 2025-10-01 11:50:31,866] Trial 205 finished with value: 130.4003076467805 and parameters: {'seq_len': 18, 'units': 128, 'dropout': 0.25279642360148463, 'lr': 0.003680825070029247, 'batch': 64, 'epochs': 58}. Best is trial 76 with value: 129.32426541449985.\n",
      "[I 2025-10-01 11:50:58,898] Trial 206 finished with value: 130.28817968497756 and parameters: {'seq_len': 18, 'units': 128, 'dropout': 0.2020327636501295, 'lr': 0.004066860517499892, 'batch': 64, 'epochs': 55}. Best is trial 76 with value: 129.32426541449985.\n",
      "[I 2025-10-01 11:51:27,453] Trial 207 finished with value: 130.23577627470496 and parameters: {'seq_len': 18, 'units': 128, 'dropout': 0.10555896853357075, 'lr': 0.0027103228537707614, 'batch': 64, 'epochs': 44}. Best is trial 76 with value: 129.32426541449985.\n",
      "[I 2025-10-01 11:51:38,583] Trial 208 pruned. Trial was pruned at epoch 5.\n",
      "[I 2025-10-01 11:52:02,886] Trial 209 finished with value: 129.78907919437984 and parameters: {'seq_len': 18, 'units': 128, 'dropout': 0.07288055241691967, 'lr': 0.004595988584217625, 'batch': 64, 'epochs': 106}. Best is trial 76 with value: 129.32426541449985.\n",
      "[I 2025-10-01 11:52:14,028] Trial 210 pruned. Trial was pruned at epoch 5.\n",
      "[I 2025-10-01 11:52:36,403] Trial 211 finished with value: 130.18491956156058 and parameters: {'seq_len': 18, 'units': 128, 'dropout': 0.07300892659902093, 'lr': 0.0045530432159282454, 'batch': 64, 'epochs': 108}. Best is trial 76 with value: 129.32426541449985.\n",
      "[I 2025-10-01 11:52:47,466] Trial 212 pruned. Trial was pruned at epoch 6.\n",
      "[I 2025-10-01 11:52:58,214] Trial 213 pruned. Trial was pruned at epoch 5.\n",
      "[I 2025-10-01 11:53:30,945] Trial 214 finished with value: 130.20409159757614 and parameters: {'seq_len': 18, 'units': 128, 'dropout': 0.08308270199072362, 'lr': 0.003781135690355278, 'batch': 64, 'epochs': 98}. Best is trial 76 with value: 129.32426541449985.\n",
      "[I 2025-10-01 11:53:42,206] Trial 215 pruned. Trial was pruned at epoch 6.\n",
      "[I 2025-10-01 11:54:07,662] Trial 216 finished with value: 129.9397922476983 and parameters: {'seq_len': 18, 'units': 128, 'dropout': 0.05746055580793192, 'lr': 0.003516923146872391, 'batch': 64, 'epochs': 88}. Best is trial 76 with value: 129.32426541449985.\n",
      "[I 2025-10-01 11:54:16,836] Trial 217 pruned. Trial was pruned at epoch 5.\n",
      "[I 2025-10-01 11:54:40,977] Trial 218 finished with value: 130.62259268116676 and parameters: {'seq_len': 18, 'units': 128, 'dropout': 0.09885590428623697, 'lr': 0.0049828663674229105, 'batch': 64, 'epochs': 100}. Best is trial 76 with value: 129.32426541449985.\n",
      "[I 2025-10-01 11:55:07,983] Trial 219 finished with value: 130.54527321728276 and parameters: {'seq_len': 18, 'units': 128, 'dropout': 0.06688140728527846, 'lr': 0.004580665888894257, 'batch': 64, 'epochs': 95}. Best is trial 76 with value: 129.32426541449985.\n",
      "[I 2025-10-01 11:55:37,740] Trial 220 finished with value: 130.26632875094776 and parameters: {'seq_len': 18, 'units': 128, 'dropout': 0.11029865889766453, 'lr': 0.002167061348763711, 'batch': 64, 'epochs': 46}. Best is trial 76 with value: 129.32426541449985.\n",
      "[I 2025-10-01 11:56:03,345] Trial 221 finished with value: 130.50270142079435 and parameters: {'seq_len': 18, 'units': 128, 'dropout': 0.09061477057054057, 'lr': 0.0024195444975186617, 'batch': 64, 'epochs': 86}. Best is trial 76 with value: 129.32426541449985.\n",
      "[I 2025-10-01 11:56:30,017] Trial 222 finished with value: 130.19275073424788 and parameters: {'seq_len': 18, 'units': 128, 'dropout': 0.09786150470993757, 'lr': 0.00266094595571985, 'batch': 64, 'epochs': 103}. Best is trial 76 with value: 129.32426541449985.\n",
      "[I 2025-10-01 11:56:39,889] Trial 223 pruned. Trial was pruned at epoch 5.\n",
      "[I 2025-10-01 11:57:07,245] Trial 224 finished with value: 130.1813338674174 and parameters: {'seq_len': 18, 'units': 128, 'dropout': 0.08872423785275847, 'lr': 0.0028425553620901552, 'batch': 64, 'epochs': 87}. Best is trial 76 with value: 129.32426541449985.\n",
      "[I 2025-10-01 11:57:30,604] Trial 225 finished with value: 130.48785414024172 and parameters: {'seq_len': 18, 'units': 128, 'dropout': 0.10189634840029421, 'lr': 0.0039061580387479895, 'batch': 64, 'epochs': 80}. Best is trial 76 with value: 129.32426541449985.\n",
      "[I 2025-10-01 11:57:40,680] Trial 226 pruned. Trial was pruned at epoch 5.\n",
      "[I 2025-10-01 11:57:50,687] Trial 227 pruned. Trial was pruned at epoch 5.\n",
      "[I 2025-10-01 11:58:18,864] Trial 228 finished with value: 129.5591458200655 and parameters: {'seq_len': 18, 'units': 128, 'dropout': 0.10788027357617781, 'lr': 0.004466978718509781, 'batch': 64, 'epochs': 83}. Best is trial 76 with value: 129.32426541449985.\n",
      "[I 2025-10-01 11:58:42,780] Trial 229 finished with value: 130.67284560353386 and parameters: {'seq_len': 18, 'units': 128, 'dropout': 0.11161128641171407, 'lr': 0.004337637477605068, 'batch': 64, 'epochs': 84}. Best is trial 76 with value: 129.32426541449985.\n",
      "[I 2025-10-01 11:59:06,749] Trial 230 finished with value: 130.1744397553721 and parameters: {'seq_len': 18, 'units': 128, 'dropout': 0.12514586449092213, 'lr': 0.004967162276996471, 'batch': 64, 'epochs': 82}. Best is trial 76 with value: 129.32426541449985.\n",
      "[I 2025-10-01 11:59:33,285] Trial 231 finished with value: 129.76441995978712 and parameters: {'seq_len': 18, 'units': 128, 'dropout': 0.10553529249682668, 'lr': 0.0045195484860877195, 'batch': 64, 'epochs': 88}. Best is trial 76 with value: 129.32426541449985.\n",
      "[I 2025-10-01 12:00:02,067] Trial 232 finished with value: 130.28265545535982 and parameters: {'seq_len': 18, 'units': 128, 'dropout': 0.10454729885624449, 'lr': 0.004478317253156409, 'batch': 64, 'epochs': 88}. Best is trial 76 with value: 129.32426541449985.\n",
      "[I 2025-10-01 12:00:25,529] Trial 233 finished with value: 129.68994726606607 and parameters: {'seq_len': 18, 'units': 128, 'dropout': 0.11298113770941368, 'lr': 0.0039057090274685507, 'batch': 64, 'epochs': 93}. Best is trial 76 with value: 129.32426541449985.\n",
      "[I 2025-10-01 12:00:37,346] Trial 234 pruned. Trial was pruned at epoch 5.\n",
      "[I 2025-10-01 12:00:43,913] Trial 235 pruned. Trial was pruned at epoch 5.\n",
      "[I 2025-10-01 12:01:17,491] Trial 236 finished with value: 130.3354596080821 and parameters: {'seq_len': 18, 'units': 128, 'dropout': 0.10696306792091491, 'lr': 0.003952401393244927, 'batch': 64, 'epochs': 90}. Best is trial 76 with value: 129.32426541449985.\n",
      "[I 2025-10-01 12:01:29,520] Trial 237 pruned. Trial was pruned at epoch 5.\n",
      "[I 2025-10-01 12:01:36,213] Trial 238 pruned. Trial was pruned at epoch 5.\n",
      "[I 2025-10-01 12:02:04,973] Trial 239 finished with value: 130.6545794858527 and parameters: {'seq_len': 18, 'units': 128, 'dropout': 0.11392991527759258, 'lr': 0.0037128965318010475, 'batch': 64, 'epochs': 89}. Best is trial 76 with value: 129.32426541449985.\n",
      "Best LSTM params: {'seq_len': 18, 'units': 96, 'dropout': 0.10611697680405062, 'lr': 0.0036218877930872225, 'batch': 64, 'epochs': 89}\n",
      "LSTM test → RMSE: 137.7330 | MAE: 71.8965 | R2: 0.7142 | Skill: 0.299\n"
     ]
    }
   ],
   "source": [
    "storageB1 = prepare_journal_storage(\"ground_trackB_lstm\")\n",
    "studyB1 = optuna.create_study(direction=\"minimize\",\n",
    "                              sampler=TPESampler(seed=SEED),\n",
    "                              pruner=MedianPruner(n_startup_trials=8, n_warmup_steps=5),\n",
    "                              study_name=\"ground_trackB_lstm\",\n",
    "                              storage=storageB1, load_if_exists=True)\n",
    "print(\"Running Study B1 (LSTM)…\")\n",
    "studyB1.optimize(objective_lstm, n_trials=40, show_progress_bar=True)\n",
    "\n",
    "best_lstm, _ = _safe_load_best(studyB1)\n",
    "bestL1 = studyB1.best_trial.user_attrs[\"seq_len_used\"]\n",
    "Xte_seq, yte_seq, idx_LSTM = build_seq_with_idx(Xte_s, yte, bestL1)\n",
    "yhatB1 = best_lstm.predict(Xte_seq, verbose=0).squeeze()\n",
    "y_base_LSTM = pd.Series(y_base, index=Xte_df.index).reindex(idx_LSTM).to_numpy()\n",
    "print(\"Best LSTM params:\", studyB1.best_trial.params | {\"seq_len\": bestL1})\n",
    "print(f\"LSTM test → RMSE: {_rmse(yte_seq, yhatB1):.4f} | MAE: {mean_absolute_error(yte_seq, yhatB1):.4f} | R2: {r2_score(yte_seq, yhatB1):.4f} | Skill: {skill(yte_seq, yhatB1, y_base_LSTM):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "218b9bf3",
   "metadata": {},
   "source": [
    "### BiLSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1b34537",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_bilstm(trial: optuna.Trial) -> float:\n",
    "    K.clear_session()\n",
    "    L   = trial.suggest_categorical(\"seq_len\", [6, 12, 18, 24])\n",
    "    u   = trial.suggest_int(\"units\", 32, 128, step=32)\n",
    "    do  = trial.suggest_float(\"dropout\", 0.0, 0.4)\n",
    "    lr  = trial.suggest_float(\"lr\", 5e-5, 5e-3, log=True)\n",
    "    bs  = trial.suggest_categorical(\"batch\", [64, 128, 256])\n",
    "    eps = trial.suggest_int(\"epochs\", 40, 120)\n",
    "\n",
    "    Xtr_seq, ytr_seq = _build_seq(Xtr_s, ytr, L)\n",
    "    Xva_seq, yva_seq = _build_seq(Xva_s, yva, L)\n",
    "    if min(map(len,[Xtr_seq, Xva_seq])) == 0:\n",
    "        raise optuna.TrialPruned()\n",
    "\n",
    "    model = build_bilstm(L, Xtr_seq.shape[2], units=u, do=do)\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=lr), loss=\"mse\", metrics=[\"mae\"])\n",
    "\n",
    "    tmp_dir  = ART_DIR / f\"B_bilstm_t{trial.number:04d}\"; tmp_dir.mkdir(parents=True, exist_ok=True)\n",
    "    tmp_path = (tmp_dir / \"best.weights.h5\").resolve()\n",
    "\n",
    "    cbs = [\n",
    "        callbacks.EarlyStopping(monitor=\"val_loss\", patience=10, restore_best_weights=True, verbose=0),\n",
    "        callbacks.ModelCheckpoint(filepath=str(tmp_path), monitor=\"val_loss\",\n",
    "                                  save_best_only=True, save_weights_only=True),\n",
    "        TFKerasPruningCallback(trial, \"val_loss\"),\n",
    "    ]\n",
    "    model.fit(Xtr_seq, ytr_seq, validation_data=(Xva_seq, yva_seq),\n",
    "              epochs=eps, batch_size=bs, verbose=0, callbacks=cbs)\n",
    "\n",
    "    yhat = model.predict(Xva_seq, verbose=0).squeeze()\n",
    "    val_rmse = _rmse(yva_seq, yhat)\n",
    "\n",
    "    trial.set_user_attr(\"model_path\", str(tmp_path))\n",
    "    trial.set_user_attr(\"arch\", \"bilstm\")\n",
    "    trial.set_user_attr(\"seq_len_used\", L)\n",
    "    trial.set_user_attr(\"n_feat\", Xtr_s.shape[1])\n",
    "    return val_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3b5bd62",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_23508/3401579257.py:37: FutureWarning: The import path :class:`~optuna.storages.JournalFileOpenLock` has been deprecated in v4.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v4.0.0. Use :class:`~optuna.storages.journal.JournalFileOpenLock` instead.\n",
      "  file_storage = JournalFileStorage(str(log_path), lock_obj=JournalFileOpenLock(str(lock_path)))\n",
      "/tmp/ipykernel_23508/3401579257.py:37: FutureWarning: JournalFileStorage has been deprecated in v4.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v4.0.0. Use :class:`~optuna.storages.journal.JournalFileBackend` instead.\n",
      "  file_storage = JournalFileStorage(str(log_path), lock_obj=JournalFileOpenLock(str(lock_path)))\n",
      "[I 2025-10-01 12:02:05,735] Using an existing study with name 'ground_trackB_bilstm' instead of creating a new one.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Study B2 (BiLSTM)…\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "955d9179aad3476ba43f8c45974a28cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/35 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-01 12:02:46,058] Trial 155 finished with value: 130.92670003192626 and parameters: {'seq_len': 18, 'units': 128, 'dropout': 0.13587324192457673, 'lr': 0.0015349938415358164, 'batch': 64, 'epochs': 58}. Best is trial 67 with value: 130.13822279119228.\n",
      "[I 2025-10-01 12:03:27,236] Trial 156 finished with value: 130.24044020819724 and parameters: {'seq_len': 18, 'units': 128, 'dropout': 0.169226941536002, 'lr': 0.002892090475983559, 'batch': 64, 'epochs': 54}. Best is trial 67 with value: 130.13822279119228.\n",
      "[I 2025-10-01 12:03:44,172] Trial 157 pruned. Trial was pruned at epoch 5.\n",
      "[I 2025-10-01 12:04:29,492] Trial 158 finished with value: 131.3369726719213 and parameters: {'seq_len': 18, 'units': 96, 'dropout': 0.20018375550345666, 'lr': 0.0032125094658653473, 'batch': 64, 'epochs': 56}. Best is trial 67 with value: 130.13822279119228.\n",
      "[I 2025-10-01 12:05:10,078] Trial 159 finished with value: 130.60494014632448 and parameters: {'seq_len': 18, 'units': 128, 'dropout': 0.21608954193884033, 'lr': 0.00460016541072541, 'batch': 64, 'epochs': 48}. Best is trial 67 with value: 130.13822279119228.\n",
      "[I 2025-10-01 12:05:45,106] Trial 160 finished with value: 130.97058054673957 and parameters: {'seq_len': 18, 'units': 128, 'dropout': 0.21590944478960486, 'lr': 0.00460304517684367, 'batch': 64, 'epochs': 48}. Best is trial 67 with value: 130.13822279119228.\n",
      "[I 2025-10-01 12:06:27,313] Trial 161 finished with value: 130.50234971543617 and parameters: {'seq_len': 18, 'units': 128, 'dropout': 0.24098257932344652, 'lr': 0.004092892168105868, 'batch': 64, 'epochs': 51}. Best is trial 67 with value: 130.13822279119228.\n",
      "[I 2025-10-01 12:07:28,724] Trial 162 finished with value: 130.92916888770432 and parameters: {'seq_len': 18, 'units': 128, 'dropout': 0.2562112186048375, 'lr': 0.004132175226269055, 'batch': 64, 'epochs': 51}. Best is trial 67 with value: 130.13822279119228.\n",
      "[I 2025-10-01 12:08:21,254] Trial 163 finished with value: 130.56434746179755 and parameters: {'seq_len': 18, 'units': 128, 'dropout': 0.21721483285469612, 'lr': 0.00496147602892913, 'batch': 64, 'epochs': 49}. Best is trial 67 with value: 130.13822279119228.\n",
      "[I 2025-10-01 12:08:57,226] Trial 164 finished with value: 130.176930379868 and parameters: {'seq_len': 18, 'units': 128, 'dropout': 0.19039086058764645, 'lr': 0.003538347666015342, 'batch': 64, 'epochs': 46}. Best is trial 67 with value: 130.13822279119228.\n",
      "[I 2025-10-01 12:10:00,838] Trial 165 finished with value: 131.05787277239395 and parameters: {'seq_len': 18, 'units': 128, 'dropout': 0.23374018827979395, 'lr': 0.0037401933570354816, 'batch': 64, 'epochs': 46}. Best is trial 67 with value: 130.13822279119228.\n",
      "[I 2025-10-01 12:10:48,330] Trial 166 finished with value: 130.9883478238618 and parameters: {'seq_len': 18, 'units': 128, 'dropout': 0.25014412208900877, 'lr': 0.0033551382450708904, 'batch': 64, 'epochs': 50}. Best is trial 67 with value: 130.13822279119228.\n",
      "[I 2025-10-01 12:11:31,652] Trial 167 finished with value: 130.39034695147106 and parameters: {'seq_len': 18, 'units': 128, 'dropout': 0.20164814630606467, 'lr': 0.0026875304012345578, 'batch': 64, 'epochs': 44}. Best is trial 67 with value: 130.13822279119228.\n",
      "[I 2025-10-01 12:11:51,138] Trial 168 pruned. Trial was pruned at epoch 5.\n",
      "[I 2025-10-01 12:12:07,307] Trial 169 pruned. Trial was pruned at epoch 5.\n",
      "[I 2025-10-01 12:12:25,103] Trial 170 pruned. Trial was pruned at epoch 5.\n",
      "[I 2025-10-01 12:12:40,752] Trial 171 pruned. Trial was pruned at epoch 5.\n",
      "[I 2025-10-01 12:13:35,068] Trial 172 finished with value: 131.10564233901223 and parameters: {'seq_len': 18, 'units': 128, 'dropout': 0.209772588201266, 'lr': 0.003021720451435755, 'batch': 64, 'epochs': 42}. Best is trial 67 with value: 130.13822279119228.\n",
      "[I 2025-10-01 12:14:17,122] Trial 173 finished with value: 130.2732254964542 and parameters: {'seq_len': 18, 'units': 128, 'dropout': 0.18368730650150136, 'lr': 0.0034414597108702307, 'batch': 64, 'epochs': 48}. Best is trial 67 with value: 130.13822279119228.\n",
      "[I 2025-10-01 12:15:09,633] Trial 174 finished with value: 130.98072824608587 and parameters: {'seq_len': 18, 'units': 128, 'dropout': 0.18296899209906142, 'lr': 0.0033129734626165717, 'batch': 64, 'epochs': 52}. Best is trial 67 with value: 130.13822279119228.\n",
      "[I 2025-10-01 12:15:26,044] Trial 175 pruned. Trial was pruned at epoch 5.\n",
      "[I 2025-10-01 12:16:05,564] Trial 176 finished with value: 131.32210816823647 and parameters: {'seq_len': 18, 'units': 128, 'dropout': 0.20001792750126582, 'lr': 0.004076311692370589, 'batch': 64, 'epochs': 49}. Best is trial 67 with value: 130.13822279119228.\n",
      "[I 2025-10-01 12:16:39,709] Trial 177 finished with value: 131.1577056447695 and parameters: {'seq_len': 6, 'units': 128, 'dropout': 0.17675572333109965, 'lr': 0.0022382369027815906, 'batch': 64, 'epochs': 45}. Best is trial 67 with value: 130.13822279119228.\n",
      "[I 2025-10-01 12:17:26,928] Trial 178 finished with value: 130.36416092287405 and parameters: {'seq_len': 18, 'units': 128, 'dropout': 0.21606665891876856, 'lr': 0.0018735767577619383, 'batch': 64, 'epochs': 53}. Best is trial 67 with value: 130.13822279119228.\n",
      "[I 2025-10-01 12:18:33,565] Trial 179 finished with value: 131.44938724182018 and parameters: {'seq_len': 18, 'units': 128, 'dropout': 0.20580566740821676, 'lr': 0.0018565423815251505, 'batch': 64, 'epochs': 54}. Best is trial 67 with value: 130.13822279119228.\n",
      "[I 2025-10-01 12:19:18,414] Trial 180 finished with value: 130.963362600958 and parameters: {'seq_len': 18, 'units': 128, 'dropout': 0.18588099692454685, 'lr': 0.0019910698390178394, 'batch': 64, 'epochs': 52}. Best is trial 67 with value: 130.13822279119228.\n",
      "[I 2025-10-01 12:20:07,173] Trial 181 finished with value: 131.0446309945585 and parameters: {'seq_len': 18, 'units': 128, 'dropout': 0.10769152044066993, 'lr': 0.0027700254034161978, 'batch': 64, 'epochs': 53}. Best is trial 67 with value: 130.13822279119228.\n",
      "[I 2025-10-01 12:20:51,254] Trial 182 finished with value: 130.8857072387012 and parameters: {'seq_len': 18, 'units': 128, 'dropout': 0.2122213293099068, 'lr': 0.003674574570990475, 'batch': 64, 'epochs': 50}. Best is trial 67 with value: 130.13822279119228.\n",
      "[I 2025-10-01 12:21:29,399] Trial 183 finished with value: 130.48932846692867 and parameters: {'seq_len': 18, 'units': 128, 'dropout': 0.1957191507271771, 'lr': 0.003142896070778264, 'batch': 64, 'epochs': 47}. Best is trial 67 with value: 130.13822279119228.\n",
      "[I 2025-10-01 12:22:07,037] Trial 184 finished with value: 131.2372984925589 and parameters: {'seq_len': 18, 'units': 128, 'dropout': 0.2669064247424111, 'lr': 0.003151396378008229, 'batch': 64, 'epochs': 47}. Best is trial 67 with value: 130.13822279119228.\n",
      "[I 2025-10-01 12:22:51,253] Trial 185 finished with value: 130.2257505017729 and parameters: {'seq_len': 18, 'units': 128, 'dropout': 0.17451916387882127, 'lr': 0.0025563514321660825, 'batch': 64, 'epochs': 42}. Best is trial 67 with value: 130.13822279119228.\n",
      "[I 2025-10-01 12:23:05,722] Trial 186 pruned. Trial was pruned at epoch 5.\n",
      "[I 2025-10-01 12:23:54,118] Trial 187 finished with value: 131.08213223252434 and parameters: {'seq_len': 18, 'units': 128, 'dropout': 0.1947815824651488, 'lr': 0.002916053839673312, 'batch': 64, 'epochs': 51}. Best is trial 67 with value: 130.13822279119228.\n",
      "[I 2025-10-01 12:24:15,970] Trial 188 pruned. Trial was pruned at epoch 5.\n",
      "[I 2025-10-01 12:25:10,654] Trial 189 finished with value: 130.29045826776803 and parameters: {'seq_len': 18, 'units': 128, 'dropout': 0.18642138732094318, 'lr': 0.003142173080905876, 'batch': 64, 'epochs': 55}. Best is trial 67 with value: 130.13822279119228.\n",
      "Best BiLSTM params: {'seq_len': 18, 'units': 128, 'dropout': 0.11290422597989508, 'lr': 0.004256193252277516, 'batch': 128, 'epochs': 64}\n",
      "BiLSTM test → RMSE: 137.1388 | MAE: 71.0945 | R2: 0.7167 | Skill: 0.302\n"
     ]
    }
   ],
   "source": [
    "storageB2 = prepare_journal_storage(\"ground_trackB_bilstm\")\n",
    "studyB2 = optuna.create_study(direction=\"minimize\",\n",
    "                              sampler=TPESampler(seed=SEED),\n",
    "                              pruner=MedianPruner(n_startup_trials=8, n_warmup_steps=5),\n",
    "                              study_name=\"ground_trackB_bilstm\",\n",
    "                              storage=storageB2, load_if_exists=True)\n",
    "print(\"Running Study B2 (BiLSTM)…\")\n",
    "studyB2.optimize(objective_bilstm, n_trials=35, show_progress_bar=True)\n",
    "\n",
    "best_bi, _ = _safe_load_best(studyB2)\n",
    "bestL2 = studyB2.best_trial.user_attrs[\"seq_len_used\"]\n",
    "Xte_seq, yte_seq, idx_BI = build_seq_with_idx(Xte_s, yte, bestL2)\n",
    "yhatB2 = best_bi.predict(Xte_seq, verbose=0).squeeze()\n",
    "y_base_BI = pd.Series(y_base, index=Xte_df.index).reindex(idx_BI).to_numpy()\n",
    "print(\"Best BiLSTM params:\", studyB2.best_trial.params | {\"seq_len\": bestL2})\n",
    "print(f\"BiLSTM test → RMSE: {_rmse(yte_seq, yhatB2):.4f} | MAE: {mean_absolute_error(yte_seq, yhatB2):.4f} | R2: {r2_score(yte_seq, yhatB2):.4f} | Skill: {skill(yte_seq, yhatB2, y_base_BI):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d213bc8d",
   "metadata": {},
   "source": [
    "### CNN-LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f1c2392",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_cnnlstm(trial: optuna.Trial) -> float:\n",
    "    K.clear_session()\n",
    "    L     = trial.suggest_categorical(\"seq_len\", [6, 12, 18, 24])\n",
    "    filt  = trial.suggest_int(\"filters\", 16, 64, step=16)\n",
    "    ksz   = trial.suggest_categorical(\"kernel_size\", [2,3,5])\n",
    "    pool  = trial.suggest_categorical(\"pool\", [1,2])\n",
    "    u     = trial.suggest_int(\"lstm_units\", 32, 128, step=32)\n",
    "    do    = trial.suggest_float(\"dropout\", 0.0, 0.4)\n",
    "    lr    = trial.suggest_float(\"lr\", 5e-5, 5e-3, log=True)\n",
    "    bs    = trial.suggest_categorical(\"batch\", [64, 128, 256])\n",
    "    eps   = trial.suggest_int(\"epochs\", 40, 120)\n",
    "\n",
    "    Xtr_seq, ytr_seq = _build_seq(Xtr_s, ytr, L)\n",
    "    Xva_seq, yva_seq = _build_seq(Xva_s, yva, L)\n",
    "    if min(map(len,[Xtr_seq, Xva_seq])) == 0:\n",
    "        raise optuna.TrialPruned()\n",
    "\n",
    "    model = build_cnnlstm(L, Xtr_seq.shape[2], filt=filt, ksz=ksz, pool=pool, lstm_units=u, do=do)\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=lr), loss=\"mse\", metrics=[\"mae\"])\n",
    "\n",
    "    tmp_dir  = ART_DIR / f\"B_cnnlstm_t{trial.number:04d}\"; tmp_dir.mkdir(parents=True, exist_ok=True)\n",
    "    tmp_path = (tmp_dir / \"best.weights.h5\").resolve()\n",
    "\n",
    "    cbs = [\n",
    "        callbacks.EarlyStopping(monitor=\"val_loss\", patience=10, restore_best_weights=True, verbose=0),\n",
    "        callbacks.ModelCheckpoint(filepath=str(tmp_path), monitor=\"val_loss\",\n",
    "                                  save_best_only=True, save_weights_only=True),\n",
    "        TFKerasPruningCallback(trial, \"val_loss\"),\n",
    "    ]\n",
    "    model.fit(Xtr_seq, ytr_seq, validation_data=(Xva_seq, yva_seq),\n",
    "              epochs=eps, batch_size=bs, verbose=0, callbacks=cbs)\n",
    "\n",
    "    yhat = model.predict(Xva_seq, verbose=0).squeeze()\n",
    "    val_rmse = _rmse(yva_seq, yhat)\n",
    "\n",
    "    trial.set_user_attr(\"model_path\", str(tmp_path))\n",
    "    trial.set_user_attr(\"arch\", \"cnn-lstm\")\n",
    "    trial.set_user_attr(\"seq_len_used\", L)\n",
    "    trial.set_user_attr(\"n_feat\", Xtr_s.shape[1])\n",
    "    return val_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee61c1f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_23508/3401579257.py:37: FutureWarning: The import path :class:`~optuna.storages.JournalFileOpenLock` has been deprecated in v4.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v4.0.0. Use :class:`~optuna.storages.journal.JournalFileOpenLock` instead.\n",
      "  file_storage = JournalFileStorage(str(log_path), lock_obj=JournalFileOpenLock(str(lock_path)))\n",
      "/tmp/ipykernel_23508/3401579257.py:37: FutureWarning: JournalFileStorage has been deprecated in v4.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v4.0.0. Use :class:`~optuna.storages.journal.JournalFileBackend` instead.\n",
      "  file_storage = JournalFileStorage(str(log_path), lock_obj=JournalFileOpenLock(str(lock_path)))\n",
      "[I 2025-10-01 12:44:01,267] Using an existing study with name 'ground_trackB_cnnlstm' instead of creating a new one.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Study B3 (CNN-LSTM)…\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7216b7085414497b5f1535df829f6ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/35 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-01 12:44:13,532] Trial 140 pruned. Trial was pruned at epoch 5.\n",
      "[I 2025-10-01 12:44:26,060] Trial 141 pruned. Trial was pruned at epoch 5.\n",
      "[I 2025-10-01 12:44:56,442] Trial 142 finished with value: 131.38979162686118 and parameters: {'seq_len': 18, 'filters': 64, 'kernel_size': 2, 'pool': 1, 'lstm_units': 96, 'dropout': 0.20500245770534004, 'lr': 0.002913861960131337, 'batch': 64, 'epochs': 74}. Best is trial 54 with value: 130.55489296891557.\n",
      "[I 2025-10-01 12:45:07,567] Trial 143 pruned. Trial was pruned at epoch 5.\n",
      "[I 2025-10-01 12:45:19,061] Trial 144 pruned. Trial was pruned at epoch 5.\n",
      "[I 2025-10-01 12:45:50,448] Trial 145 finished with value: 130.92202325000557 and parameters: {'seq_len': 18, 'filters': 64, 'kernel_size': 2, 'pool': 1, 'lstm_units': 96, 'dropout': 0.21213090979718335, 'lr': 0.004276071840407373, 'batch': 64, 'epochs': 71}. Best is trial 54 with value: 130.55489296891557.\n",
      "[I 2025-10-01 12:45:57,516] Trial 146 pruned. Trial was pruned at epoch 5.\n",
      "[I 2025-10-01 12:46:26,541] Trial 147 finished with value: 130.82823603393115 and parameters: {'seq_len': 18, 'filters': 64, 'kernel_size': 2, 'pool': 2, 'lstm_units': 96, 'dropout': 0.06964533433605719, 'lr': 0.004136574053908809, 'batch': 64, 'epochs': 71}. Best is trial 54 with value: 130.55489296891557.\n",
      "[I 2025-10-01 12:47:07,366] Trial 148 finished with value: 131.05889360798832 and parameters: {'seq_len': 18, 'filters': 64, 'kernel_size': 2, 'pool': 2, 'lstm_units': 96, 'dropout': 0.06818451141284518, 'lr': 0.004134461617984419, 'batch': 64, 'epochs': 71}. Best is trial 54 with value: 130.55489296891557.\n",
      "[I 2025-10-01 12:47:12,401] Trial 149 pruned. Trial was pruned at epoch 5.\n",
      "[I 2025-10-01 12:47:22,980] Trial 150 pruned. Trial was pruned at epoch 5.\n",
      "[I 2025-10-01 12:47:33,466] Trial 151 pruned. Trial was pruned at epoch 5.\n",
      "[I 2025-10-01 12:47:45,455] Trial 152 pruned. Trial was pruned at epoch 6.\n",
      "[I 2025-10-01 12:47:58,465] Trial 153 pruned. Trial was pruned at epoch 5.\n",
      "[I 2025-10-01 12:48:12,031] Trial 154 pruned. Trial was pruned at epoch 5.\n",
      "[I 2025-10-01 12:48:46,748] Trial 155 finished with value: 131.07740139417626 and parameters: {'seq_len': 18, 'filters': 64, 'kernel_size': 2, 'pool': 1, 'lstm_units': 128, 'dropout': 0.038630736938655666, 'lr': 0.00440329030201896, 'batch': 64, 'epochs': 91}. Best is trial 54 with value: 130.55489296891557.\n",
      "[I 2025-10-01 12:48:57,849] Trial 156 pruned. Trial was pruned at epoch 5.\n",
      "[I 2025-10-01 12:49:45,090] Trial 157 finished with value: 130.86056062895727 and parameters: {'seq_len': 18, 'filters': 64, 'kernel_size': 3, 'pool': 1, 'lstm_units': 96, 'dropout': 0.2011523975359903, 'lr': 0.0039798176676842335, 'batch': 64, 'epochs': 66}. Best is trial 54 with value: 130.55489296891557.\n",
      "[I 2025-10-01 12:49:55,217] Trial 158 pruned. Trial was pruned at epoch 5.\n",
      "[I 2025-10-01 12:50:06,679] Trial 159 pruned. Trial was pruned at epoch 5.\n",
      "[I 2025-10-01 12:50:47,381] Trial 160 finished with value: 131.3166720541417 and parameters: {'seq_len': 12, 'filters': 64, 'kernel_size': 3, 'pool': 1, 'lstm_units': 96, 'dropout': 0.12733438758195897, 'lr': 0.004021651254860568, 'batch': 64, 'epochs': 61}. Best is trial 54 with value: 130.55489296891557.\n",
      "[I 2025-10-01 12:51:16,592] Trial 161 finished with value: 131.741179140199 and parameters: {'seq_len': 18, 'filters': 64, 'kernel_size': 3, 'pool': 1, 'lstm_units': 96, 'dropout': 0.22354770228929965, 'lr': 0.003712678225019653, 'batch': 64, 'epochs': 65}. Best is trial 54 with value: 130.55489296891557.\n",
      "[I 2025-10-01 12:51:46,051] Trial 162 finished with value: 131.2542112419636 and parameters: {'seq_len': 18, 'filters': 64, 'kernel_size': 3, 'pool': 1, 'lstm_units': 96, 'dropout': 0.20542819104860635, 'lr': 0.004485547545221942, 'batch': 64, 'epochs': 73}. Best is trial 54 with value: 130.55489296891557.\n",
      "[I 2025-10-01 12:51:57,642] Trial 163 pruned. Trial was pruned at epoch 5.\n",
      "[I 2025-10-01 12:52:30,197] Trial 164 finished with value: 131.1206282040511 and parameters: {'seq_len': 18, 'filters': 64, 'kernel_size': 2, 'pool': 1, 'lstm_units': 96, 'dropout': 0.07255181011511735, 'lr': 0.0031985839366584956, 'batch': 64, 'epochs': 66}. Best is trial 54 with value: 130.55489296891557.\n",
      "[I 2025-10-01 12:52:41,659] Trial 165 pruned. Trial was pruned at epoch 5.\n",
      "[I 2025-10-01 12:52:52,771] Trial 166 pruned. Trial was pruned at epoch 5.\n",
      "[I 2025-10-01 12:53:24,320] Trial 167 finished with value: 131.48981067938306 and parameters: {'seq_len': 18, 'filters': 64, 'kernel_size': 2, 'pool': 1, 'lstm_units': 128, 'dropout': 0.19418200237339867, 'lr': 0.004625100139693118, 'batch': 64, 'epochs': 73}. Best is trial 54 with value: 130.55489296891557.\n",
      "[I 2025-10-01 12:53:53,779] Trial 168 finished with value: 131.06641923086173 and parameters: {'seq_len': 18, 'filters': 64, 'kernel_size': 3, 'pool': 1, 'lstm_units': 96, 'dropout': 0.10869136029119043, 'lr': 0.002537317631399787, 'batch': 64, 'epochs': 75}. Best is trial 54 with value: 130.55489296891557.\n",
      "[I 2025-10-01 12:54:31,348] Trial 169 finished with value: 131.25923330617545 and parameters: {'seq_len': 18, 'filters': 64, 'kernel_size': 2, 'pool': 1, 'lstm_units': 96, 'dropout': 0.10146227301992722, 'lr': 0.0039068398329650976, 'batch': 64, 'epochs': 53}. Best is trial 54 with value: 130.55489296891557.\n",
      "[I 2025-10-01 12:54:43,220] Trial 170 pruned. Trial was pruned at epoch 5.\n",
      "[I 2025-10-01 12:54:54,554] Trial 171 pruned. Trial was pruned at epoch 5.\n",
      "[I 2025-10-01 12:55:27,306] Trial 172 finished with value: 130.66573826466524 and parameters: {'seq_len': 18, 'filters': 64, 'kernel_size': 2, 'pool': 1, 'lstm_units': 96, 'dropout': 0.17253540383752689, 'lr': 0.0042139365614470145, 'batch': 64, 'epochs': 79}. Best is trial 54 with value: 130.55489296891557.\n",
      "[I 2025-10-01 12:55:58,486] Trial 173 finished with value: 131.35648953801254 and parameters: {'seq_len': 18, 'filters': 64, 'kernel_size': 2, 'pool': 1, 'lstm_units': 96, 'dropout': 0.16808314413004255, 'lr': 0.0049794626470525604, 'batch': 64, 'epochs': 79}. Best is trial 54 with value: 130.55489296891557.\n",
      "[I 2025-10-01 12:56:09,861] Trial 174 pruned. Trial was pruned at epoch 5.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "The `function` of this `Lambda` layer is a Python lambda. Deserializing it is unsafe. If you trust the source of the config artifact, you can override this error by passing `safe_mode=False` to `from_config()`, or calling `keras.config.enable_unsafe_deserialization().",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 10\u001b[39m\n\u001b[32m      7\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mRunning Study B3 (CNN-LSTM)…\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      8\u001b[39m studyB3.optimize(objective_cnnlstm, n_trials=\u001b[32m35\u001b[39m, show_progress_bar=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m best_cnn, _ = \u001b[43m_safe_load_best\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudyB3\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     11\u001b[39m bestL3 = studyB3.best_trial.user_attrs[\u001b[33m\"\u001b[39m\u001b[33mseq_len_used\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m     12\u001b[39m Xte_seq, yte_seq, idx_CNN = build_seq_with_idx(Xte_s, yte, bestL3)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 54\u001b[39m, in \u001b[36m_safe_load_best\u001b[39m\u001b[34m(study, rebuild_fn)\u001b[39m\n\u001b[32m     52\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     53\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mCheckpoint not found: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mp\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m54\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mkeras\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmodels\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mp\u001b[49m\u001b[43m)\u001b[49m, p\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/e_ladino/lib/python3.12/site-packages/keras/src/saving/saving_api.py:189\u001b[39m, in \u001b[36mload_model\u001b[39m\u001b[34m(filepath, custom_objects, compile, safe_mode)\u001b[39m\n\u001b[32m    186\u001b[39m         is_keras_zip = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    188\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_keras_zip \u001b[38;5;129;01mor\u001b[39;00m is_keras_dir \u001b[38;5;129;01mor\u001b[39;00m is_hf:\n\u001b[32m--> \u001b[39m\u001b[32m189\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msaving_lib\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    190\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfilepath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    191\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcustom_objects\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcustom_objects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    192\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mcompile\u001b[39;49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mcompile\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    193\u001b[39m \u001b[43m        \u001b[49m\u001b[43msafe_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[43msafe_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    194\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    195\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(filepath).endswith((\u001b[33m\"\u001b[39m\u001b[33m.h5\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33m.hdf5\u001b[39m\u001b[33m\"\u001b[39m)):\n\u001b[32m    196\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m legacy_h5_format.load_model_from_hdf5(\n\u001b[32m    197\u001b[39m         filepath, custom_objects=custom_objects, \u001b[38;5;28mcompile\u001b[39m=\u001b[38;5;28mcompile\u001b[39m\n\u001b[32m    198\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/e_ladino/lib/python3.12/site-packages/keras/src/saving/saving_lib.py:365\u001b[39m, in \u001b[36mload_model\u001b[39m\u001b[34m(filepath, custom_objects, compile, safe_mode)\u001b[39m\n\u001b[32m    360\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    361\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mInvalid filename: expected a `.keras` extension. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    362\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mReceived: filepath=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfilepath\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    363\u001b[39m     )\n\u001b[32m    364\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(filepath, \u001b[33m\"\u001b[39m\u001b[33mrb\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[32m--> \u001b[39m\u001b[32m365\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_load_model_from_fileobj\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    366\u001b[39m \u001b[43m        \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcustom_objects\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mcompile\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msafe_mode\u001b[49m\n\u001b[32m    367\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/e_ladino/lib/python3.12/site-packages/keras/src/saving/saving_lib.py:442\u001b[39m, in \u001b[36m_load_model_from_fileobj\u001b[39m\u001b[34m(fileobj, custom_objects, compile, safe_mode)\u001b[39m\n\u001b[32m    439\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m zf.open(_CONFIG_FILENAME, \u001b[33m\"\u001b[39m\u001b[33mr\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[32m    440\u001b[39m     config_json = f.read()\n\u001b[32m--> \u001b[39m\u001b[32m442\u001b[39m model = \u001b[43m_model_from_config\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    443\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconfig_json\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcustom_objects\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mcompile\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msafe_mode\u001b[49m\n\u001b[32m    444\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    446\u001b[39m all_filenames = zf.namelist()\n\u001b[32m    447\u001b[39m extract_dir = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/e_ladino/lib/python3.12/site-packages/keras/src/saving/saving_lib.py:431\u001b[39m, in \u001b[36m_model_from_config\u001b[39m\u001b[34m(config_json, custom_objects, compile, safe_mode)\u001b[39m\n\u001b[32m    429\u001b[39m \u001b[38;5;66;03m# Construct the model from the configuration file in the archive.\u001b[39;00m\n\u001b[32m    430\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m ObjectSharingScope():\n\u001b[32m--> \u001b[39m\u001b[32m431\u001b[39m     model = \u001b[43mdeserialize_keras_object\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    432\u001b[39m \u001b[43m        \u001b[49m\u001b[43mconfig_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcustom_objects\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msafe_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[43msafe_mode\u001b[49m\n\u001b[32m    433\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    434\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m model\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/e_ladino/lib/python3.12/site-packages/keras/src/saving/serialization_lib.py:733\u001b[39m, in \u001b[36mdeserialize_keras_object\u001b[39m\u001b[34m(config, custom_objects, safe_mode, **kwargs)\u001b[39m\n\u001b[32m    731\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m custom_obj_scope, safe_mode_scope:\n\u001b[32m    732\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m733\u001b[39m         instance = \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfrom_config\u001b[49m\u001b[43m(\u001b[49m\u001b[43minner_config\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    734\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    735\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[32m    736\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m could not be deserialized properly. Please\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    737\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33m ensure that components that are Python object\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m    741\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mconfig=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mException encountered: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    742\u001b[39m         )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/e_ladino/lib/python3.12/site-packages/keras/src/models/sequential.py:371\u001b[39m, in \u001b[36mSequential.from_config\u001b[39m\u001b[34m(cls, config, custom_objects)\u001b[39m\n\u001b[32m    366\u001b[39m         layer = saving_utils.model_from_config(\n\u001b[32m    367\u001b[39m             layer_config,\n\u001b[32m    368\u001b[39m             custom_objects=custom_objects,\n\u001b[32m    369\u001b[39m         )\n\u001b[32m    370\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m371\u001b[39m         layer = \u001b[43mserialization_lib\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdeserialize_keras_object\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    372\u001b[39m \u001b[43m            \u001b[49m\u001b[43mlayer_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    373\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcustom_objects\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcustom_objects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    374\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    375\u001b[39m     model.add(layer)\n\u001b[32m    376\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    377\u001b[39m     \u001b[38;5;129;01mnot\u001b[39;00m model._functional\n\u001b[32m    378\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mbuild_input_shape\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mlocals\u001b[39m()\n\u001b[32m    379\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m build_input_shape\n\u001b[32m    380\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(build_input_shape, (\u001b[38;5;28mtuple\u001b[39m, \u001b[38;5;28mlist\u001b[39m))\n\u001b[32m    381\u001b[39m ):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/e_ladino/lib/python3.12/site-packages/keras/src/saving/serialization_lib.py:733\u001b[39m, in \u001b[36mdeserialize_keras_object\u001b[39m\u001b[34m(config, custom_objects, safe_mode, **kwargs)\u001b[39m\n\u001b[32m    731\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m custom_obj_scope, safe_mode_scope:\n\u001b[32m    732\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m733\u001b[39m         instance = \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfrom_config\u001b[49m\u001b[43m(\u001b[49m\u001b[43minner_config\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    734\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    735\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[32m    736\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m could not be deserialized properly. Please\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    737\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33m ensure that components that are Python object\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m    741\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mconfig=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mException encountered: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    742\u001b[39m         )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/e_ladino/lib/python3.12/site-packages/keras/src/layers/core/lambda_layer.py:190\u001b[39m, in \u001b[36mLambda.from_config\u001b[39m\u001b[34m(cls, config, custom_objects, safe_mode)\u001b[39m\n\u001b[32m    184\u001b[39m fn_config = config[\u001b[33m\"\u001b[39m\u001b[33mfunction\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m    185\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    186\u001b[39m     \u001b[38;5;28misinstance\u001b[39m(fn_config, \u001b[38;5;28mdict\u001b[39m)\n\u001b[32m    187\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mclass_name\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m fn_config\n\u001b[32m    188\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m fn_config[\u001b[33m\"\u001b[39m\u001b[33mclass_name\u001b[39m\u001b[33m\"\u001b[39m] == \u001b[33m\"\u001b[39m\u001b[33m__lambda__\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    189\u001b[39m ):\n\u001b[32m--> \u001b[39m\u001b[32m190\u001b[39m     \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_raise_for_lambda_deserialization\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfunction\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msafe_mode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    191\u001b[39m     inner_config = fn_config[\u001b[33m\"\u001b[39m\u001b[33mconfig\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m    192\u001b[39m     fn = python_utils.func_load(\n\u001b[32m    193\u001b[39m         inner_config[\u001b[33m\"\u001b[39m\u001b[33mcode\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m    194\u001b[39m         defaults=inner_config[\u001b[33m\"\u001b[39m\u001b[33mdefaults\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m    195\u001b[39m         closure=inner_config[\u001b[33m\"\u001b[39m\u001b[33mclosure\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m    196\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/e_ladino/lib/python3.12/site-packages/keras/src/layers/core/lambda_layer.py:172\u001b[39m, in \u001b[36mLambda._raise_for_lambda_deserialization\u001b[39m\u001b[34m(arg_name, safe_mode)\u001b[39m\n\u001b[32m    169\u001b[39m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[32m    170\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_raise_for_lambda_deserialization\u001b[39m(arg_name, safe_mode):\n\u001b[32m    171\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m safe_mode:\n\u001b[32m--> \u001b[39m\u001b[32m172\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    173\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mThe `\u001b[39m\u001b[38;5;132;01m{\u001b[39;00marg_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m` of this `Lambda` layer is a Python lambda. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    174\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mDeserializing it is unsafe. If you trust the source of the \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    175\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mconfig artifact, you can override this error \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    176\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mby passing `safe_mode=False` \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    177\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mto `from_config()`, or calling \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    178\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33m`keras.config.enable_unsafe_deserialization().\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    179\u001b[39m         )\n",
      "\u001b[31mValueError\u001b[39m: The `function` of this `Lambda` layer is a Python lambda. Deserializing it is unsafe. If you trust the source of the config artifact, you can override this error by passing `safe_mode=False` to `from_config()`, or calling `keras.config.enable_unsafe_deserialization()."
     ]
    }
   ],
   "source": [
    "storageB3 = prepare_journal_storage(\"ground_trackB_cnnlstm\")\n",
    "studyB3 = optuna.create_study(direction=\"minimize\",\n",
    "                              sampler=TPESampler(seed=SEED),\n",
    "                              pruner=MedianPruner(n_startup_trials=8, n_warmup_steps=5),\n",
    "                              study_name=\"ground_trackB_cnnlstm\",\n",
    "                              storage=storageB3, load_if_exists=True)\n",
    "print(\"Running Study B3 (CNN-LSTM)…\")\n",
    "studyB3.optimize(objective_cnnlstm, n_trials=35, show_progress_bar=True)\n",
    "\n",
    "best_cnn, _ = _safe_load_best(studyB3)\n",
    "bestL3 = studyB3.best_trial.user_attrs[\"seq_len_used\"]\n",
    "Xte_seq, yte_seq, idx_CNN = build_seq_with_idx(Xte_s, yte, bestL3)\n",
    "yhatB3 = best_cnn.predict(Xte_seq, verbose=0).squeeze()\n",
    "y_base_CNN = pd.Series(y_base, index=Xte_df.index).reindex(idx_CNN).to_numpy()\n",
    "print(\"Best CNN-LSTM params:\", studyB3.best_trial.params | {\"seq_len\": bestL3})\n",
    "print(f\"CNN-LSTM test → RMSE: {_rmse(yte_seq, yhatB3):.4f} | MAE: {mean_absolute_error(yte_seq, yhatB3):.4f} | R2: {r2_score(yte_seq, yhatB3):.4f} | Skill: {skill(yte_seq, yhatB3, y_base_CNN):.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c53a6c7",
   "metadata": {},
   "source": [
    "### Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f244d1ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_transformer(trial: optuna.Trial) -> float:\n",
    "    K.clear_session()\n",
    "    L       = trial.suggest_categorical(\"seq_len\", [6, 12, 18, 24])\n",
    "    d_model = trial.suggest_categorical(\"d_model\", [32, 64, 96, 128])\n",
    "    heads   = trial.suggest_categorical(\"heads\", [2, 4, 8])\n",
    "    if d_model % heads != 0:\n",
    "        raise optuna.TrialPruned()\n",
    "    ff_dim  = trial.suggest_categorical(\"ff_dim\", [64, 96, 128, 192])\n",
    "    att_do  = trial.suggest_float(\"att_dropout\", 0.0, 0.3)\n",
    "    do      = trial.suggest_float(\"dropout\", 0.0, 0.4)\n",
    "    lr      = trial.suggest_float(\"lr\", 5e-5, 5e-3, log=True)\n",
    "    bs      = trial.suggest_categorical(\"batch\", [64, 128, 256])\n",
    "    eps     = trial.suggest_int(\"epochs\", 40, 120)\n",
    "\n",
    "    Xtr_seq, ytr_seq = _build_seq(Xtr_s, ytr, L)\n",
    "    Xva_seq, yva_seq = _build_seq(Xva_s, yva, L)\n",
    "    if min(map(len,[Xtr_seq, Xva_seq])) == 0:\n",
    "        raise optuna.TrialPruned()\n",
    "\n",
    "    model = build_transformer(L, Xtr_seq.shape[2], d_model=d_model, heads=heads,\n",
    "                              ff_dim=ff_dim, att_do=att_do, do=do)\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=lr), loss=\"mse\", metrics=[\"mae\"])\n",
    "\n",
    "    tmp_dir  = ART_DIR / f\"B_transformer_t{trial.number:04d}\"; tmp_dir.mkdir(parents=True, exist_ok=True)\n",
    "    tmp_path = (tmp_dir / \"best.weights.h5\").resolve()\n",
    "\n",
    "    cbs = [\n",
    "        callbacks.EarlyStopping(monitor=\"val_loss\", patience=10, restore_best_weights=True, verbose=0),\n",
    "        callbacks.ModelCheckpoint(filepath=str(tmp_path), monitor=\"val_loss\",\n",
    "                                  save_best_only=True, save_weights_only=True),\n",
    "        TFKerasPruningCallback(trial, \"val_loss\"),\n",
    "    ]\n",
    "    model.fit(Xtr_seq, ytr_seq, validation_data=(Xva_seq, yva_seq),\n",
    "              epochs=eps, batch_size=bs, verbose=0, callbacks=cbs)\n",
    "\n",
    "    yhat = model.predict(Xva_seq, verbose=0).squeeze()\n",
    "    val_rmse = _rmse(yva_seq, yhat)\n",
    "\n",
    "    trial.set_user_attr(\"model_path\", str(tmp_path))\n",
    "    trial.set_user_attr(\"arch\", \"transformer\")\n",
    "    trial.set_user_attr(\"seq_len_used\", L)\n",
    "    trial.set_user_attr(\"n_feat\", Xtr_s.shape[1])\n",
    "    return val_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab6eee50",
   "metadata": {},
   "outputs": [],
   "source": [
    "storageB4 = prepare_journal_storage(\"ground_trackB_transformer\")\n",
    "studyB4 = optuna.create_study(direction=\"minimize\",\n",
    "                              sampler=TPESampler(seed=SEED),\n",
    "                              pruner=MedianPruner(n_startup_trials=8, n_warmup_steps=5),\n",
    "                              study_name=\"ground_trackB_transformer\",\n",
    "                              storage=storageB4, load_if_exists=True)\n",
    "print(\"Running Study B4 (Transformer)…\")\n",
    "studyB4.optimize(objective_transformer, n_trials=40, show_progress_bar=True)\n",
    "\n",
    "best_tr, _ = _safe_load_best(studyB4)\n",
    "bestL4 = studyB4.best_trial.user_attrs[\"seq_len_used\"]\n",
    "Xte_seq, yte_seq, idx_TR = build_seq_with_idx(Xte_s, yte, bestL4)\n",
    "yhatB4 = best_tr.predict(Xte_seq, verbose=0).squeeze()\n",
    "y_base_TR = pd.Series(y_base, index=Xte_df.index).reindex(idx_TR).to_numpy()\n",
    "print(\"Best Transformer params:\", studyB4.best_trial.params | {\"seq_len\": bestL4})\n",
    "print(f\"Transformer test → RMSE: {_rmse(yte_seq, yhatB4):.4f} | MAE: {mean_absolute_error(yte_seq, yhatB4):.4f} | R2: {r2_score(yte_seq, yhatB4):.4f} | Skill: {skill(yte_seq, yhatB4, y_base_TR):.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01676ed5",
   "metadata": {},
   "source": [
    "## Best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5bf2a76",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = {\n",
    "    \"MLP\":        studyA.best_trial.params,\n",
    "    \"LSTM\":       studyB1.best_trial.params | {\"seq_len\": studyB1.best_trial.user_attrs[\"seq_len_used\"]},\n",
    "    \"BiLSTM\":     studyB2.best_trial.params | {\"seq_len\": studyB2.best_trial.user_attrs[\"seq_len_used\"]},\n",
    "    \"CNN_LSTM\":   studyB3.best_trial.params | {\"seq_len\": studyB3.best_trial.user_attrs[\"seq_len_used\"]},\n",
    "    \"Transformer\":studyB4.best_trial.params | {\"seq_len\": studyB4.best_trial.user_attrs[\"seq_len_used\"]},\n",
    "}\n",
    "(out := OUT_DIR / \"best_hpo_params_all.json\")\n",
    "with open(out, \"w\") as f:\n",
    "    json.dump(best_params, f, indent=2)\n",
    "print(\"Saved params →\", out)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f728f0a",
   "metadata": {},
   "source": [
    "## Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65cbfe37",
   "metadata": {},
   "outputs": [],
   "source": [
    "models_info = {\n",
    "    \"MLP\": {\n",
    "        \"type\": \"tabular\",\n",
    "        \"model\": best_mlp,\n",
    "        \"idx\": Xte_df.index,\n",
    "        \"y_base\": y_base\n",
    "    },\n",
    "    \"LSTM\": {\n",
    "        \"type\": \"seq\",\n",
    "        \"model\": best_lstm,\n",
    "        \"L\": bestL1,\n",
    "        \"idx\": idx_LSTM,\n",
    "        \"y_base\": y_base_LSTM\n",
    "    },\n",
    "    \"BiLSTM\": {\n",
    "        \"type\": \"seq\",\n",
    "        \"model\": best_bi,\n",
    "        \"L\": bestL2,\n",
    "        \"idx\": idx_BI,\n",
    "        \"y_base\": y_base_BI\n",
    "    },\n",
    "    \"CNN-LSTM\": {\n",
    "        \"type\": \"seq\",\n",
    "        \"model\": best_cnn,\n",
    "        \"L\": bestL3,\n",
    "        \"idx\": idx_CNN,\n",
    "        \"y_base\": y_base_CNN\n",
    "    },\n",
    "    \"Transformer\": {\n",
    "        \"type\": \"seq\",\n",
    "        \"model\": best_tr,\n",
    "        \"L\": bestL4,\n",
    "        \"idx\": idx_TR,\n",
    "        \"y_base\": y_base_TR\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6de2026",
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = []\n",
    "OUT_FIG = Path(\"../reports/figures\")\n",
    "for name, cfg in models_info.items():\n",
    "    print(f\"\\n=== {name} ===\")\n",
    "    if cfg[\"type\"] == \"tabular\":\n",
    "        y_true = yte\n",
    "        y_pred = cfg[\"model\"].predict(Xte, verbose=0).squeeze()\n",
    "        idx    = cfg[\"idx\"]\n",
    "        yb     = cfg[\"y_base\"]\n",
    "    else:\n",
    "        L = int(cfg[\"L\"])\n",
    "        X_seq, y_seq, idx = build_seq_with_idx(Xte_s, yte, L)\n",
    "        if len(X_seq) == 0:\n",
    "            print(\"No hay secuencias válidas (NaNs). Se omite.\")\n",
    "            continue\n",
    "        y_true = y_seq\n",
    "        y_pred = cfg[\"model\"].predict(X_seq, verbose=0).squeeze()\n",
    "        yb     = pd.Series(y_base, index=Xte_df.index).reindex(idx).to_numpy()\n",
    "\n",
    "    rmse = _rmse(y_true, y_pred)\n",
    "    mae  = mean_absolute_error(y_true, y_pred)\n",
    "    r2   = r2_score(y_true, y_pred)\n",
    "    skl  = skill(y_true, y_pred, yb)\n",
    "    print(f\"RMSE={rmse:.4f} | MAE={mae:.4f} | R2={r2:.4f} | Skill={skl:.3f}\")\n",
    "\n",
    "    rows.append({\"model\": name, \"RMSE\": rmse, \"MAE\": mae, \"R2\": r2, \"Skill\": skl})\n",
    "\n",
    "    # 1) Time series (clip)\n",
    "    N = min(400, len(y_true))\n",
    "    plt.figure(figsize=(12, 3.6))\n",
    "    plt.plot(idx[:N], y_true[:N], label=\"truth\", lw=1.4)\n",
    "    plt.plot(idx[:N], y_pred[:N], label=name, lw=1.1)\n",
    "    plt.plot(idx[:N], yb[:N], label=\"baseline\", lw=1.0, alpha=0.7)\n",
    "    plt.title(f\"Test — Truth vs {name} vs Baseline ({TARGET})\")\n",
    "    plt.ylabel(\"GHI (W/m²)\" if TARGET.startswith(\"y_ghi\") else \"k-index\")\n",
    "    plt.xlabel(\"Time\"); plt.grid(True, ls=\"--\", alpha=0.3); plt.legend()\n",
    "    plt.xticks(rotation=45); plt.tight_layout()\n",
    "    plt.savefig(OUT_FIG / f\"{name}_ts_test.png\", dpi=140)\n",
    "    plt.show()\n",
    "\n",
    "    # 2) Scatter\n",
    "    lim_min = float(min(np.min(y_true), np.min(y_pred)))\n",
    "    lim_max = float(max(np.max(y_true), np.max(y_pred)))\n",
    "    plt.figure(figsize=(4.8, 4.8))\n",
    "    plt.scatter(y_true, y_pred, s=10, alpha=0.5)\n",
    "    plt.plot([lim_min, lim_max], [lim_min, lim_max], 'r--', lw=1.0)\n",
    "    plt.xlabel(\"Actual\"); plt.ylabel(\"Predicted\")\n",
    "    plt.title(f\"{name} — Actual vs Predicted\\nRMSE={rmse:.3f} MAE={mae:.3f} R2={r2:.3f}\")\n",
    "    plt.grid(True, ls=\"--\", alpha=0.3); plt.tight_layout()\n",
    "    plt.savefig(OUT_FIG / f\"{name}_scatter.png\", dpi=140)\n",
    "    plt.show()\n",
    "\n",
    "    # 3) Residuals histogram\n",
    "    resid = y_pred - y_true\n",
    "    plt.figure(figsize=(6, 3.2))\n",
    "    plt.hist(resid, bins=50, alpha=0.85)\n",
    "    plt.axvline(0, color='r', ls='--', lw=1)\n",
    "    plt.title(f\"{name} — Residuals (mean={np.mean(resid):.3f})\")\n",
    "    plt.xlabel(\"Residual\"); plt.ylabel(\"Frequency\")\n",
    "    plt.grid(True, ls=\"--\", alpha=0.3); plt.tight_layout()\n",
    "    plt.savefig(OUT_FIG / f\"{name}_residuals.png\", dpi=140)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "688e6743",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame(rows).sort_values(\"RMSE\")\n",
    "print(\"\\n=== Test Summary ===\")\n",
    "print(results_df.round(4))\n",
    "results_df.to_csv(OUT_DIR / \"hpo_models_test_summary.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "e_ladino",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
