{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8203d6aa",
   "metadata": {},
   "source": [
    "# Ground HPO with Optuna (MLP, LSTM, BiLSTM, CNN-LSTM, Transformer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a406c53",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6aa9132",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-06 09:38:10.801092: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1759761490.808677 1218692 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1759761490.811242 1218692 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPUs visibles: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "# import os\n",
    "# os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"       # 0=all,1=info,2=warning,3=error\n",
    "# # os.environ[\"TF_ENABLE_ONEDNN_OPTS\"] = \"0\"    # opcional: desactiva oneDNN por reproducibilidad exacta (puede bajar performance)\n",
    "\n",
    "# import tensorflow as tf\n",
    "# gpus = tf.config.list_physical_devices('GPU')\n",
    "# for g in gpus:\n",
    "#     tf.config.experimental.set_memory_growth(g, True)\n",
    "# print(\"GPUs visibles:\", gpus)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fe79efe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tiempo 5 matmul GPU: 0.02906322479248047 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1759761494.420667 1218692 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 22136 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4090, pci bus id: 0000:01:00.0, compute capability: 8.9\n"
     ]
    }
   ],
   "source": [
    "# import tensorflow as tf, time\n",
    "# with tf.device('/GPU:0'):\n",
    "#     a = tf.random.normal([4000, 4000])\n",
    "#     b = tf.random.normal([4000, 4000])\n",
    "#     tf.linalg.matmul(a, b)  # warmup\n",
    "# t0 = time.time()\n",
    "# for _ in range(5):\n",
    "#     with tf.device('/GPU:0'):\n",
    "#         c = tf.linalg.matmul(a, b)\n",
    "# _ = c.numpy()\n",
    "# print(\"Tiempo 5 matmul GPU:\", time.time() - t0, \"s\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5ed6cf39",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, json, numpy as np, pandas as pd, matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, callbacks, regularizers, backend as K\n",
    "\n",
    "import optuna\n",
    "from optuna.samplers import TPESampler\n",
    "from optuna.pruners import MedianPruner\n",
    "from optuna.integration import TFKerasPruningCallback\n",
    "from optuna.storages import JournalStorage\n",
    "from optuna.storages import JournalFileStorage, JournalFileOpenLock"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8fc47f6",
   "metadata": {},
   "source": [
    "## Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1c7ce94f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Studies dir: /mnt/SOLARLAB/E_Ladino/Repo/irradiance-fusion-forecast/optuna_studies\n",
      "Artifacts dir: /mnt/SOLARLAB/E_Ladino/Repo/irradiance-fusion-forecast/models/optuna_artifacts\n"
     ]
    }
   ],
   "source": [
    "SEED = 42\n",
    "np.random.seed(SEED); tf.random.set_seed(SEED)\n",
    "\n",
    "DATA_DIR = Path(\"../data_processed\")\n",
    "OUT_DIR  = Path(\"../models\"); OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "STUDY_DIR= Path(\"../optuna_studies\"); STUDY_DIR.mkdir(parents=True, exist_ok=True)\n",
    "ART_DIR  = (OUT_DIR / \"optuna_artifacts\").resolve(); ART_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "TRAIN_PQ = DATA_DIR / \"ground_train_h6.parquet\"\n",
    "VAL_PQ   = DATA_DIR / \"ground_val_h6.parquet\"\n",
    "TEST_PQ  = DATA_DIR / \"ground_test_h6.parquet\"\n",
    "TARGET   = \"y_ghi_h6\" \n",
    "\n",
    "print(\"Studies dir:\", STUDY_DIR.resolve())\n",
    "print(\"Artifacts dir:\", ART_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7e639da",
   "metadata": {},
   "source": [
    "### Data loading and preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "89b4b493",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_parquet(TRAIN_PQ).sort_index()\n",
    "val   = pd.read_parquet(VAL_PQ).sort_index()\n",
    "test  = pd.read_parquet(TEST_PQ).sort_index()\n",
    "assert TARGET in train and TARGET in val and TARGET in test, f\"{TARGET} missing!\"\n",
    "\n",
    "feat_cols = sorted(list(set(train.columns) & set(val.columns) & set(test.columns) - {TARGET}))\n",
    "feat_cols = [c for c in feat_cols if pd.api.types.is_numeric_dtype(train[c])]\n",
    "\n",
    "Xtr_df, ytr = train[feat_cols], train[TARGET]\n",
    "Xva_df, yva = val[feat_cols],   val[TARGET]\n",
    "Xte_df, yte = test[feat_cols],  test[TARGET]\n",
    "\n",
    "scaler = StandardScaler()\n",
    "Xtr = scaler.fit_transform(Xtr_df)\n",
    "Xva = scaler.transform(Xva_df)\n",
    "Xte = scaler.transform(Xte_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9305a371",
   "metadata": {},
   "source": [
    "## Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "05a460c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _rmse(a,b):\n",
    "    return float(np.sqrt(mean_squared_error(a,b)))\n",
    "\n",
    "def skill(y_true, y_pred, y_base):\n",
    "    return 1.0 - (_rmse(y_true, y_pred) / _rmse(y_true, y_base))\n",
    "\n",
    "def _build_seq(X_df, y_ser, L):\n",
    "    \"\"\"Secuencias sin índice (rápido para objetivos Optuna).\"\"\"\n",
    "    Xv, yv = X_df.values, y_ser.values\n",
    "    xs, ys = [], []\n",
    "    for i in range(L-1, len(X_df)):\n",
    "        block = Xv[i-L+1:i+1]\n",
    "        if np.isnan(block).any():\n",
    "            continue\n",
    "        xs.append(block); ys.append(yv[i])\n",
    "    return np.asarray(xs, dtype=\"float32\"), np.asarray(ys, dtype=\"float32\")\n",
    "\n",
    "def build_seq_with_idx(X_df, y_ser, L):\n",
    "    \"\"\"Secuencias con índice (para evaluación y plots).\"\"\"\n",
    "    Xv, yv = X_df.values, y_ser.values\n",
    "    xs, ys, idx = [], [], []\n",
    "    for i in range(L-1, len(X_df)):\n",
    "        block = Xv[i-L+1:i+1]\n",
    "        if np.isnan(block).any():\n",
    "            continue\n",
    "        xs.append(block); ys.append(yv[i]); idx.append(X_df.index[i])\n",
    "    return (np.asarray(xs, dtype=\"float32\"),\n",
    "            np.asarray(ys, dtype=\"float32\"),\n",
    "            pd.DatetimeIndex(idx))\n",
    "\n",
    "def prepare_journal_storage(study_name: str) -> JournalStorage:\n",
    "    log_path   = STUDY_DIR / f\"{study_name}.log\"\n",
    "    lock_path  = STUDY_DIR / f\"{study_name}.lock\"\n",
    "    try: lock_path.unlink()\n",
    "    except FileNotFoundError: pass\n",
    "    file_storage = JournalFileStorage(str(log_path), lock_obj=JournalFileOpenLock(str(lock_path)))\n",
    "    return JournalStorage(file_storage)\n",
    "\n",
    "# def _safe_load_best(study, rebuild_fn=None):\n",
    "#     \"\"\"Carga robusta del mejor modelo guardado por el estudio.\"\"\"\n",
    "#     p = Path(study.best_trial.user_attrs[\"model_path\"])\n",
    "#     if not p.exists():\n",
    "#         # fallback: buscar por nombre\n",
    "#         hits = list(ART_DIR.rglob(p.name))\n",
    "#         if hits:\n",
    "#             p = hits[0]\n",
    "#         elif rebuild_fn is not None:\n",
    "#             model = rebuild_fn(study.best_trial.params)\n",
    "#             p = ART_DIR / \"recover.keras\"\n",
    "#             model.save(p)\n",
    "#         else:\n",
    "#             raise FileNotFoundError(f\"Checkpoint not found: {p}\")\n",
    "#     return tf.keras.models.load_model(p), p"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e762b245",
   "metadata": {},
   "source": [
    "### Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "69ab07d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_mlp(input_dim, n1=128, n2=64, do1=0.2, do2=0.1, act=\"relu\", l2w=0.0):\n",
    "    return tf.keras.Sequential([\n",
    "        layers.Input(shape=(input_dim,)),\n",
    "        layers.Dense(n1, activation=act, kernel_regularizer=regularizers.l2(l2w)),\n",
    "        layers.Dropout(do1),\n",
    "        layers.Dense(n2, activation=act, kernel_regularizer=regularizers.l2(l2w)),\n",
    "        layers.Dropout(do2),\n",
    "        layers.Dense(1, dtype=\"float32\"),\n",
    "    ])\n",
    "\n",
    "def build_lstm(L, n_feat, units=64, do=0.0):\n",
    "    inp = layers.Input(shape=(L, n_feat))\n",
    "    x   = layers.LSTM(units, dropout=do)(inp)\n",
    "    out = layers.Dense(1, dtype=\"float32\")(x)\n",
    "    return tf.keras.Model(inp, out)\n",
    "\n",
    "def build_bilstm(L, n_feat, units=64, do=0.0):\n",
    "    inp = layers.Input(shape=(L, n_feat))\n",
    "    x   = layers.Bidirectional(layers.LSTM(units, dropout=do))(inp)\n",
    "    out = layers.Dense(1, dtype=\"float32\")(x)\n",
    "    return tf.keras.Model(inp, out)\n",
    "\n",
    "def build_cnnlstm(L, n_feat, filt=32, ksz=3, pool=1, lstm_units=64, do=0.0):\n",
    "    inp = layers.Input(shape=(L, n_feat))\n",
    "    x   = layers.Conv1D(filt, kernel_size=ksz, padding=\"causal\", activation=\"relu\")(inp)\n",
    "    x   = (layers.MaxPooling1D(pool_size=pool)(x) if pool>1 else layers.Identity()(x))\n",
    "    x   = layers.LSTM(lstm_units, dropout=do)(x)\n",
    "    out = layers.Dense(1, dtype=\"float32\")(x)\n",
    "    return tf.keras.Model(inp, out)\n",
    "\n",
    "def build_transformer(L, n_feat, d_model=64, heads=4, ff_dim=128, att_do=0.1, do=0.0):\n",
    "    inp = layers.Input(shape=(L, n_feat))\n",
    "    x   = layers.Dense(d_model)(inp)\n",
    "    x2  = layers.MultiHeadAttention(num_heads=heads, key_dim=d_model//heads, dropout=att_do)(x, x)\n",
    "    x   = layers.Add()([x, x2]); x = layers.LayerNormalization()(x)\n",
    "    ff  = layers.Dense(ff_dim, activation=\"relu\")(x); ff = layers.Dense(d_model)(ff)\n",
    "    x   = layers.Add()([x, ff]); x = layers.LayerNormalization()(x)\n",
    "    x   = layers.GlobalAveragePooling1D()(x)\n",
    "    x   = layers.Dropout(do)(x)\n",
    "    out = layers.Dense(1, dtype=\"float32\")(x)\n",
    "    return tf.keras.Model(inp, out)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7fc2449",
   "metadata": {},
   "source": [
    "### Saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3518825a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _safe_load_best(study):\n",
    "    \"\"\"\n",
    "    Carga robusta: si el best_trial no tiene los nuevos user_attrs (arch, seq_len_used, n_feat),\n",
    "    los infiere desde study_name / ruta del checkpoint / params del trial.\n",
    "    Reconstruye la arquitectura y carga PESOS (.weights.h5 o .keras/.h5 legacy).\n",
    "    \"\"\"\n",
    "    ua = dict(study.best_trial.user_attrs) if study.best_trial.user_attrs else {}\n",
    "\n",
    "    # 1) Localiza el checkpoint\n",
    "    wpath = None\n",
    "    if \"model_path\" in ua:\n",
    "        p = Path(ua[\"model_path\"])\n",
    "        if p.exists():\n",
    "            wpath = p\n",
    "        else:\n",
    "            hits = list(ART_DIR.rglob(p.name))\n",
    "            if hits:\n",
    "                wpath = hits[0]\n",
    "    if wpath is None:\n",
    "        # Fallback: deduce por nombre de estudio\n",
    "        # Busca archivos 'best.weights.h5' o 'best.keras' en ART_DIR que coincidan con el estudio\n",
    "        patt = []\n",
    "        name = (study.study_name or \"\").lower()\n",
    "        if \"mlp\" in name: patt.append(\"A_mlp_*\")\n",
    "        if \"lstm\" in name and \"bilstm\" not in name: patt.append(\"B_lstm_*\")\n",
    "        if \"bilstm\" in name: patt.append(\"B_bilstm_*\")\n",
    "        if \"cnn\" in name: patt.append(\"B_cnnlstm_*\")\n",
    "        if \"transformer\" in name: patt.append(\"B_transformer_*\")\n",
    "        candidates = []\n",
    "        for pat in (patt or [\"*\"]):\n",
    "            candidates += list(ART_DIR.glob(f\"{pat}/best.weights.h5\"))\n",
    "            candidates += list(ART_DIR.glob(f\"{pat}/best.keras\"))\n",
    "            candidates += list(ART_DIR.glob(f\"{pat}/best.h5\"))\n",
    "        if not candidates:\n",
    "            raise FileNotFoundError(\"No checkpoint found for best trial and no user_attrs['model_path'].\")\n",
    "        # Toma el más reciente\n",
    "        wpath = max(candidates, key=lambda p: p.stat().st_mtime)\n",
    "\n",
    "    # 2) Deducir 'arch'\n",
    "    arch = ua.get(\"arch\")\n",
    "    base = wpath.parent.name.lower()\n",
    "    sname = (study.study_name or \"\").lower()\n",
    "    if arch is None:\n",
    "        if \"mlp\" in sname or base.startswith(\"a_mlp\"):\n",
    "            arch = \"mlp\"\n",
    "        elif \"bilstm\" in sname or \"b_bilstm\" in base:\n",
    "            arch = \"bilstm\"\n",
    "        elif (\"lstm\" in sname and \"bilstm\" not in sname) or \"b_lstm\" in base:\n",
    "            arch = \"lstm\"\n",
    "        elif \"cnn\" in sname or \"cnn\" in base:\n",
    "            arch = \"cnn-lstm\"\n",
    "        elif \"transformer\" in sname or \"transformer\" in base:\n",
    "            arch = \"transformer\"\n",
    "        else:\n",
    "            raise KeyError(\"Cannot infer 'arch' from study; please re-run trials or set user_attrs.\")\n",
    "\n",
    "    # 3) Deducir L y n_feat para secuenciales\n",
    "    params = study.best_trial.params\n",
    "    L = ua.get(\"seq_len_used\") or params.get(\"seq_len\")\n",
    "    n_feat = ua.get(\"n_feat\")\n",
    "    if arch != \"mlp\":\n",
    "        if L is None:\n",
    "            # default razonable si faltara\n",
    "            L = 12\n",
    "        if n_feat is None:\n",
    "            # usar el contexto global ya cargado\n",
    "            n_feat = int(Xtr_s.shape[1])\n",
    "\n",
    "    # 4) Reconstruye modelo y carga pesos / modelo\n",
    "    # (acepta tanto weights-only como modelo completo legacy)\n",
    "    if wpath.suffix in {\".keras\", \".h5\"} and \"weights\" not in wpath.name:\n",
    "        # Legacy: modelo completo; cargar con safe_mode desactivado SOLO si confías en el archivo\n",
    "        import keras\n",
    "        try:\n",
    "            keras.config.enable_unsafe_deserialization()\n",
    "        except Exception:\n",
    "            pass\n",
    "        model = tf.keras.models.load_model(wpath, compile=False, safe_mode=False)\n",
    "        model.compile(optimizer=\"adam\", loss=\"mse\", metrics=[\"mae\"])\n",
    "        return model, wpath\n",
    "\n",
    "    # Weights-only (recomendado)\n",
    "    if arch == \"mlp\":\n",
    "        model = build_mlp(\n",
    "            input_dim=Xtr.shape[1],\n",
    "            n1=params.get(\"n1\",128),\n",
    "            n2=params.get(\"n2\",64),\n",
    "            do1=params.get(\"do1\",0.0),\n",
    "            do2=params.get(\"do2\",0.0),\n",
    "            act=params.get(\"act\",\"relu\"),\n",
    "            l2w=params.get(\"l2\",0.0),\n",
    "        )\n",
    "    elif arch == \"lstm\":\n",
    "        model = build_lstm(int(L), int(n_feat),\n",
    "                           units=params.get(\"units\",64),\n",
    "                           do=params.get(\"dropout\",0.0))\n",
    "    elif arch == \"bilstm\":\n",
    "        model = build_bilstm(int(L), int(n_feat),\n",
    "                             units=params.get(\"units\",64),\n",
    "                             do=params.get(\"dropout\",0.0))\n",
    "    elif arch == \"cnn-lstm\":\n",
    "        model = build_cnnlstm(int(L), int(n_feat),\n",
    "                              filt=params.get(\"filters\",32),\n",
    "                              ksz=params.get(\"kernel_size\",3),\n",
    "                              pool=params.get(\"pool\",1),\n",
    "                              lstm_units=params.get(\"lstm_units\",64),\n",
    "                              do=params.get(\"dropout\",0.0))\n",
    "    elif arch == \"transformer\":\n",
    "        model = build_transformer(int(L), int(n_feat),\n",
    "                                  d_model=params.get(\"d_model\",64),\n",
    "                                  heads=params.get(\"heads\",4),\n",
    "                                  ff_dim=params.get(\"ff_dim\",128),\n",
    "                                  att_do=params.get(\"att_dropout\",0.1),\n",
    "                                  do=params.get(\"dropout\",0.0))\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown arch: {arch}\")\n",
    "\n",
    "    model.compile(optimizer=\"adam\", loss=\"mse\", metrics=[\"mae\"])\n",
    "    model.load_weights(str(wpath))\n",
    "    return model, wpath\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd38d785",
   "metadata": {},
   "source": [
    "## Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1d7b3333",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline → RMSE: 196.2835 | MAE: 102.1871\n"
     ]
    }
   ],
   "source": [
    "base_src = None\n",
    "\n",
    "# for c in [\"k_ghi\",\"k_raw\",\"k_ghi_lag1\",\"k_raw_lag1\"]:\n",
    "#     if c in test.columns: base_src = test[c]; break\n",
    "# if base_src is None:\n",
    "#     base_src = pd.Series(np.nanmedian(ytr), index=test.index)\n",
    "\n",
    "for c in [\"ghi_qc\",\"ghi_sg_definitive\",\"ghi_qc_lag1\"]:\n",
    "    if c in test.columns: base_src = test[c]; break\n",
    "if base_src is None:\n",
    "    base_src = pd.Series(np.nanmedian(ytr), index=test.index)\n",
    "\n",
    "y_base = base_src.to_numpy()\n",
    "print(f\"Baseline → RMSE: {_rmse(yte, y_base):.4f} | MAE: {mean_absolute_error(yte, y_base):.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b684d0e0",
   "metadata": {},
   "source": [
    "## Track A - MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a2285184",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_mlp(trial: optuna.Trial) -> float:\n",
    "    K.clear_session()\n",
    "    n1  = trial.suggest_int(\"n1\", 64, 512, step=64)\n",
    "    n2  = trial.suggest_int(\"n2\", 32, max(64, n1//2), step=32)\n",
    "    do1 = trial.suggest_float(\"do1\", 0.0, 0.5)\n",
    "    do2 = trial.suggest_float(\"do2\", 0.0, 0.5)\n",
    "    lr  = trial.suggest_float(\"lr\", 1e-4, 5e-3, log=True)\n",
    "    l2w = trial.suggest_float(\"l2\", 1e-8, 1e-3, log=True)\n",
    "    act = trial.suggest_categorical(\"act\", [\"relu\",\"selu\",\"gelu\"])\n",
    "    bs  = trial.suggest_categorical(\"batch\", [64, 128, 256, 512])\n",
    "    eps = trial.suggest_int(\"epochs\", 40, 150)\n",
    "\n",
    "    model = build_mlp(Xtr.shape[1], n1=n1, n2=n2, do1=do1, do2=do2, act=act, l2w=l2w)\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=lr),\n",
    "                  loss=\"mse\", metrics=[\"mae\"])\n",
    "\n",
    "    tmp_dir  = ART_DIR / f\"A_mlp_t{trial.number:04d}\"; tmp_dir.mkdir(parents=True, exist_ok=True)\n",
    "    tmp_path = (tmp_dir / \"best.weights.h5\").resolve()\n",
    "\n",
    "    cbs = [\n",
    "        callbacks.EarlyStopping(monitor=\"val_loss\", patience=12, restore_best_weights=True, verbose=0),\n",
    "        callbacks.ReduceLROnPlateau(monitor=\"val_loss\", factor=0.5, patience=6, min_lr=1e-5, verbose=0),\n",
    "        callbacks.ModelCheckpoint(filepath=str(tmp_path), monitor=\"val_loss\",\n",
    "                                  save_best_only=True, save_weights_only=True),\n",
    "        TFKerasPruningCallback(trial, \"val_loss\"),\n",
    "    ]\n",
    "\n",
    "    model.fit(Xtr, ytr, validation_data=(Xva, yva),\n",
    "              epochs=eps, batch_size=bs, verbose=0, callbacks=cbs)\n",
    "\n",
    "    yhat = model.predict(Xva, verbose=0).squeeze()\n",
    "    val_rmse = _rmse(yva, yhat)\n",
    "\n",
    "    trial.set_user_attr(\"model_path\", str(tmp_path))\n",
    "    trial.set_user_attr(\"arch\", \"mlp\")\n",
    "    trial.set_user_attr(\"input_dim\", Xtr.shape[1])\n",
    "    return val_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fb7a4566",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1170388/3240221310.py:36: FutureWarning: The import path :class:`~optuna.storages.JournalFileOpenLock` has been deprecated in v4.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v4.0.0. Use :class:`~optuna.storages.journal.JournalFileOpenLock` instead.\n",
      "  file_storage = JournalFileStorage(str(log_path), lock_obj=JournalFileOpenLock(str(lock_path)))\n",
      "/tmp/ipykernel_1170388/3240221310.py:36: FutureWarning: JournalFileStorage has been deprecated in v4.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v4.0.0. Use :class:`~optuna.storages.journal.JournalFileBackend` instead.\n",
      "  file_storage = JournalFileStorage(str(log_path), lock_obj=JournalFileOpenLock(str(lock_path)))\n",
      "[I 2025-10-06 09:30:47,914] A new study created in Journal with name: ground_trackA_mlp\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Study A (MLP)…\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c207891b457148ed9e1d1112edebe6a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1759761049.074930 1171030 service.cc:148] XLA service 0x7e7070005210 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1759761049.074954 1171030 service.cc:156]   StreamExecutor device (0): NVIDIA GeForce RTX 4090, Compute Capability 8.9\n",
      "2025-10-06 09:30:49.086167: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "I0000 00:00:1759761049.127056 1171030 cuda_dnn.cc:529] Loaded cuDNN version 90101\n",
      "I0000 00:00:1759761049.550679 1171030 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-06 09:31:05,845] Trial 0 finished with value: 131.04182150891754 and parameters: {'n1': 192, 'n2': 96, 'do1': 0.36599697090570255, 'do2': 0.2993292420985183, 'lr': 0.00018410729205738696, 'l2': 6.02521573620385e-08, 'act': 'selu', 'batch': 256, 'epochs': 63}. Best is trial 0 with value: 131.04182150891754.\n",
      "[I 2025-10-06 09:31:28,745] Trial 1 finished with value: 130.37151691176643 and parameters: {'n1': 128, 'n2': 32, 'do1': 0.15212112147976886, 'do2': 0.2623782158161189, 'lr': 0.0005418282319533242, 'l2': 2.8585493941961875e-07, 'act': 'relu', 'batch': 256, 'epochs': 97}. Best is trial 1 with value: 130.37151691176643.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-06 09:31:31.280953: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_48', 24 bytes spill stores, 24 bytes spill loads\n",
      "\n",
      "2025-10-06 09:31:31.355509: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_48', 388 bytes spill stores, 388 bytes spill loads\n",
      "\n",
      "2025-10-06 09:31:31.851422: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_48', 48 bytes spill stores, 48 bytes spill loads\n",
      "\n",
      "2025-10-06 09:31:31.897673: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_48', 404 bytes spill stores, 404 bytes spill loads\n",
      "\n",
      "2025-10-06 09:32:06.308903: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_16', 24 bytes spill stores, 24 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-06 09:32:06,677] Trial 2 finished with value: 130.85236641679433 and parameters: {'n1': 320, 'n2': 32, 'do1': 0.3037724259507192, 'do2': 0.08526206184364576, 'lr': 0.00012897950480855554, 'l2': 0.000555172168524472, 'act': 'relu', 'batch': 128, 'epochs': 94}. Best is trial 1 with value: 130.37151691176643.\n",
      "[I 2025-10-06 09:32:40,764] Trial 3 finished with value: 130.43687859219494 and parameters: {'n1': 64, 'n2': 64, 'do1': 0.12938999080000846, 'do2': 0.331261142176991, 'lr': 0.00033852267834519784, 'l2': 3.984190594434684e-06, 'act': 'gelu', 'batch': 128, 'epochs': 142}. Best is trial 1 with value: 130.37151691176643.\n",
      "[I 2025-10-06 09:33:04,315] Trial 4 finished with value: 130.44268826528761 and parameters: {'n1': 64, 'n2': 32, 'do1': 0.022613644455269033, 'do2': 0.16266516538163217, 'lr': 0.00045745782054754043, 'l2': 2.2737628102536842e-07, 'act': 'relu', 'batch': 256, 'epochs': 149}. Best is trial 1 with value: 130.37151691176643.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-06 09:33:06.611635: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_48', 196 bytes spill stores, 196 bytes spill loads\n",
      "\n",
      "2025-10-06 09:33:06.806065: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_48', 956 bytes spill stores, 960 bytes spill loads\n",
      "\n",
      "2025-10-06 09:33:07.251713: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_48', 12 bytes spill stores, 12 bytes spill loads\n",
      "\n",
      "2025-10-06 09:33:07.353886: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_48', 192 bytes spill stores, 192 bytes spill loads\n",
      "\n",
      "2025-10-06 09:33:07.522544: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_48', 1036 bytes spill stores, 940 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[W 2025-10-06 09:33:12,734] Trial 5 failed with parameters: {'n1': 448, 'n2': 64, 'do1': 0.0027610585618011996, 'do2': 0.4077307142274171, 'lr': 0.0015882886211970053, 'l2': 4.416068895118589e-05, 'act': 'relu', 'batch': 128, 'epochs': 47} because of the following error: KeyboardInterrupt().\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/e.ladino/miniconda3/envs/e_ladino/lib/python3.12/site-packages/optuna/study/_optimize.py\", line 201, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "                      ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_1170388/1771783720.py\", line 28, in objective_mlp\n",
      "    model.fit(Xtr, ytr, validation_data=(Xva, yva),\n",
      "  File \"/home/e.ladino/miniconda3/envs/e_ladino/lib/python3.12/site-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\n",
      "    return fn(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/e.ladino/miniconda3/envs/e_ladino/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py\", line 377, in fit\n",
      "    logs = self.train_function(iterator)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/e.ladino/miniconda3/envs/e_ladino/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py\", line 220, in function\n",
      "    opt_outputs = multi_step_on_iterator(iterator)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/e.ladino/miniconda3/envs/e_ladino/lib/python3.12/site-packages/tensorflow/python/util/traceback_utils.py\", line 150, in error_handler\n",
      "    return fn(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/e.ladino/miniconda3/envs/e_ladino/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\", line 833, in __call__\n",
      "    result = self._call(*args, **kwds)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/e.ladino/miniconda3/envs/e_ladino/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\", line 878, in _call\n",
      "    results = tracing_compilation.call_function(\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/e.ladino/miniconda3/envs/e_ladino/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py\", line 138, in call_function\n",
      "    flat_inputs = function.function_type.unpack_inputs(bound_args)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/e.ladino/miniconda3/envs/e_ladino/lib/python3.12/site-packages/tensorflow/core/function/polymorphism/function_type.py\", line 391, in unpack_inputs\n",
      "    p.type_constraint.to_tensors(bound_parameters.arguments[p.name])\n",
      "  File \"/home/e.ladino/miniconda3/envs/e_ladino/lib/python3.12/site-packages/tensorflow/python/framework/type_spec.py\", line 253, in to_tensors\n",
      "    self._component_specs,\n",
      "    ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/e.ladino/miniconda3/envs/e_ladino/lib/python3.12/site-packages/tensorflow/python/data/ops/iterator_ops.py\", line 965, in _component_specs\n",
      "    return (tensor.TensorSpec([], dtypes.resource),)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/e.ladino/miniconda3/envs/e_ladino/lib/python3.12/site-packages/tensorflow/python/framework/tensor.py\", line 853, in __init__\n",
      "    def __init__(self, shape, dtype=dtypes.float32, name=None):\n",
      "    \n",
      "KeyboardInterrupt\n",
      "[W 2025-10-06 09:33:12,737] Trial 5 failed with value None.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 8\u001b[39m\n\u001b[32m      2\u001b[39m studyA = optuna.create_study(direction=\u001b[33m\"\u001b[39m\u001b[33mminimize\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m      3\u001b[39m                              sampler=TPESampler(seed=SEED),\n\u001b[32m      4\u001b[39m                              pruner=MedianPruner(n_startup_trials=\u001b[32m8\u001b[39m, n_warmup_steps=\u001b[32m5\u001b[39m),\n\u001b[32m      5\u001b[39m                              study_name=\u001b[33m\"\u001b[39m\u001b[33mground_trackA_mlp\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m      6\u001b[39m                              storage=storageA, load_if_exists=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m      7\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mRunning Study A (MLP)…\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m \u001b[43mstudyA\u001b[49m\u001b[43m.\u001b[49m\u001b[43moptimize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobjective_mlp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m40\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m     10\u001b[39m best_mlp, bestA_path = _safe_load_best(studyA)\n\u001b[32m     11\u001b[39m yhatA = best_mlp.predict(Xte, verbose=\u001b[32m0\u001b[39m).squeeze()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/e_ladino/lib/python3.12/site-packages/optuna/study/study.py:490\u001b[39m, in \u001b[36mStudy.optimize\u001b[39m\u001b[34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[39m\n\u001b[32m    388\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34moptimize\u001b[39m(\n\u001b[32m    389\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    390\u001b[39m     func: ObjectiveFuncType,\n\u001b[32m   (...)\u001b[39m\u001b[32m    397\u001b[39m     show_progress_bar: \u001b[38;5;28mbool\u001b[39m = \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m    398\u001b[39m ) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    399\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[32m    400\u001b[39m \n\u001b[32m    401\u001b[39m \u001b[33;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    488\u001b[39m \u001b[33;03m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[32m    489\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m490\u001b[39m     \u001b[43m_optimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    491\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    492\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    493\u001b[39m \u001b[43m        \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    494\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    495\u001b[39m \u001b[43m        \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    496\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mIterable\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    497\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    498\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    499\u001b[39m \u001b[43m        \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m=\u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    500\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/e_ladino/lib/python3.12/site-packages/optuna/study/_optimize.py:63\u001b[39m, in \u001b[36m_optimize\u001b[39m\u001b[34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[39m\n\u001b[32m     61\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     62\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m n_jobs == \u001b[32m1\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m63\u001b[39m         \u001b[43m_optimize_sequential\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     64\u001b[39m \u001b[43m            \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     65\u001b[39m \u001b[43m            \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     66\u001b[39m \u001b[43m            \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     67\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     68\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     69\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     70\u001b[39m \u001b[43m            \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     71\u001b[39m \u001b[43m            \u001b[49m\u001b[43mreseed_sampler_rng\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     72\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtime_start\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     73\u001b[39m \u001b[43m            \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     74\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     75\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     76\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m n_jobs == -\u001b[32m1\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/e_ladino/lib/python3.12/site-packages/optuna/study/_optimize.py:160\u001b[39m, in \u001b[36m_optimize_sequential\u001b[39m\u001b[34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[39m\n\u001b[32m    157\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m    159\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m160\u001b[39m     frozen_trial_id = \u001b[43m_run_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    161\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    162\u001b[39m     \u001b[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[32m    163\u001b[39m     \u001b[38;5;66;03m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[32m    164\u001b[39m     \u001b[38;5;66;03m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[32m    165\u001b[39m     \u001b[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[32m    166\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m gc_after_trial:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/e_ladino/lib/python3.12/site-packages/optuna/study/_optimize.py:258\u001b[39m, in \u001b[36m_run_trial\u001b[39m\u001b[34m(study, func, catch)\u001b[39m\n\u001b[32m    251\u001b[39m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[33m\"\u001b[39m\u001b[33mShould not reach.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    253\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    254\u001b[39m     updated_state == TrialState.FAIL\n\u001b[32m    255\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m func_err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    256\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func_err, catch)\n\u001b[32m    257\u001b[39m ):\n\u001b[32m--> \u001b[39m\u001b[32m258\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m func_err\n\u001b[32m    259\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m trial._trial_id\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/e_ladino/lib/python3.12/site-packages/optuna/study/_optimize.py:201\u001b[39m, in \u001b[36m_run_trial\u001b[39m\u001b[34m(study, func, catch)\u001b[39m\n\u001b[32m    199\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m get_heartbeat_thread(trial._trial_id, study._storage):\n\u001b[32m    200\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m201\u001b[39m         value_or_values = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    202\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m exceptions.TrialPruned \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    203\u001b[39m         \u001b[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[32m    204\u001b[39m         state = TrialState.PRUNED\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 28\u001b[39m, in \u001b[36mobjective_mlp\u001b[39m\u001b[34m(trial)\u001b[39m\n\u001b[32m     18\u001b[39m tmp_path = (tmp_dir / \u001b[33m\"\u001b[39m\u001b[33mbest.weights.h5\u001b[39m\u001b[33m\"\u001b[39m).resolve()\n\u001b[32m     20\u001b[39m cbs = [\n\u001b[32m     21\u001b[39m     callbacks.EarlyStopping(monitor=\u001b[33m\"\u001b[39m\u001b[33mval_loss\u001b[39m\u001b[33m\"\u001b[39m, patience=\u001b[32m12\u001b[39m, restore_best_weights=\u001b[38;5;28;01mTrue\u001b[39;00m, verbose=\u001b[32m0\u001b[39m),\n\u001b[32m     22\u001b[39m     callbacks.ReduceLROnPlateau(monitor=\u001b[33m\"\u001b[39m\u001b[33mval_loss\u001b[39m\u001b[33m\"\u001b[39m, factor=\u001b[32m0.5\u001b[39m, patience=\u001b[32m6\u001b[39m, min_lr=\u001b[32m1e-5\u001b[39m, verbose=\u001b[32m0\u001b[39m),\n\u001b[32m   (...)\u001b[39m\u001b[32m     25\u001b[39m     TFKerasPruningCallback(trial, \u001b[33m\"\u001b[39m\u001b[33mval_loss\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m     26\u001b[39m ]\n\u001b[32m---> \u001b[39m\u001b[32m28\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mXtr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mytr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[43mXva\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43myva\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     29\u001b[39m \u001b[43m          \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcbs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     31\u001b[39m yhat = model.predict(Xva, verbose=\u001b[32m0\u001b[39m).squeeze()\n\u001b[32m     32\u001b[39m val_rmse = _rmse(yva, yhat)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/e_ladino/lib/python3.12/site-packages/keras/src/utils/traceback_utils.py:117\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    115\u001b[39m filtered_tb = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    116\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m117\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    118\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    119\u001b[39m     filtered_tb = _process_traceback_frames(e.__traceback__)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/e_ladino/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py:377\u001b[39m, in \u001b[36mTensorFlowTrainer.fit\u001b[39m\u001b[34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[39m\n\u001b[32m    375\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m begin_step, end_step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator:\n\u001b[32m    376\u001b[39m     callbacks.on_train_batch_begin(begin_step)\n\u001b[32m--> \u001b[39m\u001b[32m377\u001b[39m     logs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    378\u001b[39m     callbacks.on_train_batch_end(end_step, logs)\n\u001b[32m    379\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.stop_training:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/e_ladino/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py:220\u001b[39m, in \u001b[36mTensorFlowTrainer._make_function.<locals>.function\u001b[39m\u001b[34m(iterator)\u001b[39m\n\u001b[32m    216\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mfunction\u001b[39m(iterator):\n\u001b[32m    217\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\n\u001b[32m    218\u001b[39m         iterator, (tf.data.Iterator, tf.distribute.DistributedIterator)\n\u001b[32m    219\u001b[39m     ):\n\u001b[32m--> \u001b[39m\u001b[32m220\u001b[39m         opt_outputs = \u001b[43mmulti_step_on_iterator\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    221\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m opt_outputs.has_value():\n\u001b[32m    222\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/e_ladino/lib/python3.12/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    148\u001b[39m filtered_tb = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    149\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m150\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    151\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    152\u001b[39m   filtered_tb = _process_traceback_frames(e.__traceback__)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/e_ladino/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:833\u001b[39m, in \u001b[36mFunction.__call__\u001b[39m\u001b[34m(self, *args, **kwds)\u001b[39m\n\u001b[32m    830\u001b[39m compiler = \u001b[33m\"\u001b[39m\u001b[33mxla\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mnonXla\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    832\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m._jit_compile):\n\u001b[32m--> \u001b[39m\u001b[32m833\u001b[39m   result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    835\u001b[39m new_tracing_count = \u001b[38;5;28mself\u001b[39m.experimental_get_tracing_count()\n\u001b[32m    836\u001b[39m without_tracing = (tracing_count == new_tracing_count)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/e_ladino/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:878\u001b[39m, in \u001b[36mFunction._call\u001b[39m\u001b[34m(self, *args, **kwds)\u001b[39m\n\u001b[32m    875\u001b[39m \u001b[38;5;28mself\u001b[39m._lock.release()\n\u001b[32m    876\u001b[39m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[32m    877\u001b[39m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m878\u001b[39m results = \u001b[43mtracing_compilation\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    879\u001b[39m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_variable_creation_config\u001b[49m\n\u001b[32m    880\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    881\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._created_variables:\n\u001b[32m    882\u001b[39m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mCreating variables on a non-first call to a function\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    883\u001b[39m                    \u001b[33m\"\u001b[39m\u001b[33m decorated with tf.function.\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/e_ladino/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:138\u001b[39m, in \u001b[36mcall_function\u001b[39m\u001b[34m(args, kwargs, tracing_options)\u001b[39m\n\u001b[32m    136\u001b[39m \u001b[38;5;66;03m# Bind it ourselves to skip unnecessary canonicalization of default call.\u001b[39;00m\n\u001b[32m    137\u001b[39m bound_args = function.function_type.bind(*args, **kwargs)\n\u001b[32m--> \u001b[39m\u001b[32m138\u001b[39m flat_inputs = \u001b[43mfunction\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfunction_type\u001b[49m\u001b[43m.\u001b[49m\u001b[43munpack_inputs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbound_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    139\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m function._call_flat(  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[32m    140\u001b[39m     flat_inputs, captured_inputs=function.captured_inputs\n\u001b[32m    141\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/e_ladino/lib/python3.12/site-packages/tensorflow/core/function/polymorphism/function_type.py:391\u001b[39m, in \u001b[36mFunctionType.unpack_inputs\u001b[39m\u001b[34m(self, bound_parameters)\u001b[39m\n\u001b[32m    388\u001b[39m flat = []\n\u001b[32m    389\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m sorted_parameters:\n\u001b[32m    390\u001b[39m   flat.extend(\n\u001b[32m--> \u001b[39m\u001b[32m391\u001b[39m       \u001b[43mp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtype_constraint\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto_tensors\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbound_parameters\u001b[49m\u001b[43m.\u001b[49m\u001b[43marguments\u001b[49m\u001b[43m[\u001b[49m\u001b[43mp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mname\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    392\u001b[39m   )\n\u001b[32m    394\u001b[39m dealiased_inputs = []\n\u001b[32m    395\u001b[39m ids_used = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/e_ladino/lib/python3.12/site-packages/tensorflow/python/framework/type_spec.py:253\u001b[39m, in \u001b[36mTypeSpec.to_tensors\u001b[39m\u001b[34m(self, value)\u001b[39m\n\u001b[32m    248\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"See TraceType base class for details. Do not override.\"\"\"\u001b[39;00m\n\u001b[32m    250\u001b[39m tensors = []\n\u001b[32m    251\u001b[39m nest.map_structure(\n\u001b[32m    252\u001b[39m     \u001b[38;5;28;01mlambda\u001b[39;00m spec, v: tensors.extend(spec.to_tensors(v)),\n\u001b[32m--> \u001b[39m\u001b[32m253\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_component_specs\u001b[49m,\n\u001b[32m    254\u001b[39m     \u001b[38;5;28mself\u001b[39m._to_components(value))\n\u001b[32m    255\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m tensors\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/e_ladino/lib/python3.12/site-packages/tensorflow/python/data/ops/iterator_ops.py:965\u001b[39m, in \u001b[36mIteratorSpec._component_specs\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    963\u001b[39m \u001b[38;5;129m@property\u001b[39m\n\u001b[32m    964\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_component_specs\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m965\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[43mtensor\u001b[49m\u001b[43m.\u001b[49m\u001b[43mTensorSpec\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtypes\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresource\u001b[49m\u001b[43m)\u001b[49m,)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/e_ladino/lib/python3.12/site-packages/tensorflow/python/framework/tensor.py:853\u001b[39m, in \u001b[36mDenseSpec.__init__\u001b[39m\u001b[34m(self, shape, dtype, name)\u001b[39m\n\u001b[32m    849\u001b[39m \u001b[34m__slots__\u001b[39m = [\u001b[33m\"\u001b[39m\u001b[33m_shape\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33m_dtype\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33m_name\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m    851\u001b[39m _component_specs = \u001b[38;5;28mproperty\u001b[39m(\u001b[38;5;28;01mlambda\u001b[39;00m \u001b[38;5;28mself\u001b[39m: \u001b[38;5;28mself\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m853\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, shape, dtype=dtypes.float32, name=\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m    854\u001b[39m \u001b[38;5;250m  \u001b[39m\u001b[33;03m\"\"\"Creates a TensorSpec.\u001b[39;00m\n\u001b[32m    855\u001b[39m \n\u001b[32m    856\u001b[39m \u001b[33;03m  Args:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    863\u001b[39m \u001b[33;03m      not convertible to a `tf.DType`.\u001b[39;00m\n\u001b[32m    864\u001b[39m \u001b[33;03m  \"\"\"\u001b[39;00m\n\u001b[32m    865\u001b[39m   \u001b[38;5;28mself\u001b[39m._shape = tensor_shape.TensorShape(shape)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "storageA = prepare_journal_storage(\"ground_trackA_mlp\")\n",
    "studyA = optuna.create_study(direction=\"minimize\",\n",
    "                             sampler=TPESampler(seed=SEED),\n",
    "                             pruner=MedianPruner(n_startup_trials=8, n_warmup_steps=5),\n",
    "                             study_name=\"ground_trackA_mlp\",\n",
    "                             storage=storageA, load_if_exists=True)\n",
    "print(\"Running Study A (MLP)…\")\n",
    "studyA.optimize(objective_mlp, n_trials=40, show_progress_bar=True)\n",
    "\n",
    "best_mlp, bestA_path = _safe_load_best(studyA)\n",
    "yhatA = best_mlp.predict(Xte, verbose=0).squeeze()\n",
    "print(\"Best MLP params:\", studyA.best_trial.params)\n",
    "print(f\"MLP test → RMSE: {_rmse(yte, yhatA):.4f} | MAE: {mean_absolute_error(yte, yhatA):.4f} | R2: {r2_score(yte, yhatA):.4f} | Skill: {skill(yte, yhatA, y_base):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccd9c63c",
   "metadata": {},
   "source": [
    "## Track B - Sequentials"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "185cbc5c",
   "metadata": {},
   "source": [
    "### Mods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b89bcd3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtr_s = pd.DataFrame(Xtr, index=Xtr_df.index, columns=feat_cols)\n",
    "Xva_s = pd.DataFrame(Xva, index=Xva_df.index, columns=feat_cols)\n",
    "Xte_s = pd.DataFrame(Xte, index=Xte_df.index, columns=feat_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ebeef5d",
   "metadata": {},
   "source": [
    "### LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "392c9a2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_lstm(trial: optuna.Trial) -> float:\n",
    "    K.clear_session()\n",
    "    L   = trial.suggest_categorical(\"seq_len\", [6, 12, 18, 24])\n",
    "    u   = trial.suggest_int(\"units\", 32, 128, step=32)\n",
    "    do  = trial.suggest_float(\"dropout\", 0.0, 0.4)\n",
    "    lr  = trial.suggest_float(\"lr\", 5e-5, 5e-3, log=True)\n",
    "    bs  = trial.suggest_categorical(\"batch\", [64, 128, 256])\n",
    "    eps = trial.suggest_int(\"epochs\", 40, 120)\n",
    "\n",
    "    Xtr_seq, ytr_seq = _build_seq(Xtr_s, ytr, L)\n",
    "    Xva_seq, yva_seq = _build_seq(Xva_s, yva, L)\n",
    "    if min(map(len,[Xtr_seq, Xva_seq])) == 0:\n",
    "        raise optuna.TrialPruned()\n",
    "\n",
    "    model = build_lstm(L, Xtr_seq.shape[2], units=u, do=do)\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=lr), loss=\"mse\", metrics=[\"mae\"])\n",
    "\n",
    "    tmp_dir  = ART_DIR / f\"B_lstm_t{trial.number:04d}\"; tmp_dir.mkdir(parents=True, exist_ok=True)\n",
    "    tmp_path = (tmp_dir / \"best.weights.h5\").resolve()\n",
    "\n",
    "    cbs = [\n",
    "        callbacks.EarlyStopping(monitor=\"val_loss\", patience=10, restore_best_weights=True, verbose=0),\n",
    "        callbacks.ModelCheckpoint(filepath=str(tmp_path), monitor=\"val_loss\",\n",
    "                                  save_best_only=True, save_weights_only=True),\n",
    "        TFKerasPruningCallback(trial, \"val_loss\"),\n",
    "    ]\n",
    "    model.fit(Xtr_seq, ytr_seq, validation_data=(Xva_seq, yva_seq),\n",
    "              epochs=eps, batch_size=bs, verbose=0, callbacks=cbs)\n",
    "\n",
    "    yhat = model.predict(Xva_seq, verbose=0).squeeze()\n",
    "    val_rmse = _rmse(yva_seq, yhat)\n",
    "\n",
    "    trial.set_user_attr(\"model_path\", str(tmp_path))\n",
    "    trial.set_user_attr(\"arch\", \"lstm\")\n",
    "    trial.set_user_attr(\"seq_len_used\", L)\n",
    "    trial.set_user_attr(\"n_feat\", Xtr_s.shape[1])\n",
    "    return val_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6777b424",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_23508/3401579257.py:37: FutureWarning: The import path :class:`~optuna.storages.JournalFileOpenLock` has been deprecated in v4.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v4.0.0. Use :class:`~optuna.storages.journal.JournalFileOpenLock` instead.\n",
      "  file_storage = JournalFileStorage(str(log_path), lock_obj=JournalFileOpenLock(str(lock_path)))\n",
      "/tmp/ipykernel_23508/3401579257.py:37: FutureWarning: JournalFileStorage has been deprecated in v4.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v4.0.0. Use :class:`~optuna.storages.journal.JournalFileBackend` instead.\n",
      "  file_storage = JournalFileStorage(str(log_path), lock_obj=JournalFileOpenLock(str(lock_path)))\n",
      "[I 2025-10-01 11:47:45,330] Using an existing study with name 'ground_trackB_lstm' instead of creating a new one.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Study B1 (LSTM)…\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1fe90d59fca34335a87b505fb524aad2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-01 11:48:12,438] Trial 200 finished with value: 130.18653984283475 and parameters: {'seq_len': 18, 'units': 128, 'dropout': 0.1172490103060074, 'lr': 0.003043678318589167, 'batch': 64, 'epochs': 109}. Best is trial 76 with value: 129.32426541449985.\n",
      "[I 2025-10-01 11:48:36,942] Trial 201 finished with value: 130.56615002078448 and parameters: {'seq_len': 18, 'units': 128, 'dropout': 0.07232375907229845, 'lr': 0.004969705820928518, 'batch': 64, 'epochs': 49}. Best is trial 76 with value: 129.32426541449985.\n",
      "[I 2025-10-01 11:49:01,846] Trial 202 finished with value: 130.27167376054933 and parameters: {'seq_len': 18, 'units': 128, 'dropout': 0.07003913433717746, 'lr': 0.004524343692476639, 'batch': 64, 'epochs': 51}. Best is trial 76 with value: 129.32426541449985.\n",
      "[I 2025-10-01 11:49:26,999] Trial 203 finished with value: 130.69040677063867 and parameters: {'seq_len': 18, 'units': 128, 'dropout': 0.08289988847687813, 'lr': 0.0049973777287680024, 'batch': 64, 'epochs': 49}. Best is trial 76 with value: 129.32426541449985.\n",
      "[I 2025-10-01 11:49:54,837] Trial 204 finished with value: 130.24230723443898 and parameters: {'seq_len': 18, 'units': 128, 'dropout': 0.09087525550641128, 'lr': 0.004547835975844108, 'batch': 64, 'epochs': 40}. Best is trial 76 with value: 129.32426541449985.\n",
      "[I 2025-10-01 11:50:31,866] Trial 205 finished with value: 130.4003076467805 and parameters: {'seq_len': 18, 'units': 128, 'dropout': 0.25279642360148463, 'lr': 0.003680825070029247, 'batch': 64, 'epochs': 58}. Best is trial 76 with value: 129.32426541449985.\n",
      "[I 2025-10-01 11:50:58,898] Trial 206 finished with value: 130.28817968497756 and parameters: {'seq_len': 18, 'units': 128, 'dropout': 0.2020327636501295, 'lr': 0.004066860517499892, 'batch': 64, 'epochs': 55}. Best is trial 76 with value: 129.32426541449985.\n",
      "[I 2025-10-01 11:51:27,453] Trial 207 finished with value: 130.23577627470496 and parameters: {'seq_len': 18, 'units': 128, 'dropout': 0.10555896853357075, 'lr': 0.0027103228537707614, 'batch': 64, 'epochs': 44}. Best is trial 76 with value: 129.32426541449985.\n",
      "[I 2025-10-01 11:51:38,583] Trial 208 pruned. Trial was pruned at epoch 5.\n",
      "[I 2025-10-01 11:52:02,886] Trial 209 finished with value: 129.78907919437984 and parameters: {'seq_len': 18, 'units': 128, 'dropout': 0.07288055241691967, 'lr': 0.004595988584217625, 'batch': 64, 'epochs': 106}. Best is trial 76 with value: 129.32426541449985.\n",
      "[I 2025-10-01 11:52:14,028] Trial 210 pruned. Trial was pruned at epoch 5.\n",
      "[I 2025-10-01 11:52:36,403] Trial 211 finished with value: 130.18491956156058 and parameters: {'seq_len': 18, 'units': 128, 'dropout': 0.07300892659902093, 'lr': 0.0045530432159282454, 'batch': 64, 'epochs': 108}. Best is trial 76 with value: 129.32426541449985.\n",
      "[I 2025-10-01 11:52:47,466] Trial 212 pruned. Trial was pruned at epoch 6.\n",
      "[I 2025-10-01 11:52:58,214] Trial 213 pruned. Trial was pruned at epoch 5.\n",
      "[I 2025-10-01 11:53:30,945] Trial 214 finished with value: 130.20409159757614 and parameters: {'seq_len': 18, 'units': 128, 'dropout': 0.08308270199072362, 'lr': 0.003781135690355278, 'batch': 64, 'epochs': 98}. Best is trial 76 with value: 129.32426541449985.\n",
      "[I 2025-10-01 11:53:42,206] Trial 215 pruned. Trial was pruned at epoch 6.\n",
      "[I 2025-10-01 11:54:07,662] Trial 216 finished with value: 129.9397922476983 and parameters: {'seq_len': 18, 'units': 128, 'dropout': 0.05746055580793192, 'lr': 0.003516923146872391, 'batch': 64, 'epochs': 88}. Best is trial 76 with value: 129.32426541449985.\n",
      "[I 2025-10-01 11:54:16,836] Trial 217 pruned. Trial was pruned at epoch 5.\n",
      "[I 2025-10-01 11:54:40,977] Trial 218 finished with value: 130.62259268116676 and parameters: {'seq_len': 18, 'units': 128, 'dropout': 0.09885590428623697, 'lr': 0.0049828663674229105, 'batch': 64, 'epochs': 100}. Best is trial 76 with value: 129.32426541449985.\n",
      "[I 2025-10-01 11:55:07,983] Trial 219 finished with value: 130.54527321728276 and parameters: {'seq_len': 18, 'units': 128, 'dropout': 0.06688140728527846, 'lr': 0.004580665888894257, 'batch': 64, 'epochs': 95}. Best is trial 76 with value: 129.32426541449985.\n",
      "[I 2025-10-01 11:55:37,740] Trial 220 finished with value: 130.26632875094776 and parameters: {'seq_len': 18, 'units': 128, 'dropout': 0.11029865889766453, 'lr': 0.002167061348763711, 'batch': 64, 'epochs': 46}. Best is trial 76 with value: 129.32426541449985.\n",
      "[I 2025-10-01 11:56:03,345] Trial 221 finished with value: 130.50270142079435 and parameters: {'seq_len': 18, 'units': 128, 'dropout': 0.09061477057054057, 'lr': 0.0024195444975186617, 'batch': 64, 'epochs': 86}. Best is trial 76 with value: 129.32426541449985.\n",
      "[I 2025-10-01 11:56:30,017] Trial 222 finished with value: 130.19275073424788 and parameters: {'seq_len': 18, 'units': 128, 'dropout': 0.09786150470993757, 'lr': 0.00266094595571985, 'batch': 64, 'epochs': 103}. Best is trial 76 with value: 129.32426541449985.\n",
      "[I 2025-10-01 11:56:39,889] Trial 223 pruned. Trial was pruned at epoch 5.\n",
      "[I 2025-10-01 11:57:07,245] Trial 224 finished with value: 130.1813338674174 and parameters: {'seq_len': 18, 'units': 128, 'dropout': 0.08872423785275847, 'lr': 0.0028425553620901552, 'batch': 64, 'epochs': 87}. Best is trial 76 with value: 129.32426541449985.\n",
      "[I 2025-10-01 11:57:30,604] Trial 225 finished with value: 130.48785414024172 and parameters: {'seq_len': 18, 'units': 128, 'dropout': 0.10189634840029421, 'lr': 0.0039061580387479895, 'batch': 64, 'epochs': 80}. Best is trial 76 with value: 129.32426541449985.\n",
      "[I 2025-10-01 11:57:40,680] Trial 226 pruned. Trial was pruned at epoch 5.\n",
      "[I 2025-10-01 11:57:50,687] Trial 227 pruned. Trial was pruned at epoch 5.\n",
      "[I 2025-10-01 11:58:18,864] Trial 228 finished with value: 129.5591458200655 and parameters: {'seq_len': 18, 'units': 128, 'dropout': 0.10788027357617781, 'lr': 0.004466978718509781, 'batch': 64, 'epochs': 83}. Best is trial 76 with value: 129.32426541449985.\n",
      "[I 2025-10-01 11:58:42,780] Trial 229 finished with value: 130.67284560353386 and parameters: {'seq_len': 18, 'units': 128, 'dropout': 0.11161128641171407, 'lr': 0.004337637477605068, 'batch': 64, 'epochs': 84}. Best is trial 76 with value: 129.32426541449985.\n",
      "[I 2025-10-01 11:59:06,749] Trial 230 finished with value: 130.1744397553721 and parameters: {'seq_len': 18, 'units': 128, 'dropout': 0.12514586449092213, 'lr': 0.004967162276996471, 'batch': 64, 'epochs': 82}. Best is trial 76 with value: 129.32426541449985.\n",
      "[I 2025-10-01 11:59:33,285] Trial 231 finished with value: 129.76441995978712 and parameters: {'seq_len': 18, 'units': 128, 'dropout': 0.10553529249682668, 'lr': 0.0045195484860877195, 'batch': 64, 'epochs': 88}. Best is trial 76 with value: 129.32426541449985.\n",
      "[I 2025-10-01 12:00:02,067] Trial 232 finished with value: 130.28265545535982 and parameters: {'seq_len': 18, 'units': 128, 'dropout': 0.10454729885624449, 'lr': 0.004478317253156409, 'batch': 64, 'epochs': 88}. Best is trial 76 with value: 129.32426541449985.\n",
      "[I 2025-10-01 12:00:25,529] Trial 233 finished with value: 129.68994726606607 and parameters: {'seq_len': 18, 'units': 128, 'dropout': 0.11298113770941368, 'lr': 0.0039057090274685507, 'batch': 64, 'epochs': 93}. Best is trial 76 with value: 129.32426541449985.\n",
      "[I 2025-10-01 12:00:37,346] Trial 234 pruned. Trial was pruned at epoch 5.\n",
      "[I 2025-10-01 12:00:43,913] Trial 235 pruned. Trial was pruned at epoch 5.\n",
      "[I 2025-10-01 12:01:17,491] Trial 236 finished with value: 130.3354596080821 and parameters: {'seq_len': 18, 'units': 128, 'dropout': 0.10696306792091491, 'lr': 0.003952401393244927, 'batch': 64, 'epochs': 90}. Best is trial 76 with value: 129.32426541449985.\n",
      "[I 2025-10-01 12:01:29,520] Trial 237 pruned. Trial was pruned at epoch 5.\n",
      "[I 2025-10-01 12:01:36,213] Trial 238 pruned. Trial was pruned at epoch 5.\n",
      "[I 2025-10-01 12:02:04,973] Trial 239 finished with value: 130.6545794858527 and parameters: {'seq_len': 18, 'units': 128, 'dropout': 0.11392991527759258, 'lr': 0.0037128965318010475, 'batch': 64, 'epochs': 89}. Best is trial 76 with value: 129.32426541449985.\n",
      "Best LSTM params: {'seq_len': 18, 'units': 96, 'dropout': 0.10611697680405062, 'lr': 0.0036218877930872225, 'batch': 64, 'epochs': 89}\n",
      "LSTM test → RMSE: 137.7330 | MAE: 71.8965 | R2: 0.7142 | Skill: 0.299\n"
     ]
    }
   ],
   "source": [
    "storageB1 = prepare_journal_storage(\"ground_trackB_lstm\")\n",
    "studyB1 = optuna.create_study(direction=\"minimize\",\n",
    "                              sampler=TPESampler(seed=SEED),\n",
    "                              pruner=MedianPruner(n_startup_trials=8, n_warmup_steps=5),\n",
    "                              study_name=\"ground_trackB_lstm\",\n",
    "                              storage=storageB1, load_if_exists=True)\n",
    "print(\"Running Study B1 (LSTM)…\")\n",
    "studyB1.optimize(objective_lstm, n_trials=40, show_progress_bar=True)\n",
    "\n",
    "best_lstm, _ = _safe_load_best(studyB1)\n",
    "bestL1 = studyB1.best_trial.user_attrs[\"seq_len_used\"]\n",
    "Xte_seq, yte_seq, idx_LSTM = build_seq_with_idx(Xte_s, yte, bestL1)\n",
    "yhatB1 = best_lstm.predict(Xte_seq, verbose=0).squeeze()\n",
    "y_base_LSTM = pd.Series(y_base, index=Xte_df.index).reindex(idx_LSTM).to_numpy()\n",
    "print(\"Best LSTM params:\", studyB1.best_trial.params | {\"seq_len\": bestL1})\n",
    "print(f\"LSTM test → RMSE: {_rmse(yte_seq, yhatB1):.4f} | MAE: {mean_absolute_error(yte_seq, yhatB1):.4f} | R2: {r2_score(yte_seq, yhatB1):.4f} | Skill: {skill(yte_seq, yhatB1, y_base_LSTM):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "218b9bf3",
   "metadata": {},
   "source": [
    "### BiLSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1b34537",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_bilstm(trial: optuna.Trial) -> float:\n",
    "    K.clear_session()\n",
    "    L   = trial.suggest_categorical(\"seq_len\", [6, 12, 18, 24])\n",
    "    u   = trial.suggest_int(\"units\", 32, 128, step=32)\n",
    "    do  = trial.suggest_float(\"dropout\", 0.0, 0.4)\n",
    "    lr  = trial.suggest_float(\"lr\", 5e-5, 5e-3, log=True)\n",
    "    bs  = trial.suggest_categorical(\"batch\", [64, 128, 256])\n",
    "    eps = trial.suggest_int(\"epochs\", 40, 120)\n",
    "\n",
    "    Xtr_seq, ytr_seq = _build_seq(Xtr_s, ytr, L)\n",
    "    Xva_seq, yva_seq = _build_seq(Xva_s, yva, L)\n",
    "    if min(map(len,[Xtr_seq, Xva_seq])) == 0:\n",
    "        raise optuna.TrialPruned()\n",
    "\n",
    "    model = build_bilstm(L, Xtr_seq.shape[2], units=u, do=do)\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=lr), loss=\"mse\", metrics=[\"mae\"])\n",
    "\n",
    "    tmp_dir  = ART_DIR / f\"B_bilstm_t{trial.number:04d}\"; tmp_dir.mkdir(parents=True, exist_ok=True)\n",
    "    tmp_path = (tmp_dir / \"best.weights.h5\").resolve()\n",
    "\n",
    "    cbs = [\n",
    "        callbacks.EarlyStopping(monitor=\"val_loss\", patience=10, restore_best_weights=True, verbose=0),\n",
    "        callbacks.ModelCheckpoint(filepath=str(tmp_path), monitor=\"val_loss\",\n",
    "                                  save_best_only=True, save_weights_only=True),\n",
    "        TFKerasPruningCallback(trial, \"val_loss\"),\n",
    "    ]\n",
    "    model.fit(Xtr_seq, ytr_seq, validation_data=(Xva_seq, yva_seq),\n",
    "              epochs=eps, batch_size=bs, verbose=0, callbacks=cbs)\n",
    "\n",
    "    yhat = model.predict(Xva_seq, verbose=0).squeeze()\n",
    "    val_rmse = _rmse(yva_seq, yhat)\n",
    "\n",
    "    trial.set_user_attr(\"model_path\", str(tmp_path))\n",
    "    trial.set_user_attr(\"arch\", \"bilstm\")\n",
    "    trial.set_user_attr(\"seq_len_used\", L)\n",
    "    trial.set_user_attr(\"n_feat\", Xtr_s.shape[1])\n",
    "    return val_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3b5bd62",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_23508/3401579257.py:37: FutureWarning: The import path :class:`~optuna.storages.JournalFileOpenLock` has been deprecated in v4.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v4.0.0. Use :class:`~optuna.storages.journal.JournalFileOpenLock` instead.\n",
      "  file_storage = JournalFileStorage(str(log_path), lock_obj=JournalFileOpenLock(str(lock_path)))\n",
      "/tmp/ipykernel_23508/3401579257.py:37: FutureWarning: JournalFileStorage has been deprecated in v4.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v4.0.0. Use :class:`~optuna.storages.journal.JournalFileBackend` instead.\n",
      "  file_storage = JournalFileStorage(str(log_path), lock_obj=JournalFileOpenLock(str(lock_path)))\n",
      "[I 2025-10-01 12:02:05,735] Using an existing study with name 'ground_trackB_bilstm' instead of creating a new one.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Study B2 (BiLSTM)…\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "955d9179aad3476ba43f8c45974a28cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/35 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-01 12:02:46,058] Trial 155 finished with value: 130.92670003192626 and parameters: {'seq_len': 18, 'units': 128, 'dropout': 0.13587324192457673, 'lr': 0.0015349938415358164, 'batch': 64, 'epochs': 58}. Best is trial 67 with value: 130.13822279119228.\n",
      "[I 2025-10-01 12:03:27,236] Trial 156 finished with value: 130.24044020819724 and parameters: {'seq_len': 18, 'units': 128, 'dropout': 0.169226941536002, 'lr': 0.002892090475983559, 'batch': 64, 'epochs': 54}. Best is trial 67 with value: 130.13822279119228.\n",
      "[I 2025-10-01 12:03:44,172] Trial 157 pruned. Trial was pruned at epoch 5.\n",
      "[I 2025-10-01 12:04:29,492] Trial 158 finished with value: 131.3369726719213 and parameters: {'seq_len': 18, 'units': 96, 'dropout': 0.20018375550345666, 'lr': 0.0032125094658653473, 'batch': 64, 'epochs': 56}. Best is trial 67 with value: 130.13822279119228.\n",
      "[I 2025-10-01 12:05:10,078] Trial 159 finished with value: 130.60494014632448 and parameters: {'seq_len': 18, 'units': 128, 'dropout': 0.21608954193884033, 'lr': 0.00460016541072541, 'batch': 64, 'epochs': 48}. Best is trial 67 with value: 130.13822279119228.\n",
      "[I 2025-10-01 12:05:45,106] Trial 160 finished with value: 130.97058054673957 and parameters: {'seq_len': 18, 'units': 128, 'dropout': 0.21590944478960486, 'lr': 0.00460304517684367, 'batch': 64, 'epochs': 48}. Best is trial 67 with value: 130.13822279119228.\n",
      "[I 2025-10-01 12:06:27,313] Trial 161 finished with value: 130.50234971543617 and parameters: {'seq_len': 18, 'units': 128, 'dropout': 0.24098257932344652, 'lr': 0.004092892168105868, 'batch': 64, 'epochs': 51}. Best is trial 67 with value: 130.13822279119228.\n",
      "[I 2025-10-01 12:07:28,724] Trial 162 finished with value: 130.92916888770432 and parameters: {'seq_len': 18, 'units': 128, 'dropout': 0.2562112186048375, 'lr': 0.004132175226269055, 'batch': 64, 'epochs': 51}. Best is trial 67 with value: 130.13822279119228.\n",
      "[I 2025-10-01 12:08:21,254] Trial 163 finished with value: 130.56434746179755 and parameters: {'seq_len': 18, 'units': 128, 'dropout': 0.21721483285469612, 'lr': 0.00496147602892913, 'batch': 64, 'epochs': 49}. Best is trial 67 with value: 130.13822279119228.\n",
      "[I 2025-10-01 12:08:57,226] Trial 164 finished with value: 130.176930379868 and parameters: {'seq_len': 18, 'units': 128, 'dropout': 0.19039086058764645, 'lr': 0.003538347666015342, 'batch': 64, 'epochs': 46}. Best is trial 67 with value: 130.13822279119228.\n",
      "[I 2025-10-01 12:10:00,838] Trial 165 finished with value: 131.05787277239395 and parameters: {'seq_len': 18, 'units': 128, 'dropout': 0.23374018827979395, 'lr': 0.0037401933570354816, 'batch': 64, 'epochs': 46}. Best is trial 67 with value: 130.13822279119228.\n",
      "[I 2025-10-01 12:10:48,330] Trial 166 finished with value: 130.9883478238618 and parameters: {'seq_len': 18, 'units': 128, 'dropout': 0.25014412208900877, 'lr': 0.0033551382450708904, 'batch': 64, 'epochs': 50}. Best is trial 67 with value: 130.13822279119228.\n",
      "[I 2025-10-01 12:11:31,652] Trial 167 finished with value: 130.39034695147106 and parameters: {'seq_len': 18, 'units': 128, 'dropout': 0.20164814630606467, 'lr': 0.0026875304012345578, 'batch': 64, 'epochs': 44}. Best is trial 67 with value: 130.13822279119228.\n",
      "[I 2025-10-01 12:11:51,138] Trial 168 pruned. Trial was pruned at epoch 5.\n",
      "[I 2025-10-01 12:12:07,307] Trial 169 pruned. Trial was pruned at epoch 5.\n",
      "[I 2025-10-01 12:12:25,103] Trial 170 pruned. Trial was pruned at epoch 5.\n",
      "[I 2025-10-01 12:12:40,752] Trial 171 pruned. Trial was pruned at epoch 5.\n",
      "[I 2025-10-01 12:13:35,068] Trial 172 finished with value: 131.10564233901223 and parameters: {'seq_len': 18, 'units': 128, 'dropout': 0.209772588201266, 'lr': 0.003021720451435755, 'batch': 64, 'epochs': 42}. Best is trial 67 with value: 130.13822279119228.\n",
      "[I 2025-10-01 12:14:17,122] Trial 173 finished with value: 130.2732254964542 and parameters: {'seq_len': 18, 'units': 128, 'dropout': 0.18368730650150136, 'lr': 0.0034414597108702307, 'batch': 64, 'epochs': 48}. Best is trial 67 with value: 130.13822279119228.\n",
      "[I 2025-10-01 12:15:09,633] Trial 174 finished with value: 130.98072824608587 and parameters: {'seq_len': 18, 'units': 128, 'dropout': 0.18296899209906142, 'lr': 0.0033129734626165717, 'batch': 64, 'epochs': 52}. Best is trial 67 with value: 130.13822279119228.\n",
      "[I 2025-10-01 12:15:26,044] Trial 175 pruned. Trial was pruned at epoch 5.\n",
      "[I 2025-10-01 12:16:05,564] Trial 176 finished with value: 131.32210816823647 and parameters: {'seq_len': 18, 'units': 128, 'dropout': 0.20001792750126582, 'lr': 0.004076311692370589, 'batch': 64, 'epochs': 49}. Best is trial 67 with value: 130.13822279119228.\n",
      "[I 2025-10-01 12:16:39,709] Trial 177 finished with value: 131.1577056447695 and parameters: {'seq_len': 6, 'units': 128, 'dropout': 0.17675572333109965, 'lr': 0.0022382369027815906, 'batch': 64, 'epochs': 45}. Best is trial 67 with value: 130.13822279119228.\n",
      "[I 2025-10-01 12:17:26,928] Trial 178 finished with value: 130.36416092287405 and parameters: {'seq_len': 18, 'units': 128, 'dropout': 0.21606665891876856, 'lr': 0.0018735767577619383, 'batch': 64, 'epochs': 53}. Best is trial 67 with value: 130.13822279119228.\n",
      "[I 2025-10-01 12:18:33,565] Trial 179 finished with value: 131.44938724182018 and parameters: {'seq_len': 18, 'units': 128, 'dropout': 0.20580566740821676, 'lr': 0.0018565423815251505, 'batch': 64, 'epochs': 54}. Best is trial 67 with value: 130.13822279119228.\n",
      "[I 2025-10-01 12:19:18,414] Trial 180 finished with value: 130.963362600958 and parameters: {'seq_len': 18, 'units': 128, 'dropout': 0.18588099692454685, 'lr': 0.0019910698390178394, 'batch': 64, 'epochs': 52}. Best is trial 67 with value: 130.13822279119228.\n",
      "[I 2025-10-01 12:20:07,173] Trial 181 finished with value: 131.0446309945585 and parameters: {'seq_len': 18, 'units': 128, 'dropout': 0.10769152044066993, 'lr': 0.0027700254034161978, 'batch': 64, 'epochs': 53}. Best is trial 67 with value: 130.13822279119228.\n",
      "[I 2025-10-01 12:20:51,254] Trial 182 finished with value: 130.8857072387012 and parameters: {'seq_len': 18, 'units': 128, 'dropout': 0.2122213293099068, 'lr': 0.003674574570990475, 'batch': 64, 'epochs': 50}. Best is trial 67 with value: 130.13822279119228.\n",
      "[I 2025-10-01 12:21:29,399] Trial 183 finished with value: 130.48932846692867 and parameters: {'seq_len': 18, 'units': 128, 'dropout': 0.1957191507271771, 'lr': 0.003142896070778264, 'batch': 64, 'epochs': 47}. Best is trial 67 with value: 130.13822279119228.\n",
      "[I 2025-10-01 12:22:07,037] Trial 184 finished with value: 131.2372984925589 and parameters: {'seq_len': 18, 'units': 128, 'dropout': 0.2669064247424111, 'lr': 0.003151396378008229, 'batch': 64, 'epochs': 47}. Best is trial 67 with value: 130.13822279119228.\n",
      "[I 2025-10-01 12:22:51,253] Trial 185 finished with value: 130.2257505017729 and parameters: {'seq_len': 18, 'units': 128, 'dropout': 0.17451916387882127, 'lr': 0.0025563514321660825, 'batch': 64, 'epochs': 42}. Best is trial 67 with value: 130.13822279119228.\n",
      "[I 2025-10-01 12:23:05,722] Trial 186 pruned. Trial was pruned at epoch 5.\n",
      "[I 2025-10-01 12:23:54,118] Trial 187 finished with value: 131.08213223252434 and parameters: {'seq_len': 18, 'units': 128, 'dropout': 0.1947815824651488, 'lr': 0.002916053839673312, 'batch': 64, 'epochs': 51}. Best is trial 67 with value: 130.13822279119228.\n",
      "[I 2025-10-01 12:24:15,970] Trial 188 pruned. Trial was pruned at epoch 5.\n",
      "[I 2025-10-01 12:25:10,654] Trial 189 finished with value: 130.29045826776803 and parameters: {'seq_len': 18, 'units': 128, 'dropout': 0.18642138732094318, 'lr': 0.003142173080905876, 'batch': 64, 'epochs': 55}. Best is trial 67 with value: 130.13822279119228.\n",
      "Best BiLSTM params: {'seq_len': 18, 'units': 128, 'dropout': 0.11290422597989508, 'lr': 0.004256193252277516, 'batch': 128, 'epochs': 64}\n",
      "BiLSTM test → RMSE: 137.1388 | MAE: 71.0945 | R2: 0.7167 | Skill: 0.302\n"
     ]
    }
   ],
   "source": [
    "storageB2 = prepare_journal_storage(\"ground_trackB_bilstm\")\n",
    "studyB2 = optuna.create_study(direction=\"minimize\",\n",
    "                              sampler=TPESampler(seed=SEED),\n",
    "                              pruner=MedianPruner(n_startup_trials=8, n_warmup_steps=5),\n",
    "                              study_name=\"ground_trackB_bilstm\",\n",
    "                              storage=storageB2, load_if_exists=True)\n",
    "print(\"Running Study B2 (BiLSTM)…\")\n",
    "studyB2.optimize(objective_bilstm, n_trials=35, show_progress_bar=True)\n",
    "\n",
    "best_bi, _ = _safe_load_best(studyB2)\n",
    "bestL2 = studyB2.best_trial.user_attrs[\"seq_len_used\"]\n",
    "Xte_seq, yte_seq, idx_BI = build_seq_with_idx(Xte_s, yte, bestL2)\n",
    "yhatB2 = best_bi.predict(Xte_seq, verbose=0).squeeze()\n",
    "y_base_BI = pd.Series(y_base, index=Xte_df.index).reindex(idx_BI).to_numpy()\n",
    "print(\"Best BiLSTM params:\", studyB2.best_trial.params | {\"seq_len\": bestL2})\n",
    "print(f\"BiLSTM test → RMSE: {_rmse(yte_seq, yhatB2):.4f} | MAE: {mean_absolute_error(yte_seq, yhatB2):.4f} | R2: {r2_score(yte_seq, yhatB2):.4f} | Skill: {skill(yte_seq, yhatB2, y_base_BI):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d213bc8d",
   "metadata": {},
   "source": [
    "### CNN-LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f1c2392",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_cnnlstm(trial: optuna.Trial) -> float:\n",
    "    K.clear_session()\n",
    "    L     = trial.suggest_categorical(\"seq_len\", [6, 12, 18, 24])\n",
    "    filt  = trial.suggest_int(\"filters\", 16, 64, step=16)\n",
    "    ksz   = trial.suggest_categorical(\"kernel_size\", [2,3,5])\n",
    "    pool  = trial.suggest_categorical(\"pool\", [1,2])\n",
    "    u     = trial.suggest_int(\"lstm_units\", 32, 128, step=32)\n",
    "    do    = trial.suggest_float(\"dropout\", 0.0, 0.4)\n",
    "    lr    = trial.suggest_float(\"lr\", 5e-5, 5e-3, log=True)\n",
    "    bs    = trial.suggest_categorical(\"batch\", [64, 128, 256])\n",
    "    eps   = trial.suggest_int(\"epochs\", 40, 120)\n",
    "\n",
    "    Xtr_seq, ytr_seq = _build_seq(Xtr_s, ytr, L)\n",
    "    Xva_seq, yva_seq = _build_seq(Xva_s, yva, L)\n",
    "    if min(map(len,[Xtr_seq, Xva_seq])) == 0:\n",
    "        raise optuna.TrialPruned()\n",
    "\n",
    "    model = build_cnnlstm(L, Xtr_seq.shape[2], filt=filt, ksz=ksz, pool=pool, lstm_units=u, do=do)\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=lr), loss=\"mse\", metrics=[\"mae\"])\n",
    "\n",
    "    tmp_dir  = ART_DIR / f\"B_cnnlstm_t{trial.number:04d}\"; tmp_dir.mkdir(parents=True, exist_ok=True)\n",
    "    tmp_path = (tmp_dir / \"best.weights.h5\").resolve()\n",
    "\n",
    "    cbs = [\n",
    "        callbacks.EarlyStopping(monitor=\"val_loss\", patience=10, restore_best_weights=True, verbose=0),\n",
    "        callbacks.ModelCheckpoint(filepath=str(tmp_path), monitor=\"val_loss\",\n",
    "                                  save_best_only=True, save_weights_only=True),\n",
    "        TFKerasPruningCallback(trial, \"val_loss\"),\n",
    "    ]\n",
    "    model.fit(Xtr_seq, ytr_seq, validation_data=(Xva_seq, yva_seq),\n",
    "              epochs=eps, batch_size=bs, verbose=0, callbacks=cbs)\n",
    "\n",
    "    yhat = model.predict(Xva_seq, verbose=0).squeeze()\n",
    "    val_rmse = _rmse(yva_seq, yhat)\n",
    "\n",
    "    trial.set_user_attr(\"model_path\", str(tmp_path))\n",
    "    trial.set_user_attr(\"arch\", \"cnn-lstm\")\n",
    "    trial.set_user_attr(\"seq_len_used\", L)\n",
    "    trial.set_user_attr(\"n_feat\", Xtr_s.shape[1])\n",
    "    return val_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee61c1f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_23508/3401579257.py:37: FutureWarning: The import path :class:`~optuna.storages.JournalFileOpenLock` has been deprecated in v4.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v4.0.0. Use :class:`~optuna.storages.journal.JournalFileOpenLock` instead.\n",
      "  file_storage = JournalFileStorage(str(log_path), lock_obj=JournalFileOpenLock(str(lock_path)))\n",
      "/tmp/ipykernel_23508/3401579257.py:37: FutureWarning: JournalFileStorage has been deprecated in v4.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v4.0.0. Use :class:`~optuna.storages.journal.JournalFileBackend` instead.\n",
      "  file_storage = JournalFileStorage(str(log_path), lock_obj=JournalFileOpenLock(str(lock_path)))\n",
      "[I 2025-10-01 12:44:01,267] Using an existing study with name 'ground_trackB_cnnlstm' instead of creating a new one.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Study B3 (CNN-LSTM)…\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7216b7085414497b5f1535df829f6ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/35 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-01 12:44:13,532] Trial 140 pruned. Trial was pruned at epoch 5.\n",
      "[I 2025-10-01 12:44:26,060] Trial 141 pruned. Trial was pruned at epoch 5.\n",
      "[I 2025-10-01 12:44:56,442] Trial 142 finished with value: 131.38979162686118 and parameters: {'seq_len': 18, 'filters': 64, 'kernel_size': 2, 'pool': 1, 'lstm_units': 96, 'dropout': 0.20500245770534004, 'lr': 0.002913861960131337, 'batch': 64, 'epochs': 74}. Best is trial 54 with value: 130.55489296891557.\n",
      "[I 2025-10-01 12:45:07,567] Trial 143 pruned. Trial was pruned at epoch 5.\n",
      "[I 2025-10-01 12:45:19,061] Trial 144 pruned. Trial was pruned at epoch 5.\n",
      "[I 2025-10-01 12:45:50,448] Trial 145 finished with value: 130.92202325000557 and parameters: {'seq_len': 18, 'filters': 64, 'kernel_size': 2, 'pool': 1, 'lstm_units': 96, 'dropout': 0.21213090979718335, 'lr': 0.004276071840407373, 'batch': 64, 'epochs': 71}. Best is trial 54 with value: 130.55489296891557.\n",
      "[I 2025-10-01 12:45:57,516] Trial 146 pruned. Trial was pruned at epoch 5.\n",
      "[I 2025-10-01 12:46:26,541] Trial 147 finished with value: 130.82823603393115 and parameters: {'seq_len': 18, 'filters': 64, 'kernel_size': 2, 'pool': 2, 'lstm_units': 96, 'dropout': 0.06964533433605719, 'lr': 0.004136574053908809, 'batch': 64, 'epochs': 71}. Best is trial 54 with value: 130.55489296891557.\n",
      "[I 2025-10-01 12:47:07,366] Trial 148 finished with value: 131.05889360798832 and parameters: {'seq_len': 18, 'filters': 64, 'kernel_size': 2, 'pool': 2, 'lstm_units': 96, 'dropout': 0.06818451141284518, 'lr': 0.004134461617984419, 'batch': 64, 'epochs': 71}. Best is trial 54 with value: 130.55489296891557.\n",
      "[I 2025-10-01 12:47:12,401] Trial 149 pruned. Trial was pruned at epoch 5.\n",
      "[I 2025-10-01 12:47:22,980] Trial 150 pruned. Trial was pruned at epoch 5.\n",
      "[I 2025-10-01 12:47:33,466] Trial 151 pruned. Trial was pruned at epoch 5.\n",
      "[I 2025-10-01 12:47:45,455] Trial 152 pruned. Trial was pruned at epoch 6.\n",
      "[I 2025-10-01 12:47:58,465] Trial 153 pruned. Trial was pruned at epoch 5.\n",
      "[I 2025-10-01 12:48:12,031] Trial 154 pruned. Trial was pruned at epoch 5.\n",
      "[I 2025-10-01 12:48:46,748] Trial 155 finished with value: 131.07740139417626 and parameters: {'seq_len': 18, 'filters': 64, 'kernel_size': 2, 'pool': 1, 'lstm_units': 128, 'dropout': 0.038630736938655666, 'lr': 0.00440329030201896, 'batch': 64, 'epochs': 91}. Best is trial 54 with value: 130.55489296891557.\n",
      "[I 2025-10-01 12:48:57,849] Trial 156 pruned. Trial was pruned at epoch 5.\n",
      "[I 2025-10-01 12:49:45,090] Trial 157 finished with value: 130.86056062895727 and parameters: {'seq_len': 18, 'filters': 64, 'kernel_size': 3, 'pool': 1, 'lstm_units': 96, 'dropout': 0.2011523975359903, 'lr': 0.0039798176676842335, 'batch': 64, 'epochs': 66}. Best is trial 54 with value: 130.55489296891557.\n",
      "[I 2025-10-01 12:49:55,217] Trial 158 pruned. Trial was pruned at epoch 5.\n",
      "[I 2025-10-01 12:50:06,679] Trial 159 pruned. Trial was pruned at epoch 5.\n",
      "[I 2025-10-01 12:50:47,381] Trial 160 finished with value: 131.3166720541417 and parameters: {'seq_len': 12, 'filters': 64, 'kernel_size': 3, 'pool': 1, 'lstm_units': 96, 'dropout': 0.12733438758195897, 'lr': 0.004021651254860568, 'batch': 64, 'epochs': 61}. Best is trial 54 with value: 130.55489296891557.\n",
      "[I 2025-10-01 12:51:16,592] Trial 161 finished with value: 131.741179140199 and parameters: {'seq_len': 18, 'filters': 64, 'kernel_size': 3, 'pool': 1, 'lstm_units': 96, 'dropout': 0.22354770228929965, 'lr': 0.003712678225019653, 'batch': 64, 'epochs': 65}. Best is trial 54 with value: 130.55489296891557.\n",
      "[I 2025-10-01 12:51:46,051] Trial 162 finished with value: 131.2542112419636 and parameters: {'seq_len': 18, 'filters': 64, 'kernel_size': 3, 'pool': 1, 'lstm_units': 96, 'dropout': 0.20542819104860635, 'lr': 0.004485547545221942, 'batch': 64, 'epochs': 73}. Best is trial 54 with value: 130.55489296891557.\n",
      "[I 2025-10-01 12:51:57,642] Trial 163 pruned. Trial was pruned at epoch 5.\n",
      "[I 2025-10-01 12:52:30,197] Trial 164 finished with value: 131.1206282040511 and parameters: {'seq_len': 18, 'filters': 64, 'kernel_size': 2, 'pool': 1, 'lstm_units': 96, 'dropout': 0.07255181011511735, 'lr': 0.0031985839366584956, 'batch': 64, 'epochs': 66}. Best is trial 54 with value: 130.55489296891557.\n",
      "[I 2025-10-01 12:52:41,659] Trial 165 pruned. Trial was pruned at epoch 5.\n",
      "[I 2025-10-01 12:52:52,771] Trial 166 pruned. Trial was pruned at epoch 5.\n",
      "[I 2025-10-01 12:53:24,320] Trial 167 finished with value: 131.48981067938306 and parameters: {'seq_len': 18, 'filters': 64, 'kernel_size': 2, 'pool': 1, 'lstm_units': 128, 'dropout': 0.19418200237339867, 'lr': 0.004625100139693118, 'batch': 64, 'epochs': 73}. Best is trial 54 with value: 130.55489296891557.\n",
      "[I 2025-10-01 12:53:53,779] Trial 168 finished with value: 131.06641923086173 and parameters: {'seq_len': 18, 'filters': 64, 'kernel_size': 3, 'pool': 1, 'lstm_units': 96, 'dropout': 0.10869136029119043, 'lr': 0.002537317631399787, 'batch': 64, 'epochs': 75}. Best is trial 54 with value: 130.55489296891557.\n",
      "[I 2025-10-01 12:54:31,348] Trial 169 finished with value: 131.25923330617545 and parameters: {'seq_len': 18, 'filters': 64, 'kernel_size': 2, 'pool': 1, 'lstm_units': 96, 'dropout': 0.10146227301992722, 'lr': 0.0039068398329650976, 'batch': 64, 'epochs': 53}. Best is trial 54 with value: 130.55489296891557.\n",
      "[I 2025-10-01 12:54:43,220] Trial 170 pruned. Trial was pruned at epoch 5.\n",
      "[I 2025-10-01 12:54:54,554] Trial 171 pruned. Trial was pruned at epoch 5.\n",
      "[I 2025-10-01 12:55:27,306] Trial 172 finished with value: 130.66573826466524 and parameters: {'seq_len': 18, 'filters': 64, 'kernel_size': 2, 'pool': 1, 'lstm_units': 96, 'dropout': 0.17253540383752689, 'lr': 0.0042139365614470145, 'batch': 64, 'epochs': 79}. Best is trial 54 with value: 130.55489296891557.\n",
      "[I 2025-10-01 12:55:58,486] Trial 173 finished with value: 131.35648953801254 and parameters: {'seq_len': 18, 'filters': 64, 'kernel_size': 2, 'pool': 1, 'lstm_units': 96, 'dropout': 0.16808314413004255, 'lr': 0.0049794626470525604, 'batch': 64, 'epochs': 79}. Best is trial 54 with value: 130.55489296891557.\n",
      "[I 2025-10-01 12:56:09,861] Trial 174 pruned. Trial was pruned at epoch 5.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "The `function` of this `Lambda` layer is a Python lambda. Deserializing it is unsafe. If you trust the source of the config artifact, you can override this error by passing `safe_mode=False` to `from_config()`, or calling `keras.config.enable_unsafe_deserialization().",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 10\u001b[39m\n\u001b[32m      7\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mRunning Study B3 (CNN-LSTM)…\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      8\u001b[39m studyB3.optimize(objective_cnnlstm, n_trials=\u001b[32m35\u001b[39m, show_progress_bar=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m best_cnn, _ = \u001b[43m_safe_load_best\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudyB3\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     11\u001b[39m bestL3 = studyB3.best_trial.user_attrs[\u001b[33m\"\u001b[39m\u001b[33mseq_len_used\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m     12\u001b[39m Xte_seq, yte_seq, idx_CNN = build_seq_with_idx(Xte_s, yte, bestL3)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 54\u001b[39m, in \u001b[36m_safe_load_best\u001b[39m\u001b[34m(study, rebuild_fn)\u001b[39m\n\u001b[32m     52\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     53\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mCheckpoint not found: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mp\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m54\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mkeras\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmodels\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mp\u001b[49m\u001b[43m)\u001b[49m, p\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/e_ladino/lib/python3.12/site-packages/keras/src/saving/saving_api.py:189\u001b[39m, in \u001b[36mload_model\u001b[39m\u001b[34m(filepath, custom_objects, compile, safe_mode)\u001b[39m\n\u001b[32m    186\u001b[39m         is_keras_zip = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    188\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_keras_zip \u001b[38;5;129;01mor\u001b[39;00m is_keras_dir \u001b[38;5;129;01mor\u001b[39;00m is_hf:\n\u001b[32m--> \u001b[39m\u001b[32m189\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msaving_lib\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    190\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfilepath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    191\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcustom_objects\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcustom_objects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    192\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mcompile\u001b[39;49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mcompile\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    193\u001b[39m \u001b[43m        \u001b[49m\u001b[43msafe_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[43msafe_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    194\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    195\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(filepath).endswith((\u001b[33m\"\u001b[39m\u001b[33m.h5\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33m.hdf5\u001b[39m\u001b[33m\"\u001b[39m)):\n\u001b[32m    196\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m legacy_h5_format.load_model_from_hdf5(\n\u001b[32m    197\u001b[39m         filepath, custom_objects=custom_objects, \u001b[38;5;28mcompile\u001b[39m=\u001b[38;5;28mcompile\u001b[39m\n\u001b[32m    198\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/e_ladino/lib/python3.12/site-packages/keras/src/saving/saving_lib.py:365\u001b[39m, in \u001b[36mload_model\u001b[39m\u001b[34m(filepath, custom_objects, compile, safe_mode)\u001b[39m\n\u001b[32m    360\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    361\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mInvalid filename: expected a `.keras` extension. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    362\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mReceived: filepath=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfilepath\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    363\u001b[39m     )\n\u001b[32m    364\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(filepath, \u001b[33m\"\u001b[39m\u001b[33mrb\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[32m--> \u001b[39m\u001b[32m365\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_load_model_from_fileobj\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    366\u001b[39m \u001b[43m        \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcustom_objects\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mcompile\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msafe_mode\u001b[49m\n\u001b[32m    367\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/e_ladino/lib/python3.12/site-packages/keras/src/saving/saving_lib.py:442\u001b[39m, in \u001b[36m_load_model_from_fileobj\u001b[39m\u001b[34m(fileobj, custom_objects, compile, safe_mode)\u001b[39m\n\u001b[32m    439\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m zf.open(_CONFIG_FILENAME, \u001b[33m\"\u001b[39m\u001b[33mr\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[32m    440\u001b[39m     config_json = f.read()\n\u001b[32m--> \u001b[39m\u001b[32m442\u001b[39m model = \u001b[43m_model_from_config\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    443\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconfig_json\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcustom_objects\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mcompile\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msafe_mode\u001b[49m\n\u001b[32m    444\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    446\u001b[39m all_filenames = zf.namelist()\n\u001b[32m    447\u001b[39m extract_dir = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/e_ladino/lib/python3.12/site-packages/keras/src/saving/saving_lib.py:431\u001b[39m, in \u001b[36m_model_from_config\u001b[39m\u001b[34m(config_json, custom_objects, compile, safe_mode)\u001b[39m\n\u001b[32m    429\u001b[39m \u001b[38;5;66;03m# Construct the model from the configuration file in the archive.\u001b[39;00m\n\u001b[32m    430\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m ObjectSharingScope():\n\u001b[32m--> \u001b[39m\u001b[32m431\u001b[39m     model = \u001b[43mdeserialize_keras_object\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    432\u001b[39m \u001b[43m        \u001b[49m\u001b[43mconfig_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcustom_objects\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msafe_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[43msafe_mode\u001b[49m\n\u001b[32m    433\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    434\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m model\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/e_ladino/lib/python3.12/site-packages/keras/src/saving/serialization_lib.py:733\u001b[39m, in \u001b[36mdeserialize_keras_object\u001b[39m\u001b[34m(config, custom_objects, safe_mode, **kwargs)\u001b[39m\n\u001b[32m    731\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m custom_obj_scope, safe_mode_scope:\n\u001b[32m    732\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m733\u001b[39m         instance = \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfrom_config\u001b[49m\u001b[43m(\u001b[49m\u001b[43minner_config\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    734\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    735\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[32m    736\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m could not be deserialized properly. Please\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    737\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33m ensure that components that are Python object\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m    741\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mconfig=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mException encountered: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    742\u001b[39m         )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/e_ladino/lib/python3.12/site-packages/keras/src/models/sequential.py:371\u001b[39m, in \u001b[36mSequential.from_config\u001b[39m\u001b[34m(cls, config, custom_objects)\u001b[39m\n\u001b[32m    366\u001b[39m         layer = saving_utils.model_from_config(\n\u001b[32m    367\u001b[39m             layer_config,\n\u001b[32m    368\u001b[39m             custom_objects=custom_objects,\n\u001b[32m    369\u001b[39m         )\n\u001b[32m    370\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m371\u001b[39m         layer = \u001b[43mserialization_lib\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdeserialize_keras_object\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    372\u001b[39m \u001b[43m            \u001b[49m\u001b[43mlayer_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    373\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcustom_objects\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcustom_objects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    374\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    375\u001b[39m     model.add(layer)\n\u001b[32m    376\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    377\u001b[39m     \u001b[38;5;129;01mnot\u001b[39;00m model._functional\n\u001b[32m    378\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mbuild_input_shape\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mlocals\u001b[39m()\n\u001b[32m    379\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m build_input_shape\n\u001b[32m    380\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(build_input_shape, (\u001b[38;5;28mtuple\u001b[39m, \u001b[38;5;28mlist\u001b[39m))\n\u001b[32m    381\u001b[39m ):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/e_ladino/lib/python3.12/site-packages/keras/src/saving/serialization_lib.py:733\u001b[39m, in \u001b[36mdeserialize_keras_object\u001b[39m\u001b[34m(config, custom_objects, safe_mode, **kwargs)\u001b[39m\n\u001b[32m    731\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m custom_obj_scope, safe_mode_scope:\n\u001b[32m    732\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m733\u001b[39m         instance = \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfrom_config\u001b[49m\u001b[43m(\u001b[49m\u001b[43minner_config\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    734\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    735\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[32m    736\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m could not be deserialized properly. Please\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    737\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33m ensure that components that are Python object\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m    741\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mconfig=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mException encountered: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    742\u001b[39m         )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/e_ladino/lib/python3.12/site-packages/keras/src/layers/core/lambda_layer.py:190\u001b[39m, in \u001b[36mLambda.from_config\u001b[39m\u001b[34m(cls, config, custom_objects, safe_mode)\u001b[39m\n\u001b[32m    184\u001b[39m fn_config = config[\u001b[33m\"\u001b[39m\u001b[33mfunction\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m    185\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    186\u001b[39m     \u001b[38;5;28misinstance\u001b[39m(fn_config, \u001b[38;5;28mdict\u001b[39m)\n\u001b[32m    187\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mclass_name\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m fn_config\n\u001b[32m    188\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m fn_config[\u001b[33m\"\u001b[39m\u001b[33mclass_name\u001b[39m\u001b[33m\"\u001b[39m] == \u001b[33m\"\u001b[39m\u001b[33m__lambda__\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    189\u001b[39m ):\n\u001b[32m--> \u001b[39m\u001b[32m190\u001b[39m     \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_raise_for_lambda_deserialization\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfunction\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msafe_mode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    191\u001b[39m     inner_config = fn_config[\u001b[33m\"\u001b[39m\u001b[33mconfig\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m    192\u001b[39m     fn = python_utils.func_load(\n\u001b[32m    193\u001b[39m         inner_config[\u001b[33m\"\u001b[39m\u001b[33mcode\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m    194\u001b[39m         defaults=inner_config[\u001b[33m\"\u001b[39m\u001b[33mdefaults\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m    195\u001b[39m         closure=inner_config[\u001b[33m\"\u001b[39m\u001b[33mclosure\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m    196\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/e_ladino/lib/python3.12/site-packages/keras/src/layers/core/lambda_layer.py:172\u001b[39m, in \u001b[36mLambda._raise_for_lambda_deserialization\u001b[39m\u001b[34m(arg_name, safe_mode)\u001b[39m\n\u001b[32m    169\u001b[39m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[32m    170\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_raise_for_lambda_deserialization\u001b[39m(arg_name, safe_mode):\n\u001b[32m    171\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m safe_mode:\n\u001b[32m--> \u001b[39m\u001b[32m172\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    173\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mThe `\u001b[39m\u001b[38;5;132;01m{\u001b[39;00marg_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m` of this `Lambda` layer is a Python lambda. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    174\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mDeserializing it is unsafe. If you trust the source of the \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    175\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mconfig artifact, you can override this error \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    176\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mby passing `safe_mode=False` \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    177\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mto `from_config()`, or calling \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    178\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33m`keras.config.enable_unsafe_deserialization().\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    179\u001b[39m         )\n",
      "\u001b[31mValueError\u001b[39m: The `function` of this `Lambda` layer is a Python lambda. Deserializing it is unsafe. If you trust the source of the config artifact, you can override this error by passing `safe_mode=False` to `from_config()`, or calling `keras.config.enable_unsafe_deserialization()."
     ]
    }
   ],
   "source": [
    "storageB3 = prepare_journal_storage(\"ground_trackB_cnnlstm\")\n",
    "studyB3 = optuna.create_study(direction=\"minimize\",\n",
    "                              sampler=TPESampler(seed=SEED),\n",
    "                              pruner=MedianPruner(n_startup_trials=8, n_warmup_steps=5),\n",
    "                              study_name=\"ground_trackB_cnnlstm\",\n",
    "                              storage=storageB3, load_if_exists=True)\n",
    "print(\"Running Study B3 (CNN-LSTM)…\")\n",
    "studyB3.optimize(objective_cnnlstm, n_trials=35, show_progress_bar=True)\n",
    "\n",
    "best_cnn, _ = _safe_load_best(studyB3)\n",
    "bestL3 = studyB3.best_trial.user_attrs[\"seq_len_used\"]\n",
    "Xte_seq, yte_seq, idx_CNN = build_seq_with_idx(Xte_s, yte, bestL3)\n",
    "yhatB3 = best_cnn.predict(Xte_seq, verbose=0).squeeze()\n",
    "y_base_CNN = pd.Series(y_base, index=Xte_df.index).reindex(idx_CNN).to_numpy()\n",
    "print(\"Best CNN-LSTM params:\", studyB3.best_trial.params | {\"seq_len\": bestL3})\n",
    "print(f\"CNN-LSTM test → RMSE: {_rmse(yte_seq, yhatB3):.4f} | MAE: {mean_absolute_error(yte_seq, yhatB3):.4f} | R2: {r2_score(yte_seq, yhatB3):.4f} | Skill: {skill(yte_seq, yhatB3, y_base_CNN):.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c53a6c7",
   "metadata": {},
   "source": [
    "### Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f244d1ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_transformer(trial: optuna.Trial) -> float:\n",
    "    K.clear_session()\n",
    "    L       = trial.suggest_categorical(\"seq_len\", [6, 12, 18, 24])\n",
    "    d_model = trial.suggest_categorical(\"d_model\", [32, 64, 96, 128])\n",
    "    heads   = trial.suggest_categorical(\"heads\", [2, 4, 8])\n",
    "    if d_model % heads != 0:\n",
    "        raise optuna.TrialPruned()\n",
    "    ff_dim  = trial.suggest_categorical(\"ff_dim\", [64, 96, 128, 192])\n",
    "    att_do  = trial.suggest_float(\"att_dropout\", 0.0, 0.3)\n",
    "    do      = trial.suggest_float(\"dropout\", 0.0, 0.4)\n",
    "    lr      = trial.suggest_float(\"lr\", 5e-5, 5e-3, log=True)\n",
    "    bs      = trial.suggest_categorical(\"batch\", [64, 128, 256])\n",
    "    eps     = trial.suggest_int(\"epochs\", 40, 120)\n",
    "\n",
    "    Xtr_seq, ytr_seq = _build_seq(Xtr_s, ytr, L)\n",
    "    Xva_seq, yva_seq = _build_seq(Xva_s, yva, L)\n",
    "    if min(map(len,[Xtr_seq, Xva_seq])) == 0:\n",
    "        raise optuna.TrialPruned()\n",
    "\n",
    "    model = build_transformer(L, Xtr_seq.shape[2], d_model=d_model, heads=heads,\n",
    "                              ff_dim=ff_dim, att_do=att_do, do=do)\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=lr), loss=\"mse\", metrics=[\"mae\"])\n",
    "\n",
    "    tmp_dir  = ART_DIR / f\"B_transformer_t{trial.number:04d}\"; tmp_dir.mkdir(parents=True, exist_ok=True)\n",
    "    tmp_path = (tmp_dir / \"best.weights.h5\").resolve()\n",
    "\n",
    "    cbs = [\n",
    "        callbacks.EarlyStopping(monitor=\"val_loss\", patience=10, restore_best_weights=True, verbose=0),\n",
    "        callbacks.ModelCheckpoint(filepath=str(tmp_path), monitor=\"val_loss\",\n",
    "                                  save_best_only=True, save_weights_only=True),\n",
    "        TFKerasPruningCallback(trial, \"val_loss\"),\n",
    "    ]\n",
    "    model.fit(Xtr_seq, ytr_seq, validation_data=(Xva_seq, yva_seq),\n",
    "              epochs=eps, batch_size=bs, verbose=0, callbacks=cbs)\n",
    "\n",
    "    yhat = model.predict(Xva_seq, verbose=0).squeeze()\n",
    "    val_rmse = _rmse(yva_seq, yhat)\n",
    "\n",
    "    trial.set_user_attr(\"model_path\", str(tmp_path))\n",
    "    trial.set_user_attr(\"arch\", \"transformer\")\n",
    "    trial.set_user_attr(\"seq_len_used\", L)\n",
    "    trial.set_user_attr(\"n_feat\", Xtr_s.shape[1])\n",
    "    return val_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab6eee50",
   "metadata": {},
   "outputs": [],
   "source": [
    "storageB4 = prepare_journal_storage(\"ground_trackB_transformer\")\n",
    "studyB4 = optuna.create_study(direction=\"minimize\",\n",
    "                              sampler=TPESampler(seed=SEED),\n",
    "                              pruner=MedianPruner(n_startup_trials=8, n_warmup_steps=5),\n",
    "                              study_name=\"ground_trackB_transformer\",\n",
    "                              storage=storageB4, load_if_exists=True)\n",
    "print(\"Running Study B4 (Transformer)…\")\n",
    "studyB4.optimize(objective_transformer, n_trials=40, show_progress_bar=True)\n",
    "\n",
    "best_tr, _ = _safe_load_best(studyB4)\n",
    "bestL4 = studyB4.best_trial.user_attrs[\"seq_len_used\"]\n",
    "Xte_seq, yte_seq, idx_TR = build_seq_with_idx(Xte_s, yte, bestL4)\n",
    "yhatB4 = best_tr.predict(Xte_seq, verbose=0).squeeze()\n",
    "y_base_TR = pd.Series(y_base, index=Xte_df.index).reindex(idx_TR).to_numpy()\n",
    "print(\"Best Transformer params:\", studyB4.best_trial.params | {\"seq_len\": bestL4})\n",
    "print(f\"Transformer test → RMSE: {_rmse(yte_seq, yhatB4):.4f} | MAE: {mean_absolute_error(yte_seq, yhatB4):.4f} | R2: {r2_score(yte_seq, yhatB4):.4f} | Skill: {skill(yte_seq, yhatB4, y_base_TR):.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01676ed5",
   "metadata": {},
   "source": [
    "## Best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5bf2a76",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = {\n",
    "    \"MLP\":        studyA.best_trial.params,\n",
    "    \"LSTM\":       studyB1.best_trial.params | {\"seq_len\": studyB1.best_trial.user_attrs[\"seq_len_used\"]},\n",
    "    \"BiLSTM\":     studyB2.best_trial.params | {\"seq_len\": studyB2.best_trial.user_attrs[\"seq_len_used\"]},\n",
    "    \"CNN_LSTM\":   studyB3.best_trial.params | {\"seq_len\": studyB3.best_trial.user_attrs[\"seq_len_used\"]},\n",
    "    \"Transformer\":studyB4.best_trial.params | {\"seq_len\": studyB4.best_trial.user_attrs[\"seq_len_used\"]},\n",
    "}\n",
    "(out := OUT_DIR / \"best_hpo_params_all.json\")\n",
    "with open(out, \"w\") as f:\n",
    "    json.dump(best_params, f, indent=2)\n",
    "print(\"Saved params →\", out)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f728f0a",
   "metadata": {},
   "source": [
    "## Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65cbfe37",
   "metadata": {},
   "outputs": [],
   "source": [
    "models_info = {\n",
    "    \"MLP\": {\n",
    "        \"type\": \"tabular\",\n",
    "        \"model\": best_mlp,\n",
    "        \"idx\": Xte_df.index,\n",
    "        \"y_base\": y_base\n",
    "    },\n",
    "    \"LSTM\": {\n",
    "        \"type\": \"seq\",\n",
    "        \"model\": best_lstm,\n",
    "        \"L\": bestL1,\n",
    "        \"idx\": idx_LSTM,\n",
    "        \"y_base\": y_base_LSTM\n",
    "    },\n",
    "    \"BiLSTM\": {\n",
    "        \"type\": \"seq\",\n",
    "        \"model\": best_bi,\n",
    "        \"L\": bestL2,\n",
    "        \"idx\": idx_BI,\n",
    "        \"y_base\": y_base_BI\n",
    "    },\n",
    "    \"CNN-LSTM\": {\n",
    "        \"type\": \"seq\",\n",
    "        \"model\": best_cnn,\n",
    "        \"L\": bestL3,\n",
    "        \"idx\": idx_CNN,\n",
    "        \"y_base\": y_base_CNN\n",
    "    },\n",
    "    \"Transformer\": {\n",
    "        \"type\": \"seq\",\n",
    "        \"model\": best_tr,\n",
    "        \"L\": bestL4,\n",
    "        \"idx\": idx_TR,\n",
    "        \"y_base\": y_base_TR\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6de2026",
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = []\n",
    "OUT_FIG = Path(\"../reports/figures\")\n",
    "for name, cfg in models_info.items():\n",
    "    print(f\"\\n=== {name} ===\")\n",
    "    if cfg[\"type\"] == \"tabular\":\n",
    "        y_true = yte\n",
    "        y_pred = cfg[\"model\"].predict(Xte, verbose=0).squeeze()\n",
    "        idx    = cfg[\"idx\"]\n",
    "        yb     = cfg[\"y_base\"]\n",
    "    else:\n",
    "        L = int(cfg[\"L\"])\n",
    "        X_seq, y_seq, idx = build_seq_with_idx(Xte_s, yte, L)\n",
    "        if len(X_seq) == 0:\n",
    "            print(\"No hay secuencias válidas (NaNs). Se omite.\")\n",
    "            continue\n",
    "        y_true = y_seq\n",
    "        y_pred = cfg[\"model\"].predict(X_seq, verbose=0).squeeze()\n",
    "        yb     = pd.Series(y_base, index=Xte_df.index).reindex(idx).to_numpy()\n",
    "\n",
    "    rmse = _rmse(y_true, y_pred)\n",
    "    mae  = mean_absolute_error(y_true, y_pred)\n",
    "    r2   = r2_score(y_true, y_pred)\n",
    "    skl  = skill(y_true, y_pred, yb)\n",
    "    print(f\"RMSE={rmse:.4f} | MAE={mae:.4f} | R2={r2:.4f} | Skill={skl:.3f}\")\n",
    "\n",
    "    rows.append({\"model\": name, \"RMSE\": rmse, \"MAE\": mae, \"R2\": r2, \"Skill\": skl})\n",
    "\n",
    "    # 1) Time series (clip)\n",
    "    N = min(400, len(y_true))\n",
    "    plt.figure(figsize=(12, 3.6))\n",
    "    plt.plot(idx[:N], y_true[:N], label=\"truth\", lw=1.4)\n",
    "    plt.plot(idx[:N], y_pred[:N], label=name, lw=1.1)\n",
    "    plt.plot(idx[:N], yb[:N], label=\"baseline\", lw=1.0, alpha=0.7)\n",
    "    plt.title(f\"Test — Truth vs {name} vs Baseline ({TARGET})\")\n",
    "    plt.ylabel(\"GHI (W/m²)\" if TARGET.startswith(\"y_ghi\") else \"k-index\")\n",
    "    plt.xlabel(\"Time\"); plt.grid(True, ls=\"--\", alpha=0.3); plt.legend()\n",
    "    plt.xticks(rotation=45); plt.tight_layout()\n",
    "    plt.savefig(OUT_FIG / f\"{name}_ts_test.png\", dpi=140)\n",
    "    plt.show()\n",
    "\n",
    "    # 2) Scatter\n",
    "    lim_min = float(min(np.min(y_true), np.min(y_pred)))\n",
    "    lim_max = float(max(np.max(y_true), np.max(y_pred)))\n",
    "    plt.figure(figsize=(4.8, 4.8))\n",
    "    plt.scatter(y_true, y_pred, s=10, alpha=0.5)\n",
    "    plt.plot([lim_min, lim_max], [lim_min, lim_max], 'r--', lw=1.0)\n",
    "    plt.xlabel(\"Actual\"); plt.ylabel(\"Predicted\")\n",
    "    plt.title(f\"{name} — Actual vs Predicted\\nRMSE={rmse:.3f} MAE={mae:.3f} R2={r2:.3f}\")\n",
    "    plt.grid(True, ls=\"--\", alpha=0.3); plt.tight_layout()\n",
    "    plt.savefig(OUT_FIG / f\"{name}_scatter.png\", dpi=140)\n",
    "    plt.show()\n",
    "\n",
    "    # 3) Residuals histogram\n",
    "    resid = y_pred - y_true\n",
    "    plt.figure(figsize=(6, 3.2))\n",
    "    plt.hist(resid, bins=50, alpha=0.85)\n",
    "    plt.axvline(0, color='r', ls='--', lw=1)\n",
    "    plt.title(f\"{name} — Residuals (mean={np.mean(resid):.3f})\")\n",
    "    plt.xlabel(\"Residual\"); plt.ylabel(\"Frequency\")\n",
    "    plt.grid(True, ls=\"--\", alpha=0.3); plt.tight_layout()\n",
    "    plt.savefig(OUT_FIG / f\"{name}_residuals.png\", dpi=140)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "688e6743",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame(rows).sort_values(\"RMSE\")\n",
    "print(\"\\n=== Test Summary ===\")\n",
    "print(results_df.round(4))\n",
    "results_df.to_csv(OUT_DIR / \"hpo_models_test_summary.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "e_ladino",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
