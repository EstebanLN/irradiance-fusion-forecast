{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7811bfe6",
   "metadata": {},
   "source": [
    "# Fusion baseline Model (GOES + Ground)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "616708f3",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a9e8c5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np, pandas as pd\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import warnings; warnings.filterwarnings(\"ignore\")\n",
    "np.random.seed(42)\n",
    "\n",
    "# Deep learning\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, callbacks\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80442702",
   "metadata": {},
   "source": [
    "## Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eae382d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_train = Path(\"../data_processed/ground_train_h6.parquet\")\n",
    "ground_val   = Path(\"../data_processed/ground_val_h6.parquet\")\n",
    "ground_test  = Path(\"../data_processed/ground_test_h6.parquet\")\n",
    "\n",
    "sat_features = Path(\"../data_interim/goes_dataset/goes_features.parquet\")  # generado en tu pipeline\n",
    "target_col   = \"y_k_h6\"\n",
    "FREQ         = \"10min\"\n",
    "SEQ_LEN      = 12 # 12*10min = 2 horas de contexto"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3836198",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d79e4c9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ground shapes: (57789, 41) (12384, 41) (12384, 41)\n"
     ]
    }
   ],
   "source": [
    "g_tr = pd.read_parquet(ground_train)\n",
    "g_va = pd.read_parquet(ground_val)\n",
    "g_te = pd.read_parquet(ground_test)\n",
    "\n",
    "for g in (g_tr, g_va, g_te):\n",
    "    idx = pd.to_datetime(g.index)\n",
    "    g.index = idx.tz_localize(\"UTC\") if idx.tz is None else idx.tz_convert(\"UTC\")\n",
    "\n",
    "sat = pd.read_parquet(sat_features)\n",
    "sat.index = pd.to_datetime(sat.index)\n",
    "sat.index = sat.index.tz_localize(\"UTC\") if sat.index.tz is None else sat.index.tz_convert(\"UTC\")\n",
    "sat = sat.select_dtypes(include=[np.number])  # sólo numérico\n",
    "sat.index = sat.index.round(FREQ)\n",
    "sat = sat.groupby(sat.index).mean().sort_index()\n",
    "\n",
    "print(\"Ground:\", g_tr.shape, g_va.shape, g_te.shape, \" | Sat:\", sat.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfb92988",
   "metadata": {},
   "source": [
    "## Join & cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "996216bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_split(gdf, sat_df, target):\n",
    "    df = gdf.join(sat_df, how=\"left\")\n",
    "    df = df.dropna(subset=[target])\n",
    "\n",
    "    # features = todo lo numérico excepto targets\n",
    "    X = (\n",
    "        df.drop(columns=[c for c in df.columns if c.startswith(\"y_\") or c == target], errors=\"ignore\")\n",
    "          .select_dtypes(include=[np.number])\n",
    "          .astype(\"float32\")\n",
    "    )\n",
    "    y = df[target].astype(\"float32\")\n",
    "\n",
    "    # ffill/bfill por día para reducir huecos de sat\n",
    "    X = X.groupby(X.index.date).apply(lambda d: d.ffill().bfill()).reset_index(level=0, drop=True)\n",
    "    # quita columnas vacías\n",
    "    X = X.dropna(axis=1, how=\"all\")\n",
    "    # filtra filas con demasiados NaN\n",
    "    keep = (X.isna().mean(axis=1) <= 0.3)\n",
    "    X, y = X.loc[keep], y.loc[keep]\n",
    "    # relleno final mínimo\n",
    "    X = X.fillna(method=\"ffill\").fillna(method=\"bfill\")\n",
    "\n",
    "    return X, y\n",
    "\n",
    "Xtr, ytr = prepare_split(g_tr, sat, target_col)\n",
    "Xva, yva = prepare_split(g_va, sat, target_col)\n",
    "Xte, yte = prepare_split(g_te, sat, target_col)\n",
    "\n",
    "print(\"Joined — train:\", Xtr.shape, \"val:\", Xva.shape, \"test:\", Xte.shape)\n",
    "if min(len(Xtr), len(Xva), len(Xte)) == 0:\n",
    "    raise RuntimeError(\"❌ No quedaron filas tras el join/limpieza. Revisa cobertura temporal de sat/ground.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fada9bfc",
   "metadata": {},
   "source": [
    "## Baseline (RF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1a0e1ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>C01_mean</th>\n",
       "      <th>C01_std</th>\n",
       "      <th>C02_mean</th>\n",
       "      <th>C02_std</th>\n",
       "      <th>C03_mean</th>\n",
       "      <th>C03_std</th>\n",
       "      <th>C04_mean</th>\n",
       "      <th>C04_std</th>\n",
       "      <th>C05_mean</th>\n",
       "      <th>C05_std</th>\n",
       "      <th>...</th>\n",
       "      <th>C12_mean</th>\n",
       "      <th>C12_std</th>\n",
       "      <th>C13_mean</th>\n",
       "      <th>C13_std</th>\n",
       "      <th>C14_mean</th>\n",
       "      <th>C14_std</th>\n",
       "      <th>C15_mean</th>\n",
       "      <th>C15_std</th>\n",
       "      <th>C16_mean</th>\n",
       "      <th>C16_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2024-01-01 00:00:00+00:00</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-01 00:10:00+00:00</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-01 00:20:00+00:00</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-01 00:30:00+00:00</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-01 00:40:00+00:00</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           C01_mean  C01_std  C02_mean  C02_std  C03_mean  \\\n",
       "2024-01-01 00:00:00+00:00       NaN      NaN       NaN      NaN       NaN   \n",
       "2024-01-01 00:10:00+00:00       NaN      NaN       NaN      NaN       NaN   \n",
       "2024-01-01 00:20:00+00:00       NaN      NaN       NaN      NaN       NaN   \n",
       "2024-01-01 00:30:00+00:00       NaN      NaN       NaN      NaN       NaN   \n",
       "2024-01-01 00:40:00+00:00       NaN      NaN       NaN      NaN       NaN   \n",
       "\n",
       "                           C03_std  C04_mean  C04_std  C05_mean  C05_std  ...  \\\n",
       "2024-01-01 00:00:00+00:00      NaN       NaN      NaN       NaN      NaN  ...   \n",
       "2024-01-01 00:10:00+00:00      NaN       NaN      NaN       NaN      NaN  ...   \n",
       "2024-01-01 00:20:00+00:00      NaN       NaN      NaN       NaN      NaN  ...   \n",
       "2024-01-01 00:30:00+00:00      NaN       NaN      NaN       NaN      NaN  ...   \n",
       "2024-01-01 00:40:00+00:00      NaN       NaN      NaN       NaN      NaN  ...   \n",
       "\n",
       "                           C12_mean  C12_std  C13_mean  C13_std  C14_mean  \\\n",
       "2024-01-01 00:00:00+00:00       NaN      NaN       NaN      NaN       NaN   \n",
       "2024-01-01 00:10:00+00:00       NaN      NaN       NaN      NaN       NaN   \n",
       "2024-01-01 00:20:00+00:00       NaN      NaN       NaN      NaN       NaN   \n",
       "2024-01-01 00:30:00+00:00       NaN      NaN       NaN      NaN       NaN   \n",
       "2024-01-01 00:40:00+00:00       NaN      NaN       NaN      NaN       NaN   \n",
       "\n",
       "                           C14_std  C15_mean  C15_std  C16_mean  C16_std  \n",
       "2024-01-01 00:00:00+00:00      NaN       NaN      NaN       NaN      NaN  \n",
       "2024-01-01 00:10:00+00:00      NaN       NaN      NaN       NaN      NaN  \n",
       "2024-01-01 00:20:00+00:00      NaN       NaN      NaN       NaN      NaN  \n",
       "2024-01-01 00:30:00+00:00      NaN       NaN      NaN       NaN      NaN  \n",
       "2024-01-01 00:40:00+00:00      NaN       NaN      NaN       NaN      NaN  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def rmse(a,b): return mean_squared_error(a,b, squared=False)\n",
    "\n",
    "if \"k_ghi_lag1\" in Xte.columns:\n",
    "    yhat_base = Xte[\"k_ghi_lag1\"].clip(0, 2.0)\n",
    "else:\n",
    "    yhat_base = pd.Series(np.median(ytr), index=yte.index)\n",
    "\n",
    "print(\"Baseline → RMSE:\", rmse(yte, yhat_base), \" MAE:\", mean_absolute_error(yte, yhat_base))\n",
    "\n",
    "rf = RandomForestRegressor(n_estimators=400, random_state=42, n_jobs=-1)\n",
    "rf.fit(Xtr, ytr)\n",
    "yhat_te_rf = pd.Series(rf.predict(Xte), index=Xte.index)\n",
    "print(\"RF Test → RMSE:\", rmse(yte, yhat_te_rf), \" MAE:\", mean_absolute_error(yte, yhat_te_rf), \" R2:\", r2_score(yte, yhat_te_rf))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d1938607",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sat.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6152f1f",
   "metadata": {},
   "source": [
    "## Sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff4c891a",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sat' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m rows, times = [], []\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m ts, row \u001b[38;5;129;01min\u001b[39;00m \u001b[43msat\u001b[49m.iterrows():\n\u001b[32m      3\u001b[39m     out = {}\n\u001b[32m      4\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m channels:\n",
      "\u001b[31mNameError\u001b[39m: name 'sat' is not defined"
     ]
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "Xtr_s = pd.DataFrame(scaler.fit_transform(Xtr), index=Xtr.index, columns=Xtr.columns)\n",
    "Xva_s = pd.DataFrame(scaler.transform(Xva), index=Xva.index, columns=Xva.columns)\n",
    "Xte_s = pd.DataFrame(scaler.transform(Xte), index=Xte.index, columns=Xte.columns)\n",
    "\n",
    "def build_sequences(X_df, y_ser, seq_len):\n",
    "    Xv, yv = X_df.values, y_ser.values\n",
    "    n = len(X_df)\n",
    "    xs, ys, idxs = [], [], []\n",
    "    for i in range(seq_len-1, n):\n",
    "        # asumimos grilla regular 10 min; si quieres, verifica gaps aquí\n",
    "        block = Xv[i-seq_len+1:i+1]\n",
    "        if np.isnan(block).any():\n",
    "            continue\n",
    "        xs.append(block)\n",
    "        ys.append(yv[i])\n",
    "        idxs.append(X_df.index[i])\n",
    "    return np.array(xs, dtype=\"float32\"), np.array(ys, dtype=\"float32\"), pd.DatetimeIndex(idxs)\n",
    "\n",
    "Xtr_seq, ytr_seq, i_tr = build_sequences(Xtr_s, ytr, SEQ_LEN)\n",
    "Xva_seq, yva_seq, i_va = build_sequences(Xva_s, yva, SEQ_LEN)\n",
    "Xte_seq, yte_seq, i_te = build_sequences(Xte_s, yte, SEQ_LEN)\n",
    "\n",
    "n_features = Xtr_seq.shape[2]\n",
    "print(\"Seq shapes →\",\n",
    "      \"Xtr\", Xtr_seq.shape, \"Xva\", Xva_seq.shape, \"Xte\", Xte_seq.shape, \"| features:\", n_features)\n",
    "\n",
    "if min(len(Xtr_seq), len(Xva_seq), len(Xte_seq)) == 0:\n",
    "    raise RuntimeError(\"❌ No hay suficientes ventanas para las secuencias. Reduce SEQ_LEN o revisa cobertura.\")\n",
    "\n",
    "# Alinear baseline a las muestras secuenciales del test\n",
    "ybase_seq = yhat_base.reindex(i_te).to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ca57f39",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c03cddaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Joined shapes — train: (40344, 40) val: (12360, 40) test: (0, 40)\n"
     ]
    }
   ],
   "source": [
    "es = callbacks.EarlyStopping(patience=10, restore_best_weights=True, monitor=\"val_loss\")\n",
    "\n",
    "def fit_and_eval(model, name, epochs=60, batch=256):\n",
    "    model.compile(optimizer=\"adam\", loss=\"mse\", metrics=[tf.keras.metrics.MAE])\n",
    "    hist = model.fit(Xtr_seq, ytr_seq,\n",
    "                     validation_data=(Xva_seq, yva_seq),\n",
    "                     epochs=epochs, batch_size=batch,\n",
    "                     verbose=0, callbacks=[es])\n",
    "    # predicciones\n",
    "    yhat_va = model.predict(Xva_seq, verbose=0).squeeze()\n",
    "    yhat_te = model.predict(Xte_seq, verbose=0).squeeze()\n",
    "    # métricas\n",
    "    def rmse_np(a,b): return np.sqrt(np.mean((a-b)**2))\n",
    "    print(f\"{name} → Val RMSE: {rmse_np(yva_seq, yhat_va):.4f} | Test RMSE: {rmse_np(yte_seq, yhat_te):.4f} \"\n",
    "          f\"| Test MAE: {mean_absolute_error(yte_seq, yhat_te):.4f} | R2: {r2_score(yte_seq, yhat_te):.4f}\")\n",
    "    return hist, yhat_te"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60bf9473",
   "metadata": {},
   "outputs": [],
   "source": [
    "mdl_lstm = models.Sequential([\n",
    "    layers.Input(shape=(SEQ_LEN, n_features)),\n",
    "    layers.LSTM(64),\n",
    "    layers.Dense(1)\n",
    "])\n",
    "hist_lstm, yhat_lstm = fit_and_eval(mdl_lstm, \"LSTM\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a313f4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "mdl_bilstm = models.Sequential([\n",
    "    layers.Input(shape=(SEQ_LEN, n_features)),\n",
    "    layers.Bidirectional(layers.LSTM(64)),\n",
    "    layers.Dense(1)\n",
    "])\n",
    "hist_bilstm, yhat_bilstm = fit_and_eval(mdl_bilstm, \"BiLSTM\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6b7b4b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "mdl_cnnlstm = models.Sequential([\n",
    "    layers.Input(shape=(SEQ_LEN, n_features)),\n",
    "    layers.Conv1D(32, kernel_size=3, padding=\"causal\", activation=\"relu\"),\n",
    "    layers.MaxPooling1D(pool_size=2),\n",
    "    layers.LSTM(64),\n",
    "    layers.Dense(1)\n",
    "])\n",
    "hist_cnnlstm, yhat_cnnlstm = fit_and_eval(mdl_cnnlstm, \"CNN-LSTM\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3217e9d",
   "metadata": {},
   "source": [
    "## Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec8febc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_series(y_true, preds_dict, n=500, title=\"Test — Truth vs Models (primeros puntos)\"):\n",
    "    sl = slice(0, min(n, len(y_true)))\n",
    "    plt.figure(figsize=(10,3))\n",
    "    plt.plot(y_true[sl], label=\"truth\", lw=1.2)\n",
    "    for name, yhat in preds_dict.items():\n",
    "        plt.plot(pd.Series(yhat, index=i_te)[sl], label=name, lw=1.0)\n",
    "    plt.title(title); plt.grid(True, ls=\"--\", alpha=0.3); plt.legend(); plt.tight_layout(); plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "936ea626",
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import isfinite\n",
    "plot_series(pd.Series(yte_seq, index=i_te),\n",
    "            {\"baseline\": ybase_seq,\n",
    "             \"RF\": yhat_te_rf.reindex(i_te).values,\n",
    "             \"LSTM\": yhat_lstm,\n",
    "             \"BiLSTM\": yhat_bilstm,\n",
    "             \"CNN-LSTM\": yhat_cnnlstm},\n",
    "            n=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b42c70b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scatter_plot(y_true, y_pred, name):\n",
    "    plt.figure(figsize=(4.2,4))\n",
    "    plt.scatter(y_true, y_pred, s=8, alpha=0.4)\n",
    "    lim = [0, max(2.0, np.nanmax(y_true), np.nanmax(y_pred))]\n",
    "    plt.plot(lim, lim, \"k--\", lw=1)\n",
    "    plt.xlim(lim); plt.ylim(lim)\n",
    "    plt.xlabel(\"y_true (k)\"); plt.ylabel(\"y_pred (k)\")\n",
    "    plt.title(f\"Scatter Test — {name}\")\n",
    "    plt.grid(True, ls=\"--\", alpha=0.3); plt.tight_layout(); plt.show()\n",
    "\n",
    "scatter_plot(yte_seq, yhat_cnnlstm, \"CNN-LSTM\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ee40155",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hist residual (CNN-LSTM)\n",
    "res = yhat_cnnlstm - yte_seq\n",
    "plt.figure(figsize=(6,3)); plt.hist(res, bins=40, alpha=0.85)\n",
    "plt.title(\"Residuals (y_pred - y_true) — CNN-LSTM (Test)\")\n",
    "plt.xlabel(\"residual\"); plt.ylabel(\"count\")\n",
    "plt.grid(True, ls=\"--\", alpha=0.3); plt.tight_layout(); plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3b9517a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Skill vs Baseline (secuencias)\n",
    "def rmse_np(a,b): return np.sqrt(np.mean((a-b)**2))\n",
    "rmse_base = rmse_np(yte_seq, ybase_seq)\n",
    "for name, yhat in [(\"RF\", yhat_te_rf.reindex(i_te).values),\n",
    "                   (\"LSTM\", yhat_lstm),\n",
    "                   (\"BiLSTM\", yhat_bilstm),\n",
    "                   (\"CNN-LSTM\", yhat_cnnlstm)]:\n",
    "    s = 1 - (rmse_np(yte_seq, yhat) / rmse_base)\n",
    "    print(f\"Skill (RMSE) vs baseline — {name}: {s:.3f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "e_ladino",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
