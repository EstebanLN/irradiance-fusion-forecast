{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8203d6aa",
   "metadata": {},
   "source": [
    "# Final Ground Model with Optuna (MLP, LSTM, BiLSTM, CNN-LSTM, Transformer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a406c53",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5ed6cf39",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-19 15:46:39.832527: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-11-19 15:46:39.838762: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1763585199.845787  676494 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1763585199.848170  676494 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-11-19 15:46:39.856407: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 AVX512F AVX512_VNNI AVX512_BF16 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import os, json, numpy as np, pandas as pd, matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, callbacks, regularizers, backend as K\n",
    "\n",
    "import optuna\n",
    "from optuna.samplers import TPESampler\n",
    "from optuna.pruners import MedianPruner\n",
    "from optuna.integration import TFKerasPruningCallback\n",
    "from optuna.storages import JournalStorage\n",
    "from optuna.storages import JournalFileStorage, JournalFileOpenLock"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8fc47f6",
   "metadata": {},
   "source": [
    "## Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1c7ce94f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Studies dir: /mnt/SOLARLAB/E_Ladino/Repo/irradiance-fusion-forecast/optuna_studies/05_ground_hpo_optuna_v1\n",
      "Artifacts dir: /mnt/SOLARLAB/E_Ladino/Repo/irradiance-fusion-forecast/models/optuna_artifacts\n"
     ]
    }
   ],
   "source": [
    "SEED = 42\n",
    "np.random.seed(SEED); tf.random.set_seed(SEED)\n",
    "\n",
    "DATA_DIR = Path(\"../data_processed\")\n",
    "OUT_DIR  = Path(\"../models\"); OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "STUDY_DIR= Path(\"../optuna_studies/05_ground_hpo_optuna_v1\"); STUDY_DIR.mkdir(parents=True, exist_ok=True)\n",
    "ART_DIR  = (OUT_DIR / \"optuna_artifacts\").resolve(); ART_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "TRAIN_PQ = DATA_DIR / \"ground_train_h6.parquet\"\n",
    "VAL_PQ   = DATA_DIR / \"ground_val_h6.parquet\"\n",
    "TEST_PQ  = DATA_DIR / \"ground_test_h6.parquet\"\n",
    "TARGET   = \"y_ghi_h6\" \n",
    "\n",
    "print(\"Studies dir:\", STUDY_DIR.resolve())\n",
    "print(\"Artifacts dir:\", ART_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7e639da",
   "metadata": {},
   "source": [
    "### Data loading and preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "89b4b493",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_parquet(TRAIN_PQ).sort_index()\n",
    "val   = pd.read_parquet(VAL_PQ).sort_index()\n",
    "test  = pd.read_parquet(TEST_PQ).sort_index()\n",
    "assert TARGET in train and TARGET in val and TARGET in test, f\"{TARGET} missing!\"\n",
    "\n",
    "feat_cols = sorted(list(set(train.columns) & set(val.columns) & set(test.columns) - {TARGET}))\n",
    "feat_cols = [c for c in feat_cols if pd.api.types.is_numeric_dtype(train[c])]\n",
    "\n",
    "Xtr_df, ytr = train[feat_cols], train[TARGET]\n",
    "Xva_df, yva = val[feat_cols],   val[TARGET]\n",
    "Xte_df, yte = test[feat_cols],  test[TARGET]\n",
    "\n",
    "scaler = StandardScaler()\n",
    "Xtr = scaler.fit_transform(Xtr_df)\n",
    "Xva = scaler.transform(Xva_df)\n",
    "Xte = scaler.transform(Xte_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f85f1e32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Hr', 'azimuth', 'dewpoint_c', 'dewpoint_c_lag1', 'dewpoint_c_lag2', 'dewpoint_c_lag3', 'dewpoint_c_roll_mean_1h', 'dewpoint_c_roll_std_1h', 'doy_cos', 'doy_sin', 'ghi_cs', 'ghi_qc_lag1', 'ghi_qc_lag2', 'ghi_qc_lag3', 'ghi_qc_roll_mean_1h', 'ghi_qc_roll_std_1h', 'hod_cos', 'hod_sin', 'k_ghi_lag1', 'k_ghi_lag2', 'k_ghi_lag3', 'k_ghi_roll_mean_1h', 'k_ghi_roll_std_1h', 'p_hpa', 'temp_c', 'temp_c_lag1', 'temp_c_lag2', 'temp_c_lag3', 'temp_c_roll_mean_1h', 'temp_c_roll_std_1h', 'u_ms', 'u_ms_lag1', 'u_ms_lag2', 'u_ms_lag3', 'u_ms_roll_mean_1h', 'u_ms_roll_std_1h', 'v_ms', 'v_ms_lag1', 'v_ms_lag2', 'v_ms_lag3', 'v_ms_roll_mean_1h', 'v_ms_roll_std_1h', 'wdir_deg', 'wspd_ms', 'zenith']\n"
     ]
    }
   ],
   "source": [
    "print(feat_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9305a371",
   "metadata": {},
   "source": [
    "## Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "05a460c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _rmse(a,b):\n",
    "    return float(np.sqrt(mean_squared_error(a,b)))\n",
    "\n",
    "def skill(y_true, y_pred, y_base):\n",
    "    return 1.0 - (_rmse(y_true, y_pred) / _rmse(y_true, y_base))\n",
    "\n",
    "def _build_seq(X_df, y_ser, L):\n",
    "    \"\"\"Secuencias sin índice (rápido para objetivos Optuna).\"\"\"\n",
    "    Xv, yv = X_df.values, y_ser.values\n",
    "    xs, ys = [], []\n",
    "    for i in range(L-1, len(X_df)):\n",
    "        block = Xv[i-L+1:i+1]\n",
    "        if np.isnan(block).any():\n",
    "            continue\n",
    "        xs.append(block); ys.append(yv[i])\n",
    "    return np.asarray(xs, dtype=\"float32\"), np.asarray(ys, dtype=\"float32\")\n",
    "\n",
    "def build_seq_with_idx(X_df, y_ser, L):\n",
    "    \"\"\"Secuencias con índice (para evaluación y plots).\"\"\"\n",
    "    Xv, yv = X_df.values, y_ser.values\n",
    "    xs, ys, idx = [], [], []\n",
    "    for i in range(L-1, len(X_df)):\n",
    "        block = Xv[i-L+1:i+1]\n",
    "        if np.isnan(block).any():\n",
    "            continue\n",
    "        xs.append(block); ys.append(yv[i]); idx.append(X_df.index[i])\n",
    "    return (np.asarray(xs, dtype=\"float32\"),\n",
    "            np.asarray(ys, dtype=\"float32\"),\n",
    "            pd.DatetimeIndex(idx))\n",
    "\n",
    "def prepare_journal_storage(study_name: str) -> JournalStorage:\n",
    "    log_path   = STUDY_DIR / f\"{study_name}.log\"\n",
    "    lock_path  = STUDY_DIR / f\"{study_name}.lock\"\n",
    "    try: lock_path.unlink()\n",
    "    except FileNotFoundError: pass\n",
    "    file_storage = JournalFileStorage(str(log_path), lock_obj=JournalFileOpenLock(str(lock_path)))\n",
    "    return JournalStorage(file_storage)\n",
    "\n",
    "# def _safe_load_best(study, rebuild_fn=None):\n",
    "#     \"\"\"Carga robusta del mejor modelo guardado por el estudio.\"\"\"\n",
    "#     p = Path(study.best_trial.user_attrs[\"model_path\"])\n",
    "#     if not p.exists():\n",
    "#         # fallback: buscar por nombre\n",
    "#         hits = list(ART_DIR.rglob(p.name))\n",
    "#         if hits:\n",
    "#             p = hits[0]\n",
    "#         elif rebuild_fn is not None:\n",
    "#             model = rebuild_fn(study.best_trial.params)\n",
    "#             p = ART_DIR / \"recover.keras\"\n",
    "#             model.save(p)\n",
    "#         else:\n",
    "#             raise FileNotFoundError(f\"Checkpoint not found: {p}\")\n",
    "#     return tf.keras.models.load_model(p), p"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e762b245",
   "metadata": {},
   "source": [
    "### Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "69ab07d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_mlp(input_dim, n1=128, n2=64, do1=0.2, do2=0.1, act=\"relu\", l2w=0.0):\n",
    "    return tf.keras.Sequential([\n",
    "        layers.Input(shape=(input_dim,)),\n",
    "        layers.Dense(n1, activation=act, kernel_regularizer=regularizers.l2(l2w)),\n",
    "        layers.Dropout(do1),\n",
    "        layers.Dense(n2, activation=act, kernel_regularizer=regularizers.l2(l2w)),\n",
    "        layers.Dropout(do2),\n",
    "        layers.Dense(1, dtype=\"float32\"),\n",
    "    ])\n",
    "\n",
    "def build_lstm(L, n_feat, units=64, do=0.0):\n",
    "    inp = layers.Input(shape=(L, n_feat))\n",
    "    x   = layers.LSTM(units, dropout=do)(inp)\n",
    "    out = layers.Dense(1, dtype=\"float32\")(x)\n",
    "    return tf.keras.Model(inp, out)\n",
    "\n",
    "def build_bilstm(L, n_feat, units=64, do=0.0):\n",
    "    inp = layers.Input(shape=(L, n_feat))\n",
    "    x   = layers.Bidirectional(layers.LSTM(units, dropout=do))(inp)\n",
    "    out = layers.Dense(1, dtype=\"float32\")(x)\n",
    "    return tf.keras.Model(inp, out)\n",
    "\n",
    "def build_cnnlstm(L, n_feat, filt=32, ksz=3, pool=1, lstm_units=64, do=0.0):\n",
    "    inp = layers.Input(shape=(L, n_feat))\n",
    "    x   = layers.Conv1D(filt, kernel_size=ksz, padding=\"causal\", activation=\"relu\")(inp)\n",
    "    x   = (layers.MaxPooling1D(pool_size=pool)(x) if pool>1 else layers.Identity()(x))\n",
    "    x   = layers.LSTM(lstm_units, dropout=do)(x)\n",
    "    out = layers.Dense(1, dtype=\"float32\")(x)\n",
    "    return tf.keras.Model(inp, out)\n",
    "\n",
    "def build_transformer(L, n_feat, d_model=64, heads=4, ff_dim=128, att_do=0.1, do=0.0):\n",
    "    inp = layers.Input(shape=(L, n_feat))\n",
    "    x   = layers.Dense(d_model)(inp)\n",
    "    x2  = layers.MultiHeadAttention(num_heads=heads, key_dim=d_model//heads, dropout=att_do)(x, x)\n",
    "    x   = layers.Add()([x, x2]); x = layers.LayerNormalization()(x)\n",
    "    ff  = layers.Dense(ff_dim, activation=\"relu\")(x); ff = layers.Dense(d_model)(ff)\n",
    "    x   = layers.Add()([x, ff]); x = layers.LayerNormalization()(x)\n",
    "    x   = layers.GlobalAveragePooling1D()(x)\n",
    "    x   = layers.Dropout(do)(x)\n",
    "    out = layers.Dense(1, dtype=\"float32\")(x)\n",
    "    return tf.keras.Model(inp, out)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7fc2449",
   "metadata": {},
   "source": [
    "### Saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3518825a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _safe_load_best(study):\n",
    "    \"\"\"\n",
    "    Carga robusta: si el best_trial no tiene los nuevos user_attrs (arch, seq_len_used, n_feat),\n",
    "    los infiere desde study_name / ruta del checkpoint / params del trial.\n",
    "    Reconstruye la arquitectura y carga PESOS (.weights.h5 o .keras/.h5 legacy).\n",
    "    \"\"\"\n",
    "    ua = dict(study.best_trial.user_attrs) if study.best_trial.user_attrs else {}\n",
    "\n",
    "    # 1) Localiza el checkpoint\n",
    "    wpath = None\n",
    "    if \"model_path\" in ua:\n",
    "        p = Path(ua[\"model_path\"])\n",
    "        if p.exists():\n",
    "            wpath = p\n",
    "        else:\n",
    "            hits = list(ART_DIR.rglob(p.name))\n",
    "            if hits:\n",
    "                wpath = hits[0]\n",
    "    if wpath is None:\n",
    "        # Fallback: deduce por nombre de estudio\n",
    "        # Busca archivos 'best.weights.h5' o 'best.keras' en ART_DIR que coincidan con el estudio\n",
    "        patt = []\n",
    "        name = (study.study_name or \"\").lower()\n",
    "        if \"mlp\" in name: patt.append(\"A_mlp_*\")\n",
    "        if \"lstm\" in name and \"bilstm\" not in name: patt.append(\"B_lstm_*\")\n",
    "        if \"bilstm\" in name: patt.append(\"B_bilstm_*\")\n",
    "        if \"cnn\" in name: patt.append(\"B_cnnlstm_*\")\n",
    "        if \"transformer\" in name: patt.append(\"B_transformer_*\")\n",
    "        candidates = []\n",
    "        for pat in (patt or [\"*\"]):\n",
    "            candidates += list(ART_DIR.glob(f\"{pat}/best.weights.h5\"))\n",
    "            candidates += list(ART_DIR.glob(f\"{pat}/best.keras\"))\n",
    "            candidates += list(ART_DIR.glob(f\"{pat}/best.h5\"))\n",
    "        if not candidates:\n",
    "            raise FileNotFoundError(\"No checkpoint found for best trial and no user_attrs['model_path'].\")\n",
    "        # Toma el más reciente\n",
    "        wpath = max(candidates, key=lambda p: p.stat().st_mtime)\n",
    "\n",
    "    # 2) Deducir 'arch'\n",
    "    arch = ua.get(\"arch\")\n",
    "    base = wpath.parent.name.lower()\n",
    "    sname = (study.study_name or \"\").lower()\n",
    "    if arch is None:\n",
    "        if \"mlp\" in sname or base.startswith(\"a_mlp\"):\n",
    "            arch = \"mlp\"\n",
    "        elif \"bilstm\" in sname or \"b_bilstm\" in base:\n",
    "            arch = \"bilstm\"\n",
    "        elif (\"lstm\" in sname and \"bilstm\" not in sname) or \"b_lstm\" in base:\n",
    "            arch = \"lstm\"\n",
    "        elif \"cnn\" in sname or \"cnn\" in base:\n",
    "            arch = \"cnn-lstm\"\n",
    "        elif \"transformer\" in sname or \"transformer\" in base:\n",
    "            arch = \"transformer\"\n",
    "        else:\n",
    "            raise KeyError(\"Cannot infer 'arch' from study; please re-run trials or set user_attrs.\")\n",
    "\n",
    "    # 3) Deducir L y n_feat para secuenciales\n",
    "    params = study.best_trial.params\n",
    "    L = ua.get(\"seq_len_used\") or params.get(\"seq_len\")\n",
    "    n_feat = ua.get(\"n_feat\")\n",
    "    if arch != \"mlp\":\n",
    "        if L is None:\n",
    "            # default razonable si faltara\n",
    "            L = 12\n",
    "        if n_feat is None:\n",
    "            # usar el contexto global ya cargado\n",
    "            n_feat = int(Xtr_s.shape[1])\n",
    "\n",
    "    # 4) Reconstruye modelo y carga pesos / modelo\n",
    "    # (acepta tanto weights-only como modelo completo legacy)\n",
    "    if wpath.suffix in {\".keras\", \".h5\"} and \"weights\" not in wpath.name:\n",
    "        # Legacy: modelo completo; cargar con safe_mode desactivado SOLO si confías en el archivo\n",
    "        import keras\n",
    "        try:\n",
    "            keras.config.enable_unsafe_deserialization()\n",
    "        except Exception:\n",
    "            pass\n",
    "        model = tf.keras.models.load_model(wpath, compile=False, safe_mode=False)\n",
    "        model.compile(optimizer=\"adam\", loss=\"mse\", metrics=[\"mae\"])\n",
    "        return model, wpath\n",
    "\n",
    "    # Weights-only (recomendado)\n",
    "    if arch == \"mlp\":\n",
    "        model = build_mlp(\n",
    "            input_dim=Xtr.shape[1],\n",
    "            n1=params.get(\"n1\",128),\n",
    "            n2=params.get(\"n2\",64),\n",
    "            do1=params.get(\"do1\",0.0),\n",
    "            do2=params.get(\"do2\",0.0),\n",
    "            act=params.get(\"act\",\"relu\"),\n",
    "            l2w=params.get(\"l2\",0.0),\n",
    "        )\n",
    "    elif arch == \"lstm\":\n",
    "        model = build_lstm(int(L), int(n_feat),\n",
    "                           units=params.get(\"units\",64),\n",
    "                           do=params.get(\"dropout\",0.0))\n",
    "    elif arch == \"bilstm\":\n",
    "        model = build_bilstm(int(L), int(n_feat),\n",
    "                             units=params.get(\"units\",64),\n",
    "                             do=params.get(\"dropout\",0.0))\n",
    "    elif arch == \"cnn-lstm\":\n",
    "        model = build_cnnlstm(int(L), int(n_feat),\n",
    "                              filt=params.get(\"filters\",32),\n",
    "                              ksz=params.get(\"kernel_size\",3),\n",
    "                              pool=params.get(\"pool\",1),\n",
    "                              lstm_units=params.get(\"lstm_units\",64),\n",
    "                              do=params.get(\"dropout\",0.0))\n",
    "    elif arch == \"transformer\":\n",
    "        model = build_transformer(int(L), int(n_feat),\n",
    "                                  d_model=params.get(\"d_model\",64),\n",
    "                                  heads=params.get(\"heads\",4),\n",
    "                                  ff_dim=params.get(\"ff_dim\",128),\n",
    "                                  att_do=params.get(\"att_dropout\",0.1),\n",
    "                                  do=params.get(\"dropout\",0.0))\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown arch: {arch}\")\n",
    "\n",
    "    model.compile(optimizer=\"adam\", loss=\"mse\", metrics=[\"mae\"])\n",
    "    model.load_weights(str(wpath))\n",
    "    return model, wpath\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd38d785",
   "metadata": {},
   "source": [
    "## Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1d7b3333",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline → RMSE: 196.2835 | MAE: 102.1871\n"
     ]
    }
   ],
   "source": [
    "base_src = None\n",
    "\n",
    "# for c in [\"k_ghi\",\"k_raw\",\"k_ghi_lag1\",\"k_raw_lag1\"]:\n",
    "#     if c in test.columns: base_src = test[c]; break\n",
    "# if base_src is None:\n",
    "#     base_src = pd.Series(np.nanmedian(ytr), index=test.index)\n",
    "\n",
    "for c in [\"ghi_qc\",\"ghi_sg_definitive\",\"ghi_qc_lag1\"]:\n",
    "    if c in test.columns: base_src = test[c]; break\n",
    "if base_src is None:\n",
    "    base_src = pd.Series(np.nanmedian(ytr), index=test.index)\n",
    "\n",
    "y_base = base_src.to_numpy()\n",
    "print(f\"Baseline → RMSE: {_rmse(yte, y_base):.4f} | MAE: {mean_absolute_error(yte, y_base):.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b684d0e0",
   "metadata": {},
   "source": [
    "## Track A - MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a2285184",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_mlp(trial: optuna.Trial) -> float:\n",
    "    K.clear_session()\n",
    "    n1  = trial.suggest_int(\"n1\", 64, 512, step=64)\n",
    "    n2  = trial.suggest_int(\"n2\", 32, max(64, n1//2), step=32)\n",
    "    do1 = trial.suggest_float(\"do1\", 0.0, 0.5)\n",
    "    do2 = trial.suggest_float(\"do2\", 0.0, 0.5)\n",
    "    lr  = trial.suggest_float(\"lr\", 1e-4, 5e-3, log=True)\n",
    "    l2w = trial.suggest_float(\"l2\", 1e-8, 1e-3, log=True)\n",
    "    act = trial.suggest_categorical(\"act\", [\"relu\",\"selu\",\"gelu\"])\n",
    "    bs  = trial.suggest_categorical(\"batch\", [64, 128, 256, 512])\n",
    "    eps = trial.suggest_int(\"epochs\", 40, 150)\n",
    "\n",
    "    model = build_mlp(Xtr.shape[1], n1=n1, n2=n2, do1=do1, do2=do2, act=act, l2w=l2w)\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=lr),\n",
    "                  loss=\"mse\", metrics=[\"mae\"])\n",
    "\n",
    "    tmp_dir  = ART_DIR / f\"A_mlp_t{trial.number:04d}\"; tmp_dir.mkdir(parents=True, exist_ok=True)\n",
    "    tmp_path = (tmp_dir / \"best.weights.h5\").resolve()\n",
    "\n",
    "    cbs = [\n",
    "        callbacks.EarlyStopping(monitor=\"val_loss\", patience=12, restore_best_weights=True, verbose=0),\n",
    "        callbacks.ReduceLROnPlateau(monitor=\"val_loss\", factor=0.5, patience=6, min_lr=1e-5, verbose=0),\n",
    "        callbacks.ModelCheckpoint(filepath=str(tmp_path), monitor=\"val_loss\",\n",
    "                                  save_best_only=True, save_weights_only=True),\n",
    "        TFKerasPruningCallback(trial, \"val_loss\"),\n",
    "    ]\n",
    "\n",
    "    model.fit(Xtr, ytr, validation_data=(Xva, yva),\n",
    "              epochs=eps, batch_size=bs, verbose=0, callbacks=cbs)\n",
    "\n",
    "    yhat = model.predict(Xva, verbose=0).squeeze()\n",
    "    val_rmse = _rmse(yva, yhat)\n",
    "\n",
    "    trial.set_user_attr(\"model_path\", str(tmp_path))\n",
    "    trial.set_user_attr(\"arch\", \"mlp\")\n",
    "    trial.set_user_attr(\"input_dim\", Xtr.shape[1])\n",
    "    return val_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb7a4566",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_676494/3240221310.py:36: FutureWarning: The import path :class:`~optuna.storages.JournalFileOpenLock` has been deprecated in v4.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v4.0.0. Use :class:`~optuna.storages.journal.JournalFileOpenLock` instead.\n",
      "  file_storage = JournalFileStorage(str(log_path), lock_obj=JournalFileOpenLock(str(lock_path)))\n",
      "/tmp/ipykernel_676494/3240221310.py:36: FutureWarning: JournalFileStorage has been deprecated in v4.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v4.0.0. Use :class:`~optuna.storages.journal.JournalFileBackend` instead.\n",
      "  file_storage = JournalFileStorage(str(log_path), lock_obj=JournalFileOpenLock(str(lock_path)))\n",
      "[I 2025-11-19 15:46:47,458] Using an existing study with name 'ground_trackA_mlp' instead of creating a new one.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Study A (MLP)…\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3189520a91004443b173d7eea1397f6f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1763585212.030226  676494 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 17584 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4090, pci bus id: 0000:01:00.0, compute capability: 8.9\n",
      "I0000 00:00:1763585213.366499  676630 service.cc:148] XLA service 0x7c399c01aab0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1763585213.366525  676630 service.cc:156]   StreamExecutor device (0): NVIDIA GeForce RTX 4090, Compute Capability 8.9\n",
      "2025-11-19 15:46:53.380825: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "I0000 00:00:1763585213.431116  676630 cuda_dnn.cc:529] Loaded cuDNN version 90101\n",
      "I0000 00:00:1763585214.644602  676630 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-19 15:47:05,133] Trial 46 pruned. Trial was pruned at epoch 7.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-19 15:47:11.785924: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_48_0', 256 bytes spill stores, 256 bytes spill loads\n",
      "\n",
      "2025-11-19 15:47:11.831379: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_48_0', 776 bytes spill stores, 724 bytes spill loads\n",
      "\n",
      "2025-11-19 15:47:12.432322: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_48_0', 260 bytes spill stores, 292 bytes spill loads\n",
      "\n",
      "2025-11-19 15:47:12.589585: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_48_0', 1044 bytes spill stores, 732 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-19 15:47:22,485] Trial 47 pruned. Trial was pruned at epoch 5.\n",
      "[I 2025-11-19 15:47:42,488] Trial 48 pruned. Trial was pruned at epoch 5.\n",
      "[I 2025-11-19 15:48:08,235] Trial 49 pruned. Trial was pruned at epoch 15.\n",
      "[I 2025-11-19 15:48:33,613] Trial 50 pruned. Trial was pruned at epoch 7.\n",
      "[I 2025-11-19 15:48:49,294] Trial 51 pruned. Trial was pruned at epoch 5.\n",
      "[I 2025-11-19 15:49:05,868] Trial 52 pruned. Trial was pruned at epoch 5.\n",
      "[I 2025-11-19 15:50:01,572] Trial 53 finished with value: 129.91637935610737 and parameters: {'n1': 256, 'n2': 96, 'do1': 0.3839648965685951, 'do2': 0.25150335484031106, 'lr': 0.003965090997776624, 'l2': 4.429404772444898e-05, 'act': 'gelu', 'batch': 512, 'epochs': 70}. Best is trial 32 with value: 129.6991561026902.\n",
      "[I 2025-11-19 15:50:57,837] Trial 54 finished with value: 130.01483539148524 and parameters: {'n1': 320, 'n2': 128, 'do1': 0.1884979853831891, 'do2': 0.3138205158294623, 'lr': 0.002462635028933902, 'l2': 0.00012202518958340676, 'act': 'gelu', 'batch': 512, 'epochs': 84}. Best is trial 32 with value: 129.6991561026902.\n",
      "[I 2025-11-19 15:51:39,859] Trial 55 finished with value: 129.75579527038474 and parameters: {'n1': 384, 'n2': 160, 'do1': 0.4682065516535711, 'do2': 0.2828053311333306, 'lr': 0.003005020533498331, 'l2': 0.00016173771023025632, 'act': 'gelu', 'batch': 512, 'epochs': 86}. Best is trial 32 with value: 129.6991561026902.\n",
      "[I 2025-11-19 15:51:59,829] Trial 56 pruned. Trial was pruned at epoch 5.\n",
      "[I 2025-11-19 15:52:45,729] Trial 57 finished with value: 129.94421880176125 and parameters: {'n1': 448, 'n2': 192, 'do1': 0.45516691066018655, 'do2': 0.32482807101393196, 'lr': 0.003045370173795237, 'l2': 2.617224561138091e-05, 'act': 'gelu', 'batch': 512, 'epochs': 76}. Best is trial 32 with value: 129.6991561026902.\n",
      "[I 2025-11-19 15:52:59,918] Trial 58 pruned. Trial was pruned at epoch 5.\n",
      "[I 2025-11-19 15:53:32,082] Trial 59 finished with value: 129.91402655939427 and parameters: {'n1': 448, 'n2': 192, 'do1': 0.43886538875997716, 'do2': 0.38161625654375125, 'lr': 0.003407606562526955, 'l2': 0.0003718203235172278, 'act': 'gelu', 'batch': 512, 'epochs': 51}. Best is trial 32 with value: 129.6991561026902.\n",
      "[I 2025-11-19 15:54:08,360] Trial 60 finished with value: 129.88952637722565 and parameters: {'n1': 384, 'n2': 160, 'do1': 0.3510348019123299, 'do2': 0.3522093717068979, 'lr': 0.0021871040924309904, 'l2': 0.00015581582572575975, 'act': 'gelu', 'batch': 512, 'epochs': 43}. Best is trial 32 with value: 129.6991561026902.\n",
      "[I 2025-11-19 15:54:55,392] Trial 61 finished with value: 129.87347358342657 and parameters: {'n1': 448, 'n2': 192, 'do1': 0.47445595821049186, 'do2': 0.2227647382885829, 'lr': 0.0017465444767743655, 'l2': 0.0005781466057989363, 'act': 'gelu', 'batch': 128, 'epochs': 73}. Best is trial 32 with value: 129.6991561026902.\n",
      "[I 2025-11-19 15:55:08,545] Trial 62 pruned. Trial was pruned at epoch 5.\n",
      "[I 2025-11-19 15:55:22,696] Trial 63 pruned. Trial was pruned at epoch 6.\n",
      "[I 2025-11-19 15:55:36,295] Trial 64 pruned. Trial was pruned at epoch 5.\n",
      "[I 2025-11-19 15:55:50,791] Trial 65 pruned. Trial was pruned at epoch 5.\n",
      "[I 2025-11-19 15:56:06,771] Trial 66 pruned. Trial was pruned at epoch 5.\n",
      "[I 2025-11-19 15:56:41,276] Trial 67 finished with value: 129.9423399771991 and parameters: {'n1': 384, 'n2': 160, 'do1': 0.4600054999352652, 'do2': 0.2902180041471263, 'lr': 0.0024152938490490383, 'l2': 0.0002695557853552123, 'act': 'gelu', 'batch': 512, 'epochs': 80}. Best is trial 32 with value: 129.6991561026902.\n",
      "[I 2025-11-19 15:56:55,640] Trial 68 pruned. Trial was pruned at epoch 5.\n",
      "[I 2025-11-19 15:57:09,884] Trial 69 pruned. Trial was pruned at epoch 5.\n",
      "[I 2025-11-19 15:57:24,136] Trial 70 pruned. Trial was pruned at epoch 5.\n",
      "[I 2025-11-19 15:57:37,070] Trial 71 pruned. Trial was pruned at epoch 5.\n",
      "[I 2025-11-19 15:58:07,174] Trial 72 finished with value: 129.90281072546122 and parameters: {'n1': 384, 'n2': 160, 'do1': 0.46618554234653986, 'do2': 0.32522636753403084, 'lr': 0.002988404345781297, 'l2': 5.142338242536008e-06, 'act': 'gelu', 'batch': 512, 'epochs': 55}. Best is trial 32 with value: 129.6991561026902.\n",
      "[I 2025-11-19 15:58:25,043] Trial 73 pruned. Trial was pruned at epoch 12.\n",
      "[I 2025-11-19 15:59:08,759] Trial 74 finished with value: 129.66827417732142 and parameters: {'n1': 320, 'n2': 128, 'do1': 0.4860755506545529, 'do2': 0.33702281101431014, 'lr': 0.0037573051304608286, 'l2': 7.0590920479768835e-06, 'act': 'gelu', 'batch': 512, 'epochs': 43}. Best is trial 74 with value: 129.66827417732142.\n",
      "[I 2025-11-19 15:59:52,245] Trial 75 finished with value: 129.88004531826667 and parameters: {'n1': 320, 'n2': 128, 'do1': 0.48572427447545985, 'do2': 0.30250818012578323, 'lr': 0.0037114910304361596, 'l2': 1.392101259515317e-05, 'act': 'gelu', 'batch': 512, 'epochs': 44}. Best is trial 74 with value: 129.66827417732142.\n"
     ]
    }
   ],
   "source": [
    "storageA = prepare_journal_storage(\"ground_trackA_mlp\")\n",
    "studyA = optuna.create_study(direction=\"minimize\",\n",
    "                             sampler=TPESampler(seed=SEED),\n",
    "                             pruner=MedianPruner(n_startup_trials=8, n_warmup_steps=5),\n",
    "                             study_name=\"ground_trackA_mlp\",\n",
    "                             storage=storageA, load_if_exists=True)\n",
    "print(\"Running Study A (MLP)…\")\n",
    "studyA.optimize(objective_mlp, n_trials=40, show_progress_bar=True)\n",
    "\n",
    "best_mlp, bestA_path = _safe_load_best(studyA)\n",
    "yhatA = best_mlp.predict(Xte, verbose=0).squeeze()\n",
    "print(\"Best MLP params:\", studyA.best_trial.params)\n",
    "print(f\"MLP test → RMSE: {_rmse(yte, yhatA):.4f} | MAE: {mean_absolute_error(yte, yhatA):.4f} | R2: {r2_score(yte, yhatA):.4f} | Skill: {skill(yte, yhatA, y_base):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccd9c63c",
   "metadata": {},
   "source": [
    "## Track B - Sequentials"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "185cbc5c",
   "metadata": {},
   "source": [
    "### Mods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b89bcd3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtr_s = pd.DataFrame(Xtr, index=Xtr_df.index, columns=feat_cols)\n",
    "Xva_s = pd.DataFrame(Xva, index=Xva_df.index, columns=feat_cols)\n",
    "Xte_s = pd.DataFrame(Xte, index=Xte_df.index, columns=feat_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ebeef5d",
   "metadata": {},
   "source": [
    "### LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "392c9a2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_lstm(trial: optuna.Trial) -> float:\n",
    "    K.clear_session()\n",
    "    L   = trial.suggest_categorical(\"seq_len\", [6, 12, 18, 24])\n",
    "    u   = trial.suggest_int(\"units\", 32, 128, step=32)\n",
    "    do  = trial.suggest_float(\"dropout\", 0.0, 0.4)\n",
    "    lr  = trial.suggest_float(\"lr\", 5e-5, 5e-3, log=True)\n",
    "    bs  = trial.suggest_categorical(\"batch\", [64, 128, 256])\n",
    "    eps = trial.suggest_int(\"epochs\", 40, 120)\n",
    "\n",
    "    Xtr_seq, ytr_seq = _build_seq(Xtr_s, ytr, L)\n",
    "    Xva_seq, yva_seq = _build_seq(Xva_s, yva, L)\n",
    "    if min(map(len,[Xtr_seq, Xva_seq])) == 0:\n",
    "        raise optuna.TrialPruned()\n",
    "\n",
    "    model = build_lstm(L, Xtr_seq.shape[2], units=u, do=do)\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=lr), loss=\"mse\", metrics=[\"mae\"])\n",
    "\n",
    "    tmp_dir  = ART_DIR / f\"B_lstm_t{trial.number:04d}\"; tmp_dir.mkdir(parents=True, exist_ok=True)\n",
    "    tmp_path = (tmp_dir / \"best.weights.h5\").resolve()\n",
    "\n",
    "    cbs = [\n",
    "        callbacks.EarlyStopping(monitor=\"val_loss\", patience=10, restore_best_weights=True, verbose=0),\n",
    "        callbacks.ModelCheckpoint(filepath=str(tmp_path), monitor=\"val_loss\",\n",
    "                                  save_best_only=True, save_weights_only=True),\n",
    "        TFKerasPruningCallback(trial, \"val_loss\"),\n",
    "    ]\n",
    "    model.fit(Xtr_seq, ytr_seq, validation_data=(Xva_seq, yva_seq),\n",
    "              epochs=eps, batch_size=bs, verbose=0, callbacks=cbs)\n",
    "\n",
    "    yhat = model.predict(Xva_seq, verbose=0).squeeze()\n",
    "    val_rmse = _rmse(yva_seq, yhat)\n",
    "\n",
    "    trial.set_user_attr(\"model_path\", str(tmp_path))\n",
    "    trial.set_user_attr(\"arch\", \"lstm\")\n",
    "    trial.set_user_attr(\"seq_len_used\", L)\n",
    "    trial.set_user_attr(\"n_feat\", Xtr_s.shape[1])\n",
    "    return val_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6777b424",
   "metadata": {},
   "outputs": [],
   "source": [
    "storageB1 = prepare_journal_storage(\"ground_trackB_lstm\")\n",
    "studyB1 = optuna.create_study(direction=\"minimize\",\n",
    "                              sampler=TPESampler(seed=SEED),\n",
    "                              pruner=MedianPruner(n_startup_trials=8, n_warmup_steps=5),\n",
    "                              study_name=\"ground_trackB_lstm\",\n",
    "                              storage=storageB1, load_if_exists=True)\n",
    "print(\"Running Study B1 (LSTM)…\")\n",
    "studyB1.optimize(objective_lstm, n_trials=40, show_progress_bar=True)\n",
    "\n",
    "best_lstm, _ = _safe_load_best(studyB1)\n",
    "bestL1 = studyB1.best_trial.user_attrs[\"seq_len_used\"]\n",
    "Xte_seq, yte_seq, idx_LSTM = build_seq_with_idx(Xte_s, yte, bestL1)\n",
    "yhatB1 = best_lstm.predict(Xte_seq, verbose=0).squeeze()\n",
    "y_base_LSTM = pd.Series(y_base, index=Xte_df.index).reindex(idx_LSTM).to_numpy()\n",
    "print(\"Best LSTM params:\", studyB1.best_trial.params | {\"seq_len\": bestL1})\n",
    "print(f\"LSTM test → RMSE: {_rmse(yte_seq, yhatB1):.4f} | MAE: {mean_absolute_error(yte_seq, yhatB1):.4f} | R2: {r2_score(yte_seq, yhatB1):.4f} | Skill: {skill(yte_seq, yhatB1, y_base_LSTM):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "218b9bf3",
   "metadata": {},
   "source": [
    "### BiLSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1b34537",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_bilstm(trial: optuna.Trial) -> float:\n",
    "    K.clear_session()\n",
    "    L   = trial.suggest_categorical(\"seq_len\", [6, 12, 18, 24])\n",
    "    u   = trial.suggest_int(\"units\", 32, 128, step=32)\n",
    "    do  = trial.suggest_float(\"dropout\", 0.0, 0.4)\n",
    "    lr  = trial.suggest_float(\"lr\", 5e-5, 5e-3, log=True)\n",
    "    bs  = trial.suggest_categorical(\"batch\", [64, 128, 256])\n",
    "    eps = trial.suggest_int(\"epochs\", 40, 120)\n",
    "\n",
    "    Xtr_seq, ytr_seq = _build_seq(Xtr_s, ytr, L)\n",
    "    Xva_seq, yva_seq = _build_seq(Xva_s, yva, L)\n",
    "    if min(map(len,[Xtr_seq, Xva_seq])) == 0:\n",
    "        raise optuna.TrialPruned()\n",
    "\n",
    "    model = build_bilstm(L, Xtr_seq.shape[2], units=u, do=do)\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=lr), loss=\"mse\", metrics=[\"mae\"])\n",
    "\n",
    "    tmp_dir  = ART_DIR / f\"B_bilstm_t{trial.number:04d}\"; tmp_dir.mkdir(parents=True, exist_ok=True)\n",
    "    tmp_path = (tmp_dir / \"best.weights.h5\").resolve()\n",
    "\n",
    "    cbs = [\n",
    "        callbacks.EarlyStopping(monitor=\"val_loss\", patience=10, restore_best_weights=True, verbose=0),\n",
    "        callbacks.ModelCheckpoint(filepath=str(tmp_path), monitor=\"val_loss\",\n",
    "                                  save_best_only=True, save_weights_only=True),\n",
    "        TFKerasPruningCallback(trial, \"val_loss\"),\n",
    "    ]\n",
    "    model.fit(Xtr_seq, ytr_seq, validation_data=(Xva_seq, yva_seq),\n",
    "              epochs=eps, batch_size=bs, verbose=0, callbacks=cbs)\n",
    "\n",
    "    yhat = model.predict(Xva_seq, verbose=0).squeeze()\n",
    "    val_rmse = _rmse(yva_seq, yhat)\n",
    "\n",
    "    trial.set_user_attr(\"model_path\", str(tmp_path))\n",
    "    trial.set_user_attr(\"arch\", \"bilstm\")\n",
    "    trial.set_user_attr(\"seq_len_used\", L)\n",
    "    trial.set_user_attr(\"n_feat\", Xtr_s.shape[1])\n",
    "    return val_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3b5bd62",
   "metadata": {},
   "outputs": [],
   "source": [
    "storageB2 = prepare_journal_storage(\"ground_trackB_bilstm\")\n",
    "studyB2 = optuna.create_study(direction=\"minimize\",\n",
    "                              sampler=TPESampler(seed=SEED),\n",
    "                              pruner=MedianPruner(n_startup_trials=8, n_warmup_steps=5),\n",
    "                              study_name=\"ground_trackB_bilstm\",\n",
    "                              storage=storageB2, load_if_exists=True)\n",
    "print(\"Running Study B2 (BiLSTM)…\")\n",
    "studyB2.optimize(objective_bilstm, n_trials=35, show_progress_bar=True)\n",
    "\n",
    "best_bi, _ = _safe_load_best(studyB2)\n",
    "bestL2 = studyB2.best_trial.user_attrs[\"seq_len_used\"]\n",
    "Xte_seq, yte_seq, idx_BI = build_seq_with_idx(Xte_s, yte, bestL2)\n",
    "yhatB2 = best_bi.predict(Xte_seq, verbose=0).squeeze()\n",
    "y_base_BI = pd.Series(y_base, index=Xte_df.index).reindex(idx_BI).to_numpy()\n",
    "print(\"Best BiLSTM params:\", studyB2.best_trial.params | {\"seq_len\": bestL2})\n",
    "print(f\"BiLSTM test → RMSE: {_rmse(yte_seq, yhatB2):.4f} | MAE: {mean_absolute_error(yte_seq, yhatB2):.4f} | R2: {r2_score(yte_seq, yhatB2):.4f} | Skill: {skill(yte_seq, yhatB2, y_base_BI):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d213bc8d",
   "metadata": {},
   "source": [
    "### CNN-LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f1c2392",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_cnnlstm(trial: optuna.Trial) -> float:\n",
    "    K.clear_session()\n",
    "    L     = trial.suggest_categorical(\"seq_len\", [6, 12, 18, 24])\n",
    "    filt  = trial.suggest_int(\"filters\", 16, 64, step=16)\n",
    "    ksz   = trial.suggest_categorical(\"kernel_size\", [2,3,5])\n",
    "    pool  = trial.suggest_categorical(\"pool\", [1,2])\n",
    "    u     = trial.suggest_int(\"lstm_units\", 32, 128, step=32)\n",
    "    do    = trial.suggest_float(\"dropout\", 0.0, 0.4)\n",
    "    lr    = trial.suggest_float(\"lr\", 5e-5, 5e-3, log=True)\n",
    "    bs    = trial.suggest_categorical(\"batch\", [64, 128, 256])\n",
    "    eps   = trial.suggest_int(\"epochs\", 40, 120)\n",
    "\n",
    "    Xtr_seq, ytr_seq = _build_seq(Xtr_s, ytr, L)\n",
    "    Xva_seq, yva_seq = _build_seq(Xva_s, yva, L)\n",
    "    if min(map(len,[Xtr_seq, Xva_seq])) == 0:\n",
    "        raise optuna.TrialPruned()\n",
    "\n",
    "    model = build_cnnlstm(L, Xtr_seq.shape[2], filt=filt, ksz=ksz, pool=pool, lstm_units=u, do=do)\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=lr), loss=\"mse\", metrics=[\"mae\"])\n",
    "\n",
    "    tmp_dir  = ART_DIR / f\"B_cnnlstm_t{trial.number:04d}\"; tmp_dir.mkdir(parents=True, exist_ok=True)\n",
    "    tmp_path = (tmp_dir / \"best.weights.h5\").resolve()\n",
    "\n",
    "    cbs = [\n",
    "        callbacks.EarlyStopping(monitor=\"val_loss\", patience=10, restore_best_weights=True, verbose=0),\n",
    "        callbacks.ModelCheckpoint(filepath=str(tmp_path), monitor=\"val_loss\",\n",
    "                                  save_best_only=True, save_weights_only=True),\n",
    "        TFKerasPruningCallback(trial, \"val_loss\"),\n",
    "    ]\n",
    "    model.fit(Xtr_seq, ytr_seq, validation_data=(Xva_seq, yva_seq),\n",
    "              epochs=eps, batch_size=bs, verbose=0, callbacks=cbs)\n",
    "\n",
    "    yhat = model.predict(Xva_seq, verbose=0).squeeze()\n",
    "    val_rmse = _rmse(yva_seq, yhat)\n",
    "\n",
    "    trial.set_user_attr(\"model_path\", str(tmp_path))\n",
    "    trial.set_user_attr(\"arch\", \"cnn-lstm\")\n",
    "    trial.set_user_attr(\"seq_len_used\", L)\n",
    "    trial.set_user_attr(\"n_feat\", Xtr_s.shape[1])\n",
    "    return val_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee61c1f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "storageB3 = prepare_journal_storage(\"ground_trackB_cnnlstm\")\n",
    "studyB3 = optuna.create_study(direction=\"minimize\",\n",
    "                              sampler=TPESampler(seed=SEED),\n",
    "                              pruner=MedianPruner(n_startup_trials=8, n_warmup_steps=5),\n",
    "                              study_name=\"ground_trackB_cnnlstm\",\n",
    "                              storage=storageB3, load_if_exists=True)\n",
    "print(\"Running Study B3 (CNN-LSTM)…\")\n",
    "studyB3.optimize(objective_cnnlstm, n_trials=35, show_progress_bar=True)\n",
    "\n",
    "best_cnn, _ = _safe_load_best(studyB3)\n",
    "bestL3 = studyB3.best_trial.user_attrs[\"seq_len_used\"]\n",
    "Xte_seq, yte_seq, idx_CNN = build_seq_with_idx(Xte_s, yte, bestL3)\n",
    "yhatB3 = best_cnn.predict(Xte_seq, verbose=0).squeeze()\n",
    "y_base_CNN = pd.Series(y_base, index=Xte_df.index).reindex(idx_CNN).to_numpy()\n",
    "print(\"Best CNN-LSTM params:\", studyB3.best_trial.params | {\"seq_len\": bestL3})\n",
    "print(f\"CNN-LSTM test → RMSE: {_rmse(yte_seq, yhatB3):.4f} | MAE: {mean_absolute_error(yte_seq, yhatB3):.4f} | R2: {r2_score(yte_seq, yhatB3):.4f} | Skill: {skill(yte_seq, yhatB3, y_base_CNN):.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c53a6c7",
   "metadata": {},
   "source": [
    "### Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f244d1ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_transformer(trial: optuna.Trial) -> float:\n",
    "    K.clear_session()\n",
    "    L       = trial.suggest_categorical(\"seq_len\", [6, 12, 18, 24])\n",
    "    d_model = trial.suggest_categorical(\"d_model\", [32, 64, 96, 128])\n",
    "    heads   = trial.suggest_categorical(\"heads\", [2, 4, 8])\n",
    "    if d_model % heads != 0:\n",
    "        raise optuna.TrialPruned()\n",
    "    ff_dim  = trial.suggest_categorical(\"ff_dim\", [64, 96, 128, 192])\n",
    "    att_do  = trial.suggest_float(\"att_dropout\", 0.0, 0.3)\n",
    "    do      = trial.suggest_float(\"dropout\", 0.0, 0.4)\n",
    "    lr      = trial.suggest_float(\"lr\", 5e-5, 5e-3, log=True)\n",
    "    bs      = trial.suggest_categorical(\"batch\", [64, 128, 256])\n",
    "    eps     = trial.suggest_int(\"epochs\", 40, 120)\n",
    "\n",
    "    Xtr_seq, ytr_seq = _build_seq(Xtr_s, ytr, L)\n",
    "    Xva_seq, yva_seq = _build_seq(Xva_s, yva, L)\n",
    "    if min(map(len,[Xtr_seq, Xva_seq])) == 0:\n",
    "        raise optuna.TrialPruned()\n",
    "\n",
    "    model = build_transformer(L, Xtr_seq.shape[2], d_model=d_model, heads=heads,\n",
    "                              ff_dim=ff_dim, att_do=att_do, do=do)\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=lr), loss=\"mse\", metrics=[\"mae\"])\n",
    "\n",
    "    tmp_dir  = ART_DIR / f\"B_transformer_t{trial.number:04d}\"; tmp_dir.mkdir(parents=True, exist_ok=True)\n",
    "    tmp_path = (tmp_dir / \"best.weights.h5\").resolve()\n",
    "\n",
    "    cbs = [\n",
    "        callbacks.EarlyStopping(monitor=\"val_loss\", patience=10, restore_best_weights=True, verbose=0),\n",
    "        callbacks.ModelCheckpoint(filepath=str(tmp_path), monitor=\"val_loss\",\n",
    "                                  save_best_only=True, save_weights_only=True),\n",
    "        TFKerasPruningCallback(trial, \"val_loss\"),\n",
    "    ]\n",
    "    model.fit(Xtr_seq, ytr_seq, validation_data=(Xva_seq, yva_seq),\n",
    "              epochs=eps, batch_size=bs, verbose=0, callbacks=cbs)\n",
    "\n",
    "    yhat = model.predict(Xva_seq, verbose=0).squeeze()\n",
    "    val_rmse = _rmse(yva_seq, yhat)\n",
    "\n",
    "    trial.set_user_attr(\"model_path\", str(tmp_path))\n",
    "    trial.set_user_attr(\"arch\", \"transformer\")\n",
    "    trial.set_user_attr(\"seq_len_used\", L)\n",
    "    trial.set_user_attr(\"n_feat\", Xtr_s.shape[1])\n",
    "    return val_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab6eee50",
   "metadata": {},
   "outputs": [],
   "source": [
    "storageB4 = prepare_journal_storage(\"ground_trackB_transformer\")\n",
    "studyB4 = optuna.create_study(direction=\"minimize\",\n",
    "                              sampler=TPESampler(seed=SEED),\n",
    "                              pruner=MedianPruner(n_startup_trials=8, n_warmup_steps=5),\n",
    "                              study_name=\"ground_trackB_transformer\",\n",
    "                              storage=storageB4, load_if_exists=True)\n",
    "print(\"Running Study B4 (Transformer)…\")\n",
    "studyB4.optimize(objective_transformer, n_trials=40, show_progress_bar=True)\n",
    "\n",
    "best_tr, _ = _safe_load_best(studyB4)\n",
    "bestL4 = studyB4.best_trial.user_attrs[\"seq_len_used\"]\n",
    "Xte_seq, yte_seq, idx_TR = build_seq_with_idx(Xte_s, yte, bestL4)\n",
    "yhatB4 = best_tr.predict(Xte_seq, verbose=0).squeeze()\n",
    "y_base_TR = pd.Series(y_base, index=Xte_df.index).reindex(idx_TR).to_numpy()\n",
    "print(\"Best Transformer params:\", studyB4.best_trial.params | {\"seq_len\": bestL4})\n",
    "print(f\"Transformer test → RMSE: {_rmse(yte_seq, yhatB4):.4f} | MAE: {mean_absolute_error(yte_seq, yhatB4):.4f} | R2: {r2_score(yte_seq, yhatB4):.4f} | Skill: {skill(yte_seq, yhatB4, y_base_TR):.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01676ed5",
   "metadata": {},
   "source": [
    "## Best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5bf2a76",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = {\n",
    "    \"MLP\":        studyA.best_trial.params,\n",
    "    \"LSTM\":       studyB1.best_trial.params | {\"seq_len\": studyB1.best_trial.user_attrs[\"seq_len_used\"]},\n",
    "    \"BiLSTM\":     studyB2.best_trial.params | {\"seq_len\": studyB2.best_trial.user_attrs[\"seq_len_used\"]},\n",
    "    \"CNN_LSTM\":   studyB3.best_trial.params | {\"seq_len\": studyB3.best_trial.user_attrs[\"seq_len_used\"]},\n",
    "    \"Transformer\":studyB4.best_trial.params | {\"seq_len\": studyB4.best_trial.user_attrs[\"seq_len_used\"]},\n",
    "}\n",
    "(out := OUT_DIR / \"best_hpo_params_all.json\")\n",
    "with open(out, \"w\") as f:\n",
    "    json.dump(best_params, f, indent=2)\n",
    "print(\"Saved params →\", out)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f728f0a",
   "metadata": {},
   "source": [
    "## Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3ae1a93",
   "metadata": {},
   "source": [
    "### Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9fd080b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "OUT_FIG = Path(\"../reports/figures/latest\")\n",
    "OUT_FIG.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def compute_metrics(y_true, y_pred, y_base):\n",
    "    \"\"\"RMSE, MAE, R2 y Skill vs baseline.\"\"\"\n",
    "    rmse = _rmse(y_true, y_pred)\n",
    "    mae  = mean_absolute_error(y_true, y_pred)\n",
    "    r2   = r2_score(y_true, y_pred)\n",
    "    skl  = skill(y_true, y_pred, y_base)\n",
    "    return {\"RMSE\": rmse, \"MAE\": mae, \"R2\": r2, \"Skill\": skl}\n",
    "\n",
    "def plot_ts_clip(idx, y_true, y_pred, y_base, name, target_label, out_dir: Path):\n",
    "    \"\"\"Serie temporal recortada con truth vs modelo vs baseline.\"\"\"\n",
    "    N = min(400, len(y_true))\n",
    "    plt.figure(figsize=(12, 3.6))\n",
    "    plt.plot(idx[:N], y_true[:N], label=\"truth\", lw=1.4)\n",
    "    plt.plot(idx[:N], y_pred[:N], label=name, lw=1.1)\n",
    "    plt.plot(idx[:N], y_base[:N], label=\"baseline\", lw=1.0, alpha=0.7)\n",
    "    plt.title(f\"Test — Truth vs {name} vs Baseline ({target_label})\")\n",
    "    plt.ylabel(\"GHI (W/m²)\" if target_label.startswith(\"y_ghi\") else \"k-index\")\n",
    "    plt.xlabel(\"Time\")\n",
    "    plt.grid(True, ls=\"--\", alpha=0.3)\n",
    "    plt.legend()\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    fname = out_dir / f\"{name}_ts_test.png\"\n",
    "    plt.savefig(fname, dpi=140)\n",
    "    plt.show()\n",
    "    return fname\n",
    "\n",
    "def plot_scatter(y_true, y_pred, name, out_dir: Path):\n",
    "    \"\"\"Scatter y_true vs y_pred con línea 1:1 y métricas en el título.\"\"\"\n",
    "    rmse = _rmse(y_true, y_pred)\n",
    "    mae  = mean_absolute_error(y_true, y_pred)\n",
    "    r2   = r2_score(y_true, y_pred)\n",
    "    lim_min = float(min(np.min(y_true), np.min(y_pred)))\n",
    "    lim_max = float(max(np.max(y_true), np.max(y_pred)))\n",
    "    plt.figure(figsize=(4.8, 4.8))\n",
    "    plt.scatter(y_true, y_pred, s=10, alpha=0.5)\n",
    "    plt.plot([lim_min, lim_max], [lim_min, lim_max], 'r--', lw=1.0)\n",
    "    plt.xlabel(\"Actual\")\n",
    "    plt.ylabel(\"Predicted\")\n",
    "    plt.title(f\"{name} — Actual vs Predicted\\nRMSE={rmse:.3f} MAE={mae:.3f} R2={r2:.3f}\")\n",
    "    plt.grid(True, ls=\"--\", alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    fname = out_dir / f\"{name}_scatter.png\"\n",
    "    plt.savefig(fname, dpi=140)\n",
    "    plt.show()\n",
    "    return fname\n",
    "\n",
    "def plot_residuals(y_true, y_pred, name, out_dir: Path):\n",
    "    \"\"\"Histograma de residuales (y_pred - y_true).\"\"\"\n",
    "    resid = y_pred - y_true\n",
    "    plt.figure(figsize=(6, 3.2))\n",
    "    plt.hist(resid, bins=50, alpha=0.85)\n",
    "    plt.axvline(0, color='r', ls='--', lw=1)\n",
    "    plt.title(f\"{name} — Residuals (mean={np.mean(resid):.3f})\")\n",
    "    plt.xlabel(\"Residual\")\n",
    "    plt.ylabel(\"Frequency\")\n",
    "    plt.grid(True, ls=\"--\", alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    fname = out_dir / f\"{name}_residuals.png\"\n",
    "    plt.savefig(fname, dpi=140)\n",
    "    plt.show()\n",
    "    return fname\n",
    "\n",
    "def hourly_skill(y_true, y_pred, y_base, idx):\n",
    "    \"\"\"\n",
    "    Skill vs persistencia por hora del día:\n",
    "    skill(h) = 1 - RMSE_model(h) / RMSE_base(h).\n",
    "    \"\"\"\n",
    "    df = pd.DataFrame({\n",
    "        \"time\": idx,\n",
    "        \"y_true\": y_true,\n",
    "        \"y_pred\": y_pred,\n",
    "        \"y_base\": y_base,\n",
    "    }).set_index(\"time\")\n",
    "    df[\"hour\"] = df.index.hour\n",
    "\n",
    "    rows = []\n",
    "    for h in range(24):\n",
    "        sub = df[df[\"hour\"] == h]\n",
    "        if len(sub) < 10:\n",
    "            continue\n",
    "        rmse_m = _rmse(sub[\"y_true\"], sub[\"y_pred\"])\n",
    "        rmse_b = _rmse(sub[\"y_true\"], sub[\"y_base\"])\n",
    "        skl = 1.0 - rmse_m / (rmse_b + 1e-6)\n",
    "        rows.append((h, rmse_m, rmse_b, skl))\n",
    "\n",
    "    if not rows:\n",
    "        return pd.DataFrame(columns=[\"rmse_model\", \"rmse_base\", \"skill\"])\n",
    "\n",
    "    res = pd.DataFrame(rows, columns=[\"hour\", \"rmse_model\", \"rmse_base\", \"skill\"]).set_index(\"hour\")\n",
    "    return res\n",
    "\n",
    "def plot_hourly_skill_all(models_hourly_skill: dict, out_dir: Path):\n",
    "    \"\"\"Linea de skill vs persistencia por hora para cada modelo.\"\"\"\n",
    "    plt.figure(figsize=(8, 4))\n",
    "    for name, df_skill in models_hourly_skill.items():\n",
    "        if df_skill.empty:\n",
    "            continue\n",
    "        plt.plot(df_skill.index, df_skill[\"skill\"], marker=\"o\", label=name)\n",
    "    plt.axhline(0.0, ls=\"--\", lw=1, color=\"k\")\n",
    "    plt.xlabel(\"Hour of day\")\n",
    "    plt.ylabel(\"Skill vs persistence\")\n",
    "    plt.title(\"Hourly skill vs persistence (test)\")\n",
    "    plt.xticks(range(0, 24))\n",
    "    plt.grid(True, ls=\"--\", alpha=0.3)\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    fname = out_dir / \"hourly_skill_all_models.png\"\n",
    "    plt.savefig(fname, dpi=160)\n",
    "    plt.show()\n",
    "    return fname\n",
    "\n",
    "def binned_rmse(y_true, y_pred, bins):\n",
    "    \"\"\"RMSE por rango de GHI real (como en tu otro proyecto).\"\"\"\n",
    "    df_err = pd.DataFrame({\"y\": y_true, \"yhat\": y_pred})\n",
    "    df_err[\"bin\"] = pd.cut(df_err[\"y\"], bins=bins, include_lowest=True)\n",
    "    stats = df_err.groupby(\"bin\").apply(\n",
    "        lambda d: np.sqrt(mean_squared_error(d[\"y\"], d[\"yhat\"]))\n",
    "    )\n",
    "    return stats\n",
    "\n",
    "def plot_binned_rmse(y_true, y_pred, name, out_dir: Path, bins=None):\n",
    "    if bins is None:\n",
    "        bins = [0, 200, 400, 600, 800, 1200]\n",
    "    stats = binned_rmse(y_true, y_pred, bins)\n",
    "    plt.figure(figsize=(7, 4))\n",
    "    plt.plot(stats.index.astype(str), stats.values, marker=\"o\")\n",
    "    plt.xticks(rotation=45, ha=\"right\")\n",
    "    plt.ylabel(\"RMSE (W/m²)\")\n",
    "    plt.title(f\"{name} — RMSE por rango de GHI real\")\n",
    "    plt.tight_layout()\n",
    "    fname = out_dir / f\"{name}_rmse_by_ghi_bin.png\"\n",
    "    plt.savefig(fname, dpi=160)\n",
    "    plt.show()\n",
    "    return fname\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65cbfe37",
   "metadata": {},
   "outputs": [],
   "source": [
    "models_info = {\n",
    "    \"MLP\": {\n",
    "        \"type\": \"tabular\",\n",
    "        \"model\": best_mlp,\n",
    "        \"idx\": Xte_df.index,\n",
    "        \"y_base\": y_base\n",
    "    },\n",
    "    \"LSTM\": {\n",
    "        \"type\": \"seq\",\n",
    "        \"model\": best_lstm,\n",
    "        \"L\": bestL1,\n",
    "        \"idx\": idx_LSTM,\n",
    "        \"y_base\": y_base_LSTM\n",
    "    },\n",
    "    \"BiLSTM\": {\n",
    "        \"type\": \"seq\",\n",
    "        \"model\": best_bi,\n",
    "        \"L\": bestL2,\n",
    "        \"idx\": idx_BI,\n",
    "        \"y_base\": y_base_BI\n",
    "    },\n",
    "    \"CNN-LSTM\": {\n",
    "        \"type\": \"seq\",\n",
    "        \"model\": best_cnn,\n",
    "        \"L\": bestL3,\n",
    "        \"idx\": idx_CNN,\n",
    "        \"y_base\": y_base_CNN\n",
    "    },\n",
    "    \"Transformer\": {\n",
    "        \"type\": \"seq\",\n",
    "        \"model\": best_tr,\n",
    "        \"L\": bestL4,\n",
    "        \"idx\": idx_TR,\n",
    "        \"y_base\": y_base_TR\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c60f4490",
   "metadata": {},
   "source": [
    "### Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0fc1a19",
   "metadata": {},
   "outputs": [],
   "source": [
    "models_info = {\n",
    "    \"MLP\": {\n",
    "        \"type\": \"tabular\",\n",
    "        \"model\": best_mlp,\n",
    "        \"idx\": Xte_df.index,\n",
    "        \"y_base\": y_base\n",
    "    },\n",
    "    \"LSTM\": {\n",
    "        \"type\": \"seq\",\n",
    "        \"model\": best_lstm,\n",
    "        \"L\": bestL1,\n",
    "        \"idx\": idx_LSTM,\n",
    "        \"y_base\": y_base_LSTM\n",
    "    },\n",
    "    \"BiLSTM\": {\n",
    "        \"type\": \"seq\",\n",
    "        \"model\": best_bi,\n",
    "        \"L\": bestL2,\n",
    "        \"idx\": idx_BI,\n",
    "        \"y_base\": y_base_BI\n",
    "    },\n",
    "    \"CNN-LSTM\": {\n",
    "        \"type\": \"seq\",\n",
    "        \"model\": best_cnn,\n",
    "        \"L\": bestL3,\n",
    "        \"idx\": idx_CNN,\n",
    "        \"y_base\": y_base_CNN\n",
    "    },\n",
    "    \"Transformer\": {\n",
    "        \"type\": \"seq\",\n",
    "        \"model\": best_tr,\n",
    "        \"L\": bestL4,\n",
    "        \"idx\": idx_TR,\n",
    "        \"y_base\": y_base_TR\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd459069",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_by_model = {}\n",
    "hourly_skill_by_model = {}\n",
    "diag_data = {}\n",
    "\n",
    "for name, cfg in models_info.items():\n",
    "    print(f\"\\n=== {name} ===\")\n",
    "    if cfg[\"type\"] == \"tabular\":\n",
    "        y_true = yte\n",
    "        y_pred = cfg[\"model\"].predict(Xte, verbose=0).squeeze()\n",
    "        idx    = cfg[\"idx\"]\n",
    "        yb     = cfg[\"y_base\"]\n",
    "    else:\n",
    "        L = int(cfg[\"L\"])\n",
    "        X_seq, y_seq, idx = build_seq_with_idx(Xte_s, yte, L)\n",
    "        if len(X_seq) == 0:\n",
    "            print(\"No hay secuencias válidas (NaNs). Se omite.\")\n",
    "            continue\n",
    "        y_true = y_seq\n",
    "        y_pred = cfg[\"model\"].predict(X_seq, verbose=0).squeeze()\n",
    "        yb     = pd.Series(y_base, index=Xte_df.index).reindex(idx).to_numpy()\n",
    "\n",
    "    # Métricas\n",
    "    mets = compute_metrics(y_true, y_pred, yb)\n",
    "    metrics_by_model[name] = mets\n",
    "    print(f\"RMSE={mets['RMSE']:.4f} | MAE={mets['MAE']:.4f} | R2={mets['R2']:.4f} | Skill={mets['Skill']:.3f}\")\n",
    "\n",
    "    # Guardar data cruda para diagnósticos adicionales\n",
    "    diag_data[name] = {\n",
    "        \"y_true\": y_true,\n",
    "        \"y_pred\": y_pred,\n",
    "        \"idx\": idx,\n",
    "        \"y_base\": yb,\n",
    "    }\n",
    "\n",
    "    # Plots individuales\n",
    "    plot_ts_clip(idx, y_true, y_pred, yb, name, TARGET, OUT_FIG)\n",
    "    plot_scatter(y_true, y_pred, name, OUT_FIG)\n",
    "    plot_residuals(y_true, y_pred, name, OUT_FIG)\n",
    "\n",
    "    # Skill horario\n",
    "    sk_hour = hourly_skill(y_true, y_pred, yb, idx)\n",
    "    hourly_skill_by_model[name] = sk_hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c6fca96",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = (\n",
    "    pd.DataFrame(metrics_by_model)\n",
    "    .T\n",
    "    .reset_index()\n",
    "    .rename(columns={\"index\": \"model\"})\n",
    "    .sort_values(\"RMSE\")\n",
    ")\n",
    "print(\"\\n=== Test Summary (all models, test set) ===\")\n",
    "print(results_df.round(4))\n",
    "\n",
    "# CSV \n",
    "results_df.to_csv(OUT_DIR / \"hpo_models_test_summary.csv\", index=False)\n",
    "\n",
    "# JSON\n",
    "metrics_json = {\n",
    "    m: {k: float(v) for k, v in mets.items()}\n",
    "    for m, mets in metrics_by_model.items()\n",
    "}\n",
    "with open(OUT_DIR / \"hpo_models_test_metrics.json\", \"w\") as f:\n",
    "    json.dump(metrics_json, f, indent=2)\n",
    "print(\"Saved metrics JSON →\", OUT_DIR / \"hpo_models_test_metrics.json\")\n",
    "\n",
    "# Bar plot de RMSE en test\n",
    "plt.figure(figsize=(7, 4))\n",
    "plt.bar(results_df[\"model\"], results_df[\"RMSE\"])\n",
    "plt.ylabel(\"RMSE\")\n",
    "plt.title(\"Comparación de modelos – RMSE en test\")\n",
    "plt.xticks(rotation=45, ha=\"right\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(OUT_FIG / \"models_rmse_bar.png\", dpi=160)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "375d173c",
   "metadata": {},
   "outputs": [],
   "source": [
    "if hourly_skill_by_model:\n",
    "    plot_hourly_skill_all(hourly_skill_by_model, OUT_FIG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6f761c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model_name = results_df.iloc[0][\"model\"]\n",
    "print(f\"\\nMejor modelo por RMSE: {best_model_name}\")\n",
    "best_diag = diag_data[best_model_name]\n",
    "plot_binned_rmse(\n",
    "    best_diag[\"y_true\"],\n",
    "    best_diag[\"y_pred\"],\n",
    "    best_model_name,\n",
    "    OUT_FIG,\n",
    "    bins=[0, 200, 400, 600, 800, 1200]\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "e_ladino",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
